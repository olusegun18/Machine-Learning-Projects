{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import skew,norm  # for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "#Visualizing tools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#preprocessing tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#ML Algoirthm\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "import sklearn.linear_model as linear_model\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrain = pd.read_csv('Train (1).csv')\n",
    "ttest = pd.read_csv('Test (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data = pd.concat([ttrain,ttest]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>urban_or_rural</th>\n",
       "      <th>ghsl_water_surface</th>\n",
       "      <th>ghsl_built_pre_1975</th>\n",
       "      <th>ghsl_built_1975_to_1990</th>\n",
       "      <th>ghsl_built_1990_to_2000</th>\n",
       "      <th>ghsl_built_2000_to_2014</th>\n",
       "      <th>ghsl_not_built_up</th>\n",
       "      <th>ghsl_pop_density</th>\n",
       "      <th>landcover_crops_fraction</th>\n",
       "      <th>landcover_urban_fraction</th>\n",
       "      <th>landcover_water_permanent_10km_fraction</th>\n",
       "      <th>landcover_water_seasonal_10km_fraction</th>\n",
       "      <th>nighttime_lights</th>\n",
       "      <th>dist_to_capital</th>\n",
       "      <th>dist_to_shoreline</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_AAIethGy</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>2016</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.999408</td>\n",
       "      <td>12.146134</td>\n",
       "      <td>25.489659</td>\n",
       "      <td>0.879484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>278.788451</td>\n",
       "      <td>769.338378</td>\n",
       "      <td>0.132783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_AAYiaCeL</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>2005</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.999872</td>\n",
       "      <td>113.806716</td>\n",
       "      <td>64.136053</td>\n",
       "      <td>0.601427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.986978</td>\n",
       "      <td>337.135243</td>\n",
       "      <td>0.004898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_AAdurmKj</td>\n",
       "      <td>Mozambique</td>\n",
       "      <td>2009</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.400096</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>642.594208</td>\n",
       "      <td>169.913773</td>\n",
       "      <td>0.097320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_AAgNHles</td>\n",
       "      <td>Malawi</td>\n",
       "      <td>2015</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.999195</td>\n",
       "      <td>5.213320</td>\n",
       "      <td>25.379371</td>\n",
       "      <td>2.017136</td>\n",
       "      <td>11.293841</td>\n",
       "      <td>0.131035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>365.349451</td>\n",
       "      <td>613.591610</td>\n",
       "      <td>0.304107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_AAishfND</td>\n",
       "      <td>Guinea</td>\n",
       "      <td>2012</td>\n",
       "      <td>U</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011649</td>\n",
       "      <td>0.017560</td>\n",
       "      <td>0.017383</td>\n",
       "      <td>0.099875</td>\n",
       "      <td>0.853533</td>\n",
       "      <td>31.734661</td>\n",
       "      <td>5.081620</td>\n",
       "      <td>22.815984</td>\n",
       "      <td>0.005047</td>\n",
       "      <td>0.130475</td>\n",
       "      <td>1.461894</td>\n",
       "      <td>222.867189</td>\n",
       "      <td>192.926363</td>\n",
       "      <td>0.605328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID     country  year urban_or_rural  ghsl_water_surface  \\\n",
       "0  ID_AAIethGy    Ethiopia  2016              R                 0.0   \n",
       "1  ID_AAYiaCeL    Ethiopia  2005              R                 0.0   \n",
       "2  ID_AAdurmKj  Mozambique  2009              R                 0.0   \n",
       "3  ID_AAgNHles      Malawi  2015              R                 0.0   \n",
       "4  ID_AAishfND      Guinea  2012              U                 0.0   \n",
       "\n",
       "   ghsl_built_pre_1975  ghsl_built_1975_to_1990  ghsl_built_1990_to_2000  \\\n",
       "0             0.000000                 0.000000                 0.000055   \n",
       "1             0.000000                 0.000110                 0.000000   \n",
       "2             0.000000                 0.000000                 0.000000   \n",
       "3             0.000141                 0.000181                 0.000254   \n",
       "4             0.011649                 0.017560                 0.017383   \n",
       "\n",
       "   ghsl_built_2000_to_2014  ghsl_not_built_up  ghsl_pop_density  \\\n",
       "0                 0.000536           0.999408         12.146134   \n",
       "1                 0.000018           0.999872        113.806716   \n",
       "2                 0.000000           1.000000          0.000000   \n",
       "3                 0.000228           0.999195          5.213320   \n",
       "4                 0.099875           0.853533         31.734661   \n",
       "\n",
       "   landcover_crops_fraction  landcover_urban_fraction  \\\n",
       "0                 25.489659                  0.879484   \n",
       "1                 64.136053                  0.601427   \n",
       "2                  4.400096                  0.131900   \n",
       "3                 25.379371                  2.017136   \n",
       "4                  5.081620                 22.815984   \n",
       "\n",
       "   landcover_water_permanent_10km_fraction  \\\n",
       "0                                 0.000000   \n",
       "1                                 0.000000   \n",
       "2                                 0.000000   \n",
       "3                                11.293841   \n",
       "4                                 0.005047   \n",
       "\n",
       "   landcover_water_seasonal_10km_fraction  nighttime_lights  dist_to_capital  \\\n",
       "0                                0.000000          0.000000       278.788451   \n",
       "1                                0.005427          0.000000       200.986978   \n",
       "2                                0.003078          0.000000       642.594208   \n",
       "3                                0.131035          0.000000       365.349451   \n",
       "4                                0.130475          1.461894       222.867189   \n",
       "\n",
       "   dist_to_shoreline    Target  \n",
       "0         769.338378  0.132783  \n",
       "1         337.135243  0.004898  \n",
       "2         169.913773  0.097320  \n",
       "3         613.591610  0.304107  \n",
       "4         192.926363  0.605328  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                            0\n",
       "country                                       0\n",
       "year                                          0\n",
       "urban_or_rural                                0\n",
       "ghsl_water_surface                            0\n",
       "ghsl_built_pre_1975                           0\n",
       "ghsl_built_1975_to_1990                       0\n",
       "ghsl_built_1990_to_2000                       0\n",
       "ghsl_built_2000_to_2014                       0\n",
       "ghsl_not_built_up                             0\n",
       "ghsl_pop_density                              0\n",
       "landcover_crops_fraction                      0\n",
       "landcover_urban_fraction                      0\n",
       "landcover_water_permanent_10km_fraction       0\n",
       "landcover_water_seasonal_10km_fraction        0\n",
       "nighttime_lights                              0\n",
       "dist_to_capital                               0\n",
       "dist_to_shoreline                             0\n",
       "Target                                     7194\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data.drop(['ID'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>ghsl_water_surface</th>\n",
       "      <th>ghsl_built_pre_1975</th>\n",
       "      <th>ghsl_built_1975_to_1990</th>\n",
       "      <th>ghsl_built_1990_to_2000</th>\n",
       "      <th>ghsl_built_2000_to_2014</th>\n",
       "      <th>ghsl_not_built_up</th>\n",
       "      <th>ghsl_pop_density</th>\n",
       "      <th>landcover_crops_fraction</th>\n",
       "      <th>landcover_urban_fraction</th>\n",
       "      <th>landcover_water_permanent_10km_fraction</th>\n",
       "      <th>landcover_water_seasonal_10km_fraction</th>\n",
       "      <th>nighttime_lights</th>\n",
       "      <th>dist_to_capital</th>\n",
       "      <th>dist_to_shoreline</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28648.000000</td>\n",
       "      <td>28648.000000</td>\n",
       "      <td>28648.000000</td>\n",
       "      <td>28648.000000</td>\n",
       "      <td>28648.000000</td>\n",
       "      <td>28648.000000</td>\n",
       "      <td>28648.000000</td>\n",
       "      <td>28648.000000</td>\n",
       "      <td>28648.000000</td>\n",
       "      <td>28648.000000</td>\n",
       "      <td>28648.000000</td>\n",
       "      <td>28648.000000</td>\n",
       "      <td>28648.000000</td>\n",
       "      <td>28648.000000</td>\n",
       "      <td>28648.000000</td>\n",
       "      <td>21454.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2010.271537</td>\n",
       "      <td>0.027018</td>\n",
       "      <td>0.041010</td>\n",
       "      <td>0.027820</td>\n",
       "      <td>0.013713</td>\n",
       "      <td>0.018369</td>\n",
       "      <td>0.872069</td>\n",
       "      <td>95.101508</td>\n",
       "      <td>21.097237</td>\n",
       "      <td>14.079153</td>\n",
       "      <td>1.668968</td>\n",
       "      <td>0.694652</td>\n",
       "      <td>9.260498</td>\n",
       "      <td>300.584775</td>\n",
       "      <td>473.801360</td>\n",
       "      <td>0.350736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.553145</td>\n",
       "      <td>0.095199</td>\n",
       "      <td>0.118721</td>\n",
       "      <td>0.072850</td>\n",
       "      <td>0.034208</td>\n",
       "      <td>0.040241</td>\n",
       "      <td>0.242707</td>\n",
       "      <td>210.079701</td>\n",
       "      <td>16.309999</td>\n",
       "      <td>23.917510</td>\n",
       "      <td>7.152657</td>\n",
       "      <td>2.383790</td>\n",
       "      <td>26.160952</td>\n",
       "      <td>269.097712</td>\n",
       "      <td>355.856845</td>\n",
       "      <td>0.194376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105306</td>\n",
       "      <td>0.112080</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2008.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.895615</td>\n",
       "      <td>2.943082</td>\n",
       "      <td>6.105505</td>\n",
       "      <td>0.705307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>110.789483</td>\n",
       "      <td>158.829182</td>\n",
       "      <td>0.195772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2011.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.992725</td>\n",
       "      <td>16.424158</td>\n",
       "      <td>19.297194</td>\n",
       "      <td>2.599028</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.033941</td>\n",
       "      <td>0.024074</td>\n",
       "      <td>253.537926</td>\n",
       "      <td>420.442368</td>\n",
       "      <td>0.293574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2014.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008011</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0.008823</td>\n",
       "      <td>0.015209</td>\n",
       "      <td>0.999592</td>\n",
       "      <td>64.364772</td>\n",
       "      <td>33.199903</td>\n",
       "      <td>13.063126</td>\n",
       "      <td>0.172243</td>\n",
       "      <td>0.375420</td>\n",
       "      <td>4.963472</td>\n",
       "      <td>403.780077</td>\n",
       "      <td>732.552186</td>\n",
       "      <td>0.499003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2016.000000</td>\n",
       "      <td>0.991100</td>\n",
       "      <td>0.894608</td>\n",
       "      <td>0.685010</td>\n",
       "      <td>0.515534</td>\n",
       "      <td>0.649159</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1902.876955</td>\n",
       "      <td>80.064918</td>\n",
       "      <td>98.784092</td>\n",
       "      <td>99.164018</td>\n",
       "      <td>56.201637</td>\n",
       "      <td>403.455783</td>\n",
       "      <td>1908.105037</td>\n",
       "      <td>1769.523906</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               year  ghsl_water_surface  ghsl_built_pre_1975  \\\n",
       "count  28648.000000        28648.000000         28648.000000   \n",
       "mean    2010.271537            0.027018             0.041010   \n",
       "std        4.553145            0.095199             0.118721   \n",
       "min     1994.000000            0.000000             0.000000   \n",
       "25%     2008.000000            0.000000             0.000000   \n",
       "50%     2011.000000            0.000000             0.000160   \n",
       "75%     2014.000000            0.000000             0.008011   \n",
       "max     2016.000000            0.991100             0.894608   \n",
       "\n",
       "       ghsl_built_1975_to_1990  ghsl_built_1990_to_2000  \\\n",
       "count             28648.000000             28648.000000   \n",
       "mean                  0.027820                 0.013713   \n",
       "std                   0.072850                 0.034208   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000037   \n",
       "50%                   0.000602                 0.000936   \n",
       "75%                   0.010037                 0.008823   \n",
       "max                   0.685010                 0.515534   \n",
       "\n",
       "       ghsl_built_2000_to_2014  ghsl_not_built_up  ghsl_pop_density  \\\n",
       "count             28648.000000       28648.000000      28648.000000   \n",
       "mean                  0.018369           0.872069         95.101508   \n",
       "std                   0.040241           0.242707        210.079701   \n",
       "min                   0.000000           0.000859          0.000000   \n",
       "25%                   0.000109           0.895615          2.943082   \n",
       "50%                   0.001727           0.992725         16.424158   \n",
       "75%                   0.015209           0.999592         64.364772   \n",
       "max                   0.649159           1.000000       1902.876955   \n",
       "\n",
       "       landcover_crops_fraction  landcover_urban_fraction  \\\n",
       "count              28648.000000              28648.000000   \n",
       "mean                  21.097237                 14.079153   \n",
       "std                   16.309999                 23.917510   \n",
       "min                    0.000000                  0.000000   \n",
       "25%                    6.105505                  0.705307   \n",
       "50%                   19.297194                  2.599028   \n",
       "75%                   33.199903                 13.063126   \n",
       "max                   80.064918                 98.784092   \n",
       "\n",
       "       landcover_water_permanent_10km_fraction  \\\n",
       "count                             28648.000000   \n",
       "mean                                  1.668968   \n",
       "std                                   7.152657   \n",
       "min                                   0.000000   \n",
       "25%                                   0.000000   \n",
       "50%                                   0.000579   \n",
       "75%                                   0.172243   \n",
       "max                                  99.164018   \n",
       "\n",
       "       landcover_water_seasonal_10km_fraction  nighttime_lights  \\\n",
       "count                            28648.000000      28648.000000   \n",
       "mean                                 0.694652          9.260498   \n",
       "std                                  2.383790         26.160952   \n",
       "min                                  0.000000          0.000000   \n",
       "25%                                  0.001394          0.000000   \n",
       "50%                                  0.033941          0.024074   \n",
       "75%                                  0.375420          4.963472   \n",
       "max                                 56.201637        403.455783   \n",
       "\n",
       "       dist_to_capital  dist_to_shoreline        Target  \n",
       "count     28648.000000       28648.000000  21454.000000  \n",
       "mean        300.584775         473.801360      0.350736  \n",
       "std         269.097712         355.856845      0.194376  \n",
       "min           0.105306           0.112080      0.000000  \n",
       "25%         110.789483         158.829182      0.195772  \n",
       "50%         253.537926         420.442368      0.293574  \n",
       "75%         403.780077         732.552186      0.499003  \n",
       "max        1908.105037        1769.523906      1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>ghsl_water_surface</th>\n",
       "      <th>ghsl_built_pre_1975</th>\n",
       "      <th>ghsl_built_1975_to_1990</th>\n",
       "      <th>ghsl_built_1990_to_2000</th>\n",
       "      <th>ghsl_built_2000_to_2014</th>\n",
       "      <th>ghsl_not_built_up</th>\n",
       "      <th>ghsl_pop_density</th>\n",
       "      <th>landcover_crops_fraction</th>\n",
       "      <th>landcover_urban_fraction</th>\n",
       "      <th>landcover_water_permanent_10km_fraction</th>\n",
       "      <th>landcover_water_seasonal_10km_fraction</th>\n",
       "      <th>nighttime_lights</th>\n",
       "      <th>dist_to_capital</th>\n",
       "      <th>dist_to_shoreline</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012947</td>\n",
       "      <td>-0.083721</td>\n",
       "      <td>-0.038382</td>\n",
       "      <td>-0.018690</td>\n",
       "      <td>0.017530</td>\n",
       "      <td>0.057279</td>\n",
       "      <td>-0.048618</td>\n",
       "      <td>0.082205</td>\n",
       "      <td>-0.055750</td>\n",
       "      <td>0.034326</td>\n",
       "      <td>-0.054697</td>\n",
       "      <td>-0.028213</td>\n",
       "      <td>0.019710</td>\n",
       "      <td>-0.015886</td>\n",
       "      <td>0.115014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghsl_water_surface</th>\n",
       "      <td>-0.012947</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197961</td>\n",
       "      <td>0.110012</td>\n",
       "      <td>0.040389</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>-0.533573</td>\n",
       "      <td>0.137382</td>\n",
       "      <td>-0.221121</td>\n",
       "      <td>0.246438</td>\n",
       "      <td>0.639638</td>\n",
       "      <td>0.185985</td>\n",
       "      <td>0.171599</td>\n",
       "      <td>-0.030484</td>\n",
       "      <td>-0.152016</td>\n",
       "      <td>0.182816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghsl_built_pre_1975</th>\n",
       "      <td>-0.083721</td>\n",
       "      <td>0.197961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.474982</td>\n",
       "      <td>0.464407</td>\n",
       "      <td>0.281641</td>\n",
       "      <td>-0.821521</td>\n",
       "      <td>0.816594</td>\n",
       "      <td>-0.337366</td>\n",
       "      <td>0.804210</td>\n",
       "      <td>0.079085</td>\n",
       "      <td>0.053655</td>\n",
       "      <td>0.746656</td>\n",
       "      <td>-0.147007</td>\n",
       "      <td>-0.186005</td>\n",
       "      <td>0.450119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghsl_built_1975_to_1990</th>\n",
       "      <td>-0.038382</td>\n",
       "      <td>0.110012</td>\n",
       "      <td>0.474982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.451552</td>\n",
       "      <td>0.445210</td>\n",
       "      <td>-0.713104</td>\n",
       "      <td>0.658810</td>\n",
       "      <td>-0.298848</td>\n",
       "      <td>0.750170</td>\n",
       "      <td>0.042565</td>\n",
       "      <td>0.070884</td>\n",
       "      <td>0.567003</td>\n",
       "      <td>-0.186747</td>\n",
       "      <td>-0.151022</td>\n",
       "      <td>0.500753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghsl_built_1990_to_2000</th>\n",
       "      <td>-0.018690</td>\n",
       "      <td>0.040389</td>\n",
       "      <td>0.464407</td>\n",
       "      <td>0.451552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.574375</td>\n",
       "      <td>-0.614719</td>\n",
       "      <td>0.507582</td>\n",
       "      <td>-0.257735</td>\n",
       "      <td>0.638640</td>\n",
       "      <td>0.017545</td>\n",
       "      <td>0.017371</td>\n",
       "      <td>0.414382</td>\n",
       "      <td>-0.166710</td>\n",
       "      <td>-0.142295</td>\n",
       "      <td>0.425059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghsl_built_2000_to_2014</th>\n",
       "      <td>0.017530</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>0.281641</td>\n",
       "      <td>0.445210</td>\n",
       "      <td>0.574375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.531842</td>\n",
       "      <td>0.416470</td>\n",
       "      <td>-0.226773</td>\n",
       "      <td>0.587058</td>\n",
       "      <td>0.003370</td>\n",
       "      <td>0.023246</td>\n",
       "      <td>0.355522</td>\n",
       "      <td>-0.167433</td>\n",
       "      <td>-0.088179</td>\n",
       "      <td>0.429262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghsl_not_built_up</th>\n",
       "      <td>0.057279</td>\n",
       "      <td>-0.533573</td>\n",
       "      <td>-0.821521</td>\n",
       "      <td>-0.713104</td>\n",
       "      <td>-0.614719</td>\n",
       "      <td>-0.531842</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.791663</td>\n",
       "      <td>0.415382</td>\n",
       "      <td>-0.902559</td>\n",
       "      <td>-0.305384</td>\n",
       "      <td>-0.126775</td>\n",
       "      <td>-0.720076</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>0.230617</td>\n",
       "      <td>-0.580670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ghsl_pop_density</th>\n",
       "      <td>-0.048618</td>\n",
       "      <td>0.137382</td>\n",
       "      <td>0.816594</td>\n",
       "      <td>0.658810</td>\n",
       "      <td>0.507582</td>\n",
       "      <td>0.416470</td>\n",
       "      <td>-0.791663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.323615</td>\n",
       "      <td>0.860147</td>\n",
       "      <td>0.044945</td>\n",
       "      <td>0.038811</td>\n",
       "      <td>0.761638</td>\n",
       "      <td>-0.162155</td>\n",
       "      <td>-0.164513</td>\n",
       "      <td>0.525206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>landcover_crops_fraction</th>\n",
       "      <td>0.082205</td>\n",
       "      <td>-0.221121</td>\n",
       "      <td>-0.337366</td>\n",
       "      <td>-0.298848</td>\n",
       "      <td>-0.257735</td>\n",
       "      <td>-0.226773</td>\n",
       "      <td>0.415382</td>\n",
       "      <td>-0.323615</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.377178</td>\n",
       "      <td>-0.112033</td>\n",
       "      <td>-0.096018</td>\n",
       "      <td>-0.304454</td>\n",
       "      <td>-0.055470</td>\n",
       "      <td>0.281731</td>\n",
       "      <td>-0.253550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>landcover_urban_fraction</th>\n",
       "      <td>-0.055750</td>\n",
       "      <td>0.246438</td>\n",
       "      <td>0.804210</td>\n",
       "      <td>0.750170</td>\n",
       "      <td>0.638640</td>\n",
       "      <td>0.587058</td>\n",
       "      <td>-0.902559</td>\n",
       "      <td>0.860147</td>\n",
       "      <td>-0.377178</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059166</td>\n",
       "      <td>0.066508</td>\n",
       "      <td>0.761303</td>\n",
       "      <td>-0.214692</td>\n",
       "      <td>-0.214850</td>\n",
       "      <td>0.666768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>landcover_water_permanent_10km_fraction</th>\n",
       "      <td>0.034326</td>\n",
       "      <td>0.639638</td>\n",
       "      <td>0.079085</td>\n",
       "      <td>0.042565</td>\n",
       "      <td>0.017545</td>\n",
       "      <td>0.003370</td>\n",
       "      <td>-0.305384</td>\n",
       "      <td>0.044945</td>\n",
       "      <td>-0.112033</td>\n",
       "      <td>0.059166</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.110541</td>\n",
       "      <td>0.035453</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.060882</td>\n",
       "      <td>0.017210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>landcover_water_seasonal_10km_fraction</th>\n",
       "      <td>-0.054697</td>\n",
       "      <td>0.185985</td>\n",
       "      <td>0.053655</td>\n",
       "      <td>0.070884</td>\n",
       "      <td>0.017371</td>\n",
       "      <td>0.023246</td>\n",
       "      <td>-0.126775</td>\n",
       "      <td>0.038811</td>\n",
       "      <td>-0.096018</td>\n",
       "      <td>0.066508</td>\n",
       "      <td>0.110541</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037150</td>\n",
       "      <td>0.049984</td>\n",
       "      <td>-0.007002</td>\n",
       "      <td>0.066462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nighttime_lights</th>\n",
       "      <td>-0.028213</td>\n",
       "      <td>0.171599</td>\n",
       "      <td>0.746656</td>\n",
       "      <td>0.567003</td>\n",
       "      <td>0.414382</td>\n",
       "      <td>0.355522</td>\n",
       "      <td>-0.720076</td>\n",
       "      <td>0.761638</td>\n",
       "      <td>-0.304454</td>\n",
       "      <td>0.761303</td>\n",
       "      <td>0.035453</td>\n",
       "      <td>0.037150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.190259</td>\n",
       "      <td>-0.195173</td>\n",
       "      <td>0.550703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist_to_capital</th>\n",
       "      <td>0.019710</td>\n",
       "      <td>-0.030484</td>\n",
       "      <td>-0.147007</td>\n",
       "      <td>-0.186747</td>\n",
       "      <td>-0.166710</td>\n",
       "      <td>-0.167433</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>-0.162155</td>\n",
       "      <td>-0.055470</td>\n",
       "      <td>-0.214692</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.049984</td>\n",
       "      <td>-0.190259</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.192835</td>\n",
       "      <td>-0.235850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist_to_shoreline</th>\n",
       "      <td>-0.015886</td>\n",
       "      <td>-0.152016</td>\n",
       "      <td>-0.186005</td>\n",
       "      <td>-0.151022</td>\n",
       "      <td>-0.142295</td>\n",
       "      <td>-0.088179</td>\n",
       "      <td>0.230617</td>\n",
       "      <td>-0.164513</td>\n",
       "      <td>0.281731</td>\n",
       "      <td>-0.214850</td>\n",
       "      <td>0.060882</td>\n",
       "      <td>-0.007002</td>\n",
       "      <td>-0.195173</td>\n",
       "      <td>0.192835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.321828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>0.115014</td>\n",
       "      <td>0.182816</td>\n",
       "      <td>0.450119</td>\n",
       "      <td>0.500753</td>\n",
       "      <td>0.425059</td>\n",
       "      <td>0.429262</td>\n",
       "      <td>-0.580670</td>\n",
       "      <td>0.525206</td>\n",
       "      <td>-0.253550</td>\n",
       "      <td>0.666768</td>\n",
       "      <td>0.017210</td>\n",
       "      <td>0.066462</td>\n",
       "      <td>0.550703</td>\n",
       "      <td>-0.235850</td>\n",
       "      <td>-0.321828</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             year  ghsl_water_surface  \\\n",
       "year                                     1.000000           -0.012947   \n",
       "ghsl_water_surface                      -0.012947            1.000000   \n",
       "ghsl_built_pre_1975                     -0.083721            0.197961   \n",
       "ghsl_built_1975_to_1990                 -0.038382            0.110012   \n",
       "ghsl_built_1990_to_2000                 -0.018690            0.040389   \n",
       "ghsl_built_2000_to_2014                  0.017530            0.034900   \n",
       "ghsl_not_built_up                        0.057279           -0.533573   \n",
       "ghsl_pop_density                        -0.048618            0.137382   \n",
       "landcover_crops_fraction                 0.082205           -0.221121   \n",
       "landcover_urban_fraction                -0.055750            0.246438   \n",
       "landcover_water_permanent_10km_fraction  0.034326            0.639638   \n",
       "landcover_water_seasonal_10km_fraction  -0.054697            0.185985   \n",
       "nighttime_lights                        -0.028213            0.171599   \n",
       "dist_to_capital                          0.019710           -0.030484   \n",
       "dist_to_shoreline                       -0.015886           -0.152016   \n",
       "Target                                   0.115014            0.182816   \n",
       "\n",
       "                                         ghsl_built_pre_1975  \\\n",
       "year                                               -0.083721   \n",
       "ghsl_water_surface                                  0.197961   \n",
       "ghsl_built_pre_1975                                 1.000000   \n",
       "ghsl_built_1975_to_1990                             0.474982   \n",
       "ghsl_built_1990_to_2000                             0.464407   \n",
       "ghsl_built_2000_to_2014                             0.281641   \n",
       "ghsl_not_built_up                                  -0.821521   \n",
       "ghsl_pop_density                                    0.816594   \n",
       "landcover_crops_fraction                           -0.337366   \n",
       "landcover_urban_fraction                            0.804210   \n",
       "landcover_water_permanent_10km_fraction             0.079085   \n",
       "landcover_water_seasonal_10km_fraction              0.053655   \n",
       "nighttime_lights                                    0.746656   \n",
       "dist_to_capital                                    -0.147007   \n",
       "dist_to_shoreline                                  -0.186005   \n",
       "Target                                              0.450119   \n",
       "\n",
       "                                         ghsl_built_1975_to_1990  \\\n",
       "year                                                   -0.038382   \n",
       "ghsl_water_surface                                      0.110012   \n",
       "ghsl_built_pre_1975                                     0.474982   \n",
       "ghsl_built_1975_to_1990                                 1.000000   \n",
       "ghsl_built_1990_to_2000                                 0.451552   \n",
       "ghsl_built_2000_to_2014                                 0.445210   \n",
       "ghsl_not_built_up                                      -0.713104   \n",
       "ghsl_pop_density                                        0.658810   \n",
       "landcover_crops_fraction                               -0.298848   \n",
       "landcover_urban_fraction                                0.750170   \n",
       "landcover_water_permanent_10km_fraction                 0.042565   \n",
       "landcover_water_seasonal_10km_fraction                  0.070884   \n",
       "nighttime_lights                                        0.567003   \n",
       "dist_to_capital                                        -0.186747   \n",
       "dist_to_shoreline                                      -0.151022   \n",
       "Target                                                  0.500753   \n",
       "\n",
       "                                         ghsl_built_1990_to_2000  \\\n",
       "year                                                   -0.018690   \n",
       "ghsl_water_surface                                      0.040389   \n",
       "ghsl_built_pre_1975                                     0.464407   \n",
       "ghsl_built_1975_to_1990                                 0.451552   \n",
       "ghsl_built_1990_to_2000                                 1.000000   \n",
       "ghsl_built_2000_to_2014                                 0.574375   \n",
       "ghsl_not_built_up                                      -0.614719   \n",
       "ghsl_pop_density                                        0.507582   \n",
       "landcover_crops_fraction                               -0.257735   \n",
       "landcover_urban_fraction                                0.638640   \n",
       "landcover_water_permanent_10km_fraction                 0.017545   \n",
       "landcover_water_seasonal_10km_fraction                  0.017371   \n",
       "nighttime_lights                                        0.414382   \n",
       "dist_to_capital                                        -0.166710   \n",
       "dist_to_shoreline                                      -0.142295   \n",
       "Target                                                  0.425059   \n",
       "\n",
       "                                         ghsl_built_2000_to_2014  \\\n",
       "year                                                    0.017530   \n",
       "ghsl_water_surface                                      0.034900   \n",
       "ghsl_built_pre_1975                                     0.281641   \n",
       "ghsl_built_1975_to_1990                                 0.445210   \n",
       "ghsl_built_1990_to_2000                                 0.574375   \n",
       "ghsl_built_2000_to_2014                                 1.000000   \n",
       "ghsl_not_built_up                                      -0.531842   \n",
       "ghsl_pop_density                                        0.416470   \n",
       "landcover_crops_fraction                               -0.226773   \n",
       "landcover_urban_fraction                                0.587058   \n",
       "landcover_water_permanent_10km_fraction                 0.003370   \n",
       "landcover_water_seasonal_10km_fraction                  0.023246   \n",
       "nighttime_lights                                        0.355522   \n",
       "dist_to_capital                                        -0.167433   \n",
       "dist_to_shoreline                                      -0.088179   \n",
       "Target                                                  0.429262   \n",
       "\n",
       "                                         ghsl_not_built_up  ghsl_pop_density  \\\n",
       "year                                              0.057279         -0.048618   \n",
       "ghsl_water_surface                               -0.533573          0.137382   \n",
       "ghsl_built_pre_1975                              -0.821521          0.816594   \n",
       "ghsl_built_1975_to_1990                          -0.713104          0.658810   \n",
       "ghsl_built_1990_to_2000                          -0.614719          0.507582   \n",
       "ghsl_built_2000_to_2014                          -0.531842          0.416470   \n",
       "ghsl_not_built_up                                 1.000000         -0.791663   \n",
       "ghsl_pop_density                                 -0.791663          1.000000   \n",
       "landcover_crops_fraction                          0.415382         -0.323615   \n",
       "landcover_urban_fraction                         -0.902559          0.860147   \n",
       "landcover_water_permanent_10km_fraction          -0.305384          0.044945   \n",
       "landcover_water_seasonal_10km_fraction           -0.126775          0.038811   \n",
       "nighttime_lights                                 -0.720076          0.761638   \n",
       "dist_to_capital                                   0.191176         -0.162155   \n",
       "dist_to_shoreline                                 0.230617         -0.164513   \n",
       "Target                                           -0.580670          0.525206   \n",
       "\n",
       "                                         landcover_crops_fraction  \\\n",
       "year                                                     0.082205   \n",
       "ghsl_water_surface                                      -0.221121   \n",
       "ghsl_built_pre_1975                                     -0.337366   \n",
       "ghsl_built_1975_to_1990                                 -0.298848   \n",
       "ghsl_built_1990_to_2000                                 -0.257735   \n",
       "ghsl_built_2000_to_2014                                 -0.226773   \n",
       "ghsl_not_built_up                                        0.415382   \n",
       "ghsl_pop_density                                        -0.323615   \n",
       "landcover_crops_fraction                                 1.000000   \n",
       "landcover_urban_fraction                                -0.377178   \n",
       "landcover_water_permanent_10km_fraction                 -0.112033   \n",
       "landcover_water_seasonal_10km_fraction                  -0.096018   \n",
       "nighttime_lights                                        -0.304454   \n",
       "dist_to_capital                                         -0.055470   \n",
       "dist_to_shoreline                                        0.281731   \n",
       "Target                                                  -0.253550   \n",
       "\n",
       "                                         landcover_urban_fraction  \\\n",
       "year                                                    -0.055750   \n",
       "ghsl_water_surface                                       0.246438   \n",
       "ghsl_built_pre_1975                                      0.804210   \n",
       "ghsl_built_1975_to_1990                                  0.750170   \n",
       "ghsl_built_1990_to_2000                                  0.638640   \n",
       "ghsl_built_2000_to_2014                                  0.587058   \n",
       "ghsl_not_built_up                                       -0.902559   \n",
       "ghsl_pop_density                                         0.860147   \n",
       "landcover_crops_fraction                                -0.377178   \n",
       "landcover_urban_fraction                                 1.000000   \n",
       "landcover_water_permanent_10km_fraction                  0.059166   \n",
       "landcover_water_seasonal_10km_fraction                   0.066508   \n",
       "nighttime_lights                                         0.761303   \n",
       "dist_to_capital                                         -0.214692   \n",
       "dist_to_shoreline                                       -0.214850   \n",
       "Target                                                   0.666768   \n",
       "\n",
       "                                         landcover_water_permanent_10km_fraction  \\\n",
       "year                                                                    0.034326   \n",
       "ghsl_water_surface                                                      0.639638   \n",
       "ghsl_built_pre_1975                                                     0.079085   \n",
       "ghsl_built_1975_to_1990                                                 0.042565   \n",
       "ghsl_built_1990_to_2000                                                 0.017545   \n",
       "ghsl_built_2000_to_2014                                                 0.003370   \n",
       "ghsl_not_built_up                                                      -0.305384   \n",
       "ghsl_pop_density                                                        0.044945   \n",
       "landcover_crops_fraction                                               -0.112033   \n",
       "landcover_urban_fraction                                                0.059166   \n",
       "landcover_water_permanent_10km_fraction                                 1.000000   \n",
       "landcover_water_seasonal_10km_fraction                                  0.110541   \n",
       "nighttime_lights                                                        0.035453   \n",
       "dist_to_capital                                                         0.001938   \n",
       "dist_to_shoreline                                                       0.060882   \n",
       "Target                                                                  0.017210   \n",
       "\n",
       "                                         landcover_water_seasonal_10km_fraction  \\\n",
       "year                                                                  -0.054697   \n",
       "ghsl_water_surface                                                     0.185985   \n",
       "ghsl_built_pre_1975                                                    0.053655   \n",
       "ghsl_built_1975_to_1990                                                0.070884   \n",
       "ghsl_built_1990_to_2000                                                0.017371   \n",
       "ghsl_built_2000_to_2014                                                0.023246   \n",
       "ghsl_not_built_up                                                     -0.126775   \n",
       "ghsl_pop_density                                                       0.038811   \n",
       "landcover_crops_fraction                                              -0.096018   \n",
       "landcover_urban_fraction                                               0.066508   \n",
       "landcover_water_permanent_10km_fraction                                0.110541   \n",
       "landcover_water_seasonal_10km_fraction                                 1.000000   \n",
       "nighttime_lights                                                       0.037150   \n",
       "dist_to_capital                                                        0.049984   \n",
       "dist_to_shoreline                                                     -0.007002   \n",
       "Target                                                                 0.066462   \n",
       "\n",
       "                                         nighttime_lights  dist_to_capital  \\\n",
       "year                                            -0.028213         0.019710   \n",
       "ghsl_water_surface                               0.171599        -0.030484   \n",
       "ghsl_built_pre_1975                              0.746656        -0.147007   \n",
       "ghsl_built_1975_to_1990                          0.567003        -0.186747   \n",
       "ghsl_built_1990_to_2000                          0.414382        -0.166710   \n",
       "ghsl_built_2000_to_2014                          0.355522        -0.167433   \n",
       "ghsl_not_built_up                               -0.720076         0.191176   \n",
       "ghsl_pop_density                                 0.761638        -0.162155   \n",
       "landcover_crops_fraction                        -0.304454        -0.055470   \n",
       "landcover_urban_fraction                         0.761303        -0.214692   \n",
       "landcover_water_permanent_10km_fraction          0.035453         0.001938   \n",
       "landcover_water_seasonal_10km_fraction           0.037150         0.049984   \n",
       "nighttime_lights                                 1.000000        -0.190259   \n",
       "dist_to_capital                                 -0.190259         1.000000   \n",
       "dist_to_shoreline                               -0.195173         0.192835   \n",
       "Target                                           0.550703        -0.235850   \n",
       "\n",
       "                                         dist_to_shoreline    Target  \n",
       "year                                             -0.015886  0.115014  \n",
       "ghsl_water_surface                               -0.152016  0.182816  \n",
       "ghsl_built_pre_1975                              -0.186005  0.450119  \n",
       "ghsl_built_1975_to_1990                          -0.151022  0.500753  \n",
       "ghsl_built_1990_to_2000                          -0.142295  0.425059  \n",
       "ghsl_built_2000_to_2014                          -0.088179  0.429262  \n",
       "ghsl_not_built_up                                 0.230617 -0.580670  \n",
       "ghsl_pop_density                                 -0.164513  0.525206  \n",
       "landcover_crops_fraction                          0.281731 -0.253550  \n",
       "landcover_urban_fraction                         -0.214850  0.666768  \n",
       "landcover_water_permanent_10km_fraction           0.060882  0.017210  \n",
       "landcover_water_seasonal_10km_fraction           -0.007002  0.066462  \n",
       "nighttime_lights                                 -0.195173  0.550703  \n",
       "dist_to_capital                                   0.192835 -0.235850  \n",
       "dist_to_shoreline                                 1.000000 -0.321828  \n",
       "Target                                           -0.321828  1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000    11051\n",
       "0.301812       45\n",
       "0.020879       10\n",
       "0.023733        9\n",
       "0.040677        7\n",
       "            ...  \n",
       "0.035938        1\n",
       "0.011718        1\n",
       "0.000409        1\n",
       "0.000222        1\n",
       "0.000017        1\n",
       "Name: ghsl_built_pre_1975, Length: 17431, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data['ghsl_built_pre_1975'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Too many zeros, drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000    22466\n",
       "0.090618       45\n",
       "0.098464        6\n",
       "0.010934        5\n",
       "0.019959        5\n",
       "            ...  \n",
       "0.000019        1\n",
       "0.000036        1\n",
       "0.159987        1\n",
       "0.016689        1\n",
       "0.611528        1\n",
       "Name: ghsl_water_surface, Length: 6114, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data['ghsl_water_surface'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000     14027\n",
       "12.697095       45\n",
       "0.686495        10\n",
       "1.581286         9\n",
       "2.148200         7\n",
       "             ...  \n",
       "0.275404         1\n",
       "1.729917         1\n",
       "0.229549         1\n",
       "53.345961        1\n",
       "7.173305         1\n",
       "Name: nighttime_lights, Length: 14491, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data['nighttime_lights'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000    13318\n",
       "4.869094       45\n",
       "0.081717       10\n",
       "0.376976        9\n",
       "0.242532        7\n",
       "            ...  \n",
       "0.000579        1\n",
       "0.304364        1\n",
       "0.002604        1\n",
       "5.128968        1\n",
       "0.006292        1\n",
       "Name: landcover_water_permanent_10km_fraction, Length: 15203, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data['landcover_water_permanent_10km_fraction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fin_data.drop(['ghsl_built_pre_1975'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data.drop(['ghsl_water_surface'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 numerical features with Skew > 0.5:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>landcover_water_seasonal_10km_fraction</th>\n",
       "      <td>8.674108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>landcover_water_permanent_10km_fraction</th>\n",
       "      <td>6.798676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nighttime_lights</th>\n",
       "      <td>6.292446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Skew\n",
       "landcover_water_seasonal_10km_fraction   8.674108\n",
       "landcover_water_permanent_10km_fraction  6.798676\n",
       "nighttime_lights                         6.292446"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "numeric = fin_data.select_dtypes(include = 'number').columns\n",
    "skew_features = fin_data[numeric].apply(lambda x: skew(x)).sort_values(ascending = False)\n",
    "\n",
    "from pandas import DataFrame\n",
    "high_skew = skew_features[skew_features > 6]\n",
    "skew_index = high_skew.index\n",
    "print(\"There are {} numerical features with Skew > 0.5:\".format(high_skew.shape[0]))\n",
    "Skewness = pd.DataFrame({'Skew':high_skew})\n",
    "Skewness.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landcover_water_seasonal_10km_fraction\n",
      "landcover_water_permanent_10km_fraction\n",
      "nighttime_lights\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "log = PowerTransformer()\n",
    "for i in Skewness.index:\n",
    "    fin_data[i] = log.fit_transform(fin_data[[i]])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data = pd.get_dummies(fin_data, columns=['urban_or_rural'], drop_first = True)\n",
    "fin_data['year'] = fin_data['year'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>ghsl_built_pre_1975</th>\n",
       "      <th>ghsl_built_1975_to_1990</th>\n",
       "      <th>ghsl_built_1990_to_2000</th>\n",
       "      <th>ghsl_built_2000_to_2014</th>\n",
       "      <th>ghsl_not_built_up</th>\n",
       "      <th>ghsl_pop_density</th>\n",
       "      <th>landcover_crops_fraction</th>\n",
       "      <th>landcover_urban_fraction</th>\n",
       "      <th>landcover_water_permanent_10km_fraction</th>\n",
       "      <th>landcover_water_seasonal_10km_fraction</th>\n",
       "      <th>nighttime_lights</th>\n",
       "      <th>dist_to_capital</th>\n",
       "      <th>dist_to_shoreline</th>\n",
       "      <th>Target</th>\n",
       "      <th>urban_or_rural_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.999408</td>\n",
       "      <td>12.146134</td>\n",
       "      <td>25.489659</td>\n",
       "      <td>0.879484</td>\n",
       "      <td>-0.620288</td>\n",
       "      <td>-0.822731</td>\n",
       "      <td>-0.855979</td>\n",
       "      <td>278.788451</td>\n",
       "      <td>769.338378</td>\n",
       "      <td>0.132783</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.999872</td>\n",
       "      <td>113.806716</td>\n",
       "      <td>64.136053</td>\n",
       "      <td>0.601427</td>\n",
       "      <td>-0.620288</td>\n",
       "      <td>-0.782017</td>\n",
       "      <td>-0.855979</td>\n",
       "      <td>200.986978</td>\n",
       "      <td>337.135243</td>\n",
       "      <td>0.004898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mozambique</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.400096</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>-0.620288</td>\n",
       "      <td>-0.799539</td>\n",
       "      <td>-0.855979</td>\n",
       "      <td>642.594208</td>\n",
       "      <td>169.913773</td>\n",
       "      <td>0.097320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malawi</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.999195</td>\n",
       "      <td>5.213320</td>\n",
       "      <td>25.379371</td>\n",
       "      <td>2.017136</td>\n",
       "      <td>2.138132</td>\n",
       "      <td>-0.028879</td>\n",
       "      <td>-0.855979</td>\n",
       "      <td>365.349451</td>\n",
       "      <td>613.591610</td>\n",
       "      <td>0.304107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Guinea</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.011649</td>\n",
       "      <td>0.017560</td>\n",
       "      <td>0.017383</td>\n",
       "      <td>0.099875</td>\n",
       "      <td>0.853533</td>\n",
       "      <td>31.734661</td>\n",
       "      <td>5.081620</td>\n",
       "      <td>22.815984</td>\n",
       "      <td>-0.585709</td>\n",
       "      <td>-0.031571</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>222.867189</td>\n",
       "      <td>192.926363</td>\n",
       "      <td>0.605328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28643</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.304446</td>\n",
       "      <td>32.263180</td>\n",
       "      <td>0.658724</td>\n",
       "      <td>-0.620288</td>\n",
       "      <td>-0.309046</td>\n",
       "      <td>-0.682316</td>\n",
       "      <td>500.988790</td>\n",
       "      <td>703.139988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28644</th>\n",
       "      <td>Uganda</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.992717</td>\n",
       "      <td>36.160182</td>\n",
       "      <td>27.520555</td>\n",
       "      <td>3.615442</td>\n",
       "      <td>-0.620288</td>\n",
       "      <td>-0.813981</td>\n",
       "      <td>-0.855979</td>\n",
       "      <td>159.587852</td>\n",
       "      <td>1000.194893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28645</th>\n",
       "      <td>Burkina Faso</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.009322</td>\n",
       "      <td>0.042527</td>\n",
       "      <td>0.942399</td>\n",
       "      <td>46.127465</td>\n",
       "      <td>35.674511</td>\n",
       "      <td>12.705561</td>\n",
       "      <td>-0.612497</td>\n",
       "      <td>1.338286</td>\n",
       "      <td>1.012941</td>\n",
       "      <td>33.775441</td>\n",
       "      <td>781.833777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28646</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.999551</td>\n",
       "      <td>0.309696</td>\n",
       "      <td>18.050789</td>\n",
       "      <td>0.030514</td>\n",
       "      <td>-0.403674</td>\n",
       "      <td>0.352797</td>\n",
       "      <td>-0.578246</td>\n",
       "      <td>320.974153</td>\n",
       "      <td>605.920204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28647</th>\n",
       "      <td>Democratic Republic of Congo</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.128367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041799</td>\n",
       "      <td>0.139710</td>\n",
       "      <td>0.613173</td>\n",
       "      <td>162.182887</td>\n",
       "      <td>3.917284</td>\n",
       "      <td>36.528453</td>\n",
       "      <td>2.104426</td>\n",
       "      <td>1.254954</td>\n",
       "      <td>0.958781</td>\n",
       "      <td>1186.131373</td>\n",
       "      <td>1456.101058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28648 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            country  year  ghsl_built_pre_1975  \\\n",
       "0                          Ethiopia  2016             0.000000   \n",
       "1                          Ethiopia  2005             0.000000   \n",
       "2                        Mozambique  2009             0.000000   \n",
       "3                            Malawi  2015             0.000141   \n",
       "4                            Guinea  2012             0.011649   \n",
       "...                             ...   ...                  ...   \n",
       "28643                      Zimbabwe  2010             0.000000   \n",
       "28644                        Uganda  2011             0.000056   \n",
       "28645                  Burkina Faso  2010             0.000268   \n",
       "28646                      Zimbabwe  2011             0.000000   \n",
       "28647  Democratic Republic of Congo  2007             0.128367   \n",
       "\n",
       "       ghsl_built_1975_to_1990  ghsl_built_1990_to_2000  \\\n",
       "0                     0.000000                 0.000055   \n",
       "1                     0.000110                 0.000000   \n",
       "2                     0.000000                 0.000000   \n",
       "3                     0.000181                 0.000254   \n",
       "4                     0.017560                 0.017383   \n",
       "...                        ...                      ...   \n",
       "28643                 0.000000                 0.000016   \n",
       "28644                 0.000883                 0.003861   \n",
       "28645                 0.002800                 0.009322   \n",
       "28646                 0.000017                 0.000000   \n",
       "28647                 0.000000                 0.041799   \n",
       "\n",
       "       ghsl_built_2000_to_2014  ghsl_not_built_up  ghsl_pop_density  \\\n",
       "0                     0.000536           0.999408         12.146134   \n",
       "1                     0.000018           0.999872        113.806716   \n",
       "2                     0.000000           1.000000          0.000000   \n",
       "3                     0.000228           0.999195          5.213320   \n",
       "4                     0.099875           0.853533         31.734661   \n",
       "...                        ...                ...               ...   \n",
       "28643                 0.000131           0.999853          0.304446   \n",
       "28644                 0.002483           0.992717         36.160182   \n",
       "28645                 0.042527           0.942399         46.127465   \n",
       "28646                 0.000100           0.999551          0.309696   \n",
       "28647                 0.139710           0.613173        162.182887   \n",
       "\n",
       "       landcover_crops_fraction  landcover_urban_fraction  \\\n",
       "0                     25.489659                  0.879484   \n",
       "1                     64.136053                  0.601427   \n",
       "2                      4.400096                  0.131900   \n",
       "3                     25.379371                  2.017136   \n",
       "4                      5.081620                 22.815984   \n",
       "...                         ...                       ...   \n",
       "28643                 32.263180                  0.658724   \n",
       "28644                 27.520555                  3.615442   \n",
       "28645                 35.674511                 12.705561   \n",
       "28646                 18.050789                  0.030514   \n",
       "28647                  3.917284                 36.528453   \n",
       "\n",
       "       landcover_water_permanent_10km_fraction  \\\n",
       "0                                    -0.620288   \n",
       "1                                    -0.620288   \n",
       "2                                    -0.620288   \n",
       "3                                     2.138132   \n",
       "4                                    -0.585709   \n",
       "...                                        ...   \n",
       "28643                                -0.620288   \n",
       "28644                                -0.620288   \n",
       "28645                                -0.612497   \n",
       "28646                                -0.403674   \n",
       "28647                                 2.104426   \n",
       "\n",
       "       landcover_water_seasonal_10km_fraction  nighttime_lights  \\\n",
       "0                                   -0.822731         -0.855979   \n",
       "1                                   -0.782017         -0.855979   \n",
       "2                                   -0.799539         -0.855979   \n",
       "3                                   -0.028879         -0.855979   \n",
       "4                                   -0.031571          0.372093   \n",
       "...                                       ...               ...   \n",
       "28643                               -0.309046         -0.682316   \n",
       "28644                               -0.813981         -0.855979   \n",
       "28645                                1.338286          1.012941   \n",
       "28646                                0.352797         -0.578246   \n",
       "28647                                1.254954          0.958781   \n",
       "\n",
       "       dist_to_capital  dist_to_shoreline    Target  urban_or_rural_U  \n",
       "0           278.788451         769.338378  0.132783                 0  \n",
       "1           200.986978         337.135243  0.004898                 0  \n",
       "2           642.594208         169.913773  0.097320                 0  \n",
       "3           365.349451         613.591610  0.304107                 0  \n",
       "4           222.867189         192.926363  0.605328                 1  \n",
       "...                ...                ...       ...               ...  \n",
       "28643       500.988790         703.139988       NaN                 0  \n",
       "28644       159.587852        1000.194893       NaN                 1  \n",
       "28645        33.775441         781.833777       NaN                 1  \n",
       "28646       320.974153         605.920204       NaN                 0  \n",
       "28647      1186.131373        1456.101058       NaN                 1  \n",
       "\n",
       "[28648 rows x 17 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data['dist_to_capital'] = fin_data['dist_to_capital'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler,StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "#scaler = StandardScaler()\n",
    "#fin_data['dist_to_shoreline'] = pd.DataFrame(scaler.fit_transform(fin_data['dist_to_shoreline'].values.reshape(-1,1)))\n",
    "#fin_data['dist_to_capital'] = pd.DataFrame(scaler.fit_transform(fin_data['dist_to_capital'].values.reshape(-1,1)))\n",
    "\n",
    "for i in fin_data.drop(['country','year'], axis=1).columns:\n",
    "    fin_data[i] = pd.DataFrame(scaler.fit_transform(fin_data[i].values.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mean_target_encoding(train, test, target, categorical, alpha=5):\n",
    "    # Calculate global mean on the train data\n",
    "    global_mean = train[target].mean()\n",
    "    \n",
    "    # Group by the categorical feature and calculate its properties\n",
    "    train_groups = train.groupby(categorical)\n",
    "    category_sum = train_groups[target].sum()\n",
    "    category_size = train_groups.size()\n",
    "    \n",
    "    # Calculate smoothed mean target statistics\n",
    "    train_statistics = (category_sum + global_mean * alpha) / (category_size + alpha)\n",
    "    \n",
    "    # Apply statistics to the test data and fill new categories\n",
    "    test_feature = test[categorical].map(train_statistics).fillna(global_mean)\n",
    "    return test_feature.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mean_target_encoding(train, target, categorical, alpha=5):\n",
    "    # Create 5-fold cross-validation\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state=99)\n",
    "    train_feature = pd.Series(index=train.index)\n",
    "    \n",
    "    # For each folds split\n",
    "    for train_index, test_index in kf.split(train):\n",
    "        cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]\n",
    "      \n",
    "        # Calculate out-of-fold statistics and apply to cv_test\n",
    "        cv_test_feature = test_mean_target_encoding(cv_train, cv_test, target, categorical, alpha)\n",
    "        \n",
    "        # Save new feature for this particular fold\n",
    "        train_feature.iloc[test_index] = cv_test_feature       \n",
    "    return train_feature.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_target_encoding(train, test, target, categorical, alpha=5):\n",
    "  \n",
    "    # Get the train feature\n",
    "    train_feature = train_mean_target_encoding(train, target, categorical, alpha)\n",
    "  \n",
    "    # Get the test feature\n",
    "    test_feature = test_mean_target_encoding(train, test, target, categorical, alpha)\n",
    "    \n",
    "    # Return new features to add to the model\n",
    "    return train_feature, test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state=99)\n",
    "split=ttrain.shape[0]\n",
    "train_df=fin_data[:split]\n",
    "test_df=fin_data[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train_feat, test_feat = mean_target_encoding(train_df, test_df, 'Target', 'country', alpha=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_df['country'] = train_feat\n",
    "test_df['country'] = test_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train_feat, test_feat = mean_target_encoding(train_df, test_df, 'Target', 'year', alpha=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_df['year'] = train_feat\n",
    "test_df['year'] = test_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import warnings\n",
    "\n",
    "from scipy.stats import sem\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['Target'],axis =1)\n",
    "y = train_df['Target']\n",
    "train_labels = y\n",
    "\n",
    "test_df = test_df.drop(['Target'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.1849337\ttest: 0.1865800\tbest: 0.1865800 (0)\ttotal: 92.5ms\tremaining: 6m 9s\n",
      "200:\tlearn: 0.0790287\ttest: 0.0885581\tbest: 0.0885581 (200)\ttotal: 12.3s\tremaining: 3m 52s\n",
      "400:\tlearn: 0.0705442\ttest: 0.0868875\tbest: 0.0868834 (399)\ttotal: 23.9s\tremaining: 3m 34s\n",
      "600:\tlearn: 0.0645392\ttest: 0.0858787\tbest: 0.0858760 (598)\ttotal: 35.4s\tremaining: 3m 20s\n",
      "800:\tlearn: 0.0594231\ttest: 0.0857412\tbest: 0.0856489 (635)\ttotal: 47.2s\tremaining: 3m 8s\n",
      "1000:\tlearn: 0.0551840\ttest: 0.0855220\tbest: 0.0854569 (947)\ttotal: 58.7s\tremaining: 2m 55s\n",
      "1200:\tlearn: 0.0516340\ttest: 0.0851583\tbest: 0.0851583 (1200)\ttotal: 1m 10s\tremaining: 2m 44s\n",
      "1400:\tlearn: 0.0485375\ttest: 0.0849381\tbest: 0.0848844 (1342)\ttotal: 1m 22s\tremaining: 2m 32s\n",
      "1600:\tlearn: 0.0457683\ttest: 0.0849375\tbest: 0.0848649 (1453)\ttotal: 1m 34s\tremaining: 2m 21s\n",
      "1800:\tlearn: 0.0432775\ttest: 0.0847430\tbest: 0.0847293 (1796)\ttotal: 1m 46s\tremaining: 2m 9s\n",
      "2000:\tlearn: 0.0411158\ttest: 0.0849389\tbest: 0.0847293 (1796)\ttotal: 1m 58s\tremaining: 1m 58s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08472934898\n",
      "bestIteration = 1796\n",
      "\n",
      "Shrink model to first 1797 iterations.\n",
      "0.010591168649064488\n",
      "0:\tlearn: 0.1849672\ttest: 0.1861167\tbest: 0.1861167 (0)\ttotal: 82.3ms\tremaining: 5m 29s\n",
      "200:\tlearn: 0.0793579\ttest: 0.0822749\tbest: 0.0822749 (200)\ttotal: 12s\tremaining: 3m 47s\n",
      "400:\tlearn: 0.0706229\ttest: 0.0807448\tbest: 0.0807422 (393)\ttotal: 23.7s\tremaining: 3m 32s\n",
      "600:\tlearn: 0.0643812\ttest: 0.0802760\tbest: 0.0802304 (592)\ttotal: 34.9s\tremaining: 3m 17s\n",
      "800:\tlearn: 0.0594445\ttest: 0.0801279\tbest: 0.0800928 (777)\ttotal: 46.6s\tremaining: 3m 6s\n",
      "1000:\tlearn: 0.0554050\ttest: 0.0802026\tbest: 0.0800928 (777)\ttotal: 58.3s\tremaining: 2m 54s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08009276146\n",
      "bestIteration = 777\n",
      "\n",
      "Shrink model to first 778 iterations.\n",
      "0.02060276380598159\n",
      "0:\tlearn: 0.1846145\ttest: 0.1939062\tbest: 0.1939062 (0)\ttotal: 87.4ms\tremaining: 5m 49s\n",
      "200:\tlearn: 0.0788832\ttest: 0.0909327\tbest: 0.0908974 (197)\ttotal: 12.4s\tremaining: 3m 53s\n",
      "400:\tlearn: 0.0701941\ttest: 0.0894290\tbest: 0.0893996 (392)\ttotal: 25.3s\tremaining: 3m 46s\n",
      "600:\tlearn: 0.0643955\ttest: 0.0892141\tbest: 0.0891657 (590)\ttotal: 37.9s\tremaining: 3m 34s\n",
      "800:\tlearn: 0.0594026\ttest: 0.0895127\tbest: 0.0891657 (590)\ttotal: 50.5s\tremaining: 3m 21s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08916573847\n",
      "bestIteration = 590\n",
      "\n",
      "Shrink model to first 591 iterations.\n",
      "0.03174848102579897\n",
      "0:\tlearn: 0.1848804\ttest: 0.1874622\tbest: 0.1874622 (0)\ttotal: 39.7ms\tremaining: 2m 38s\n",
      "200:\tlearn: 0.0790298\ttest: 0.0876793\tbest: 0.0876793 (200)\ttotal: 11.6s\tremaining: 3m 39s\n",
      "400:\tlearn: 0.0704782\ttest: 0.0858223\tbest: 0.0857845 (392)\ttotal: 23.6s\tremaining: 3m 31s\n",
      "600:\tlearn: 0.0643259\ttest: 0.0855612\tbest: 0.0855355 (567)\ttotal: 35s\tremaining: 3m 18s\n",
      "800:\tlearn: 0.0593431\ttest: 0.0852938\tbest: 0.0852590 (794)\ttotal: 46.9s\tremaining: 3m 7s\n",
      "1000:\tlearn: 0.0551289\ttest: 0.0851035\tbest: 0.0850868 (998)\ttotal: 58.5s\tremaining: 2m 55s\n",
      "1200:\tlearn: 0.0515706\ttest: 0.0851346\tbest: 0.0850868 (998)\ttotal: 1m 10s\tremaining: 2m 43s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08508683583\n",
      "bestIteration = 998\n",
      "\n",
      "Shrink model to first 999 iterations.\n",
      "0.0423843354270637\n",
      "0:\tlearn: 0.1847559\ttest: 0.1926679\tbest: 0.1926679 (0)\ttotal: 62.8ms\tremaining: 4m 11s\n",
      "200:\tlearn: 0.0785124\ttest: 0.0929838\tbest: 0.0929838 (200)\ttotal: 13s\tremaining: 4m 5s\n",
      "400:\tlearn: 0.0704817\ttest: 0.0918458\tbest: 0.0918207 (397)\ttotal: 24.7s\tremaining: 3m 41s\n",
      "600:\tlearn: 0.0640976\ttest: 0.0916806\tbest: 0.0916141 (471)\ttotal: 36.4s\tremaining: 3m 25s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.09161411429\n",
      "bestIteration = 471\n",
      "\n",
      "Shrink model to first 472 iterations.\n",
      "0.05383609959784788\n",
      "0:\tlearn: 0.1849663\ttest: 0.1848177\tbest: 0.1848177 (0)\ttotal: 67.6ms\tremaining: 4m 30s\n",
      "200:\tlearn: 0.0790344\ttest: 0.0889373\tbest: 0.0889373 (200)\ttotal: 12.2s\tremaining: 3m 50s\n",
      "400:\tlearn: 0.0705716\ttest: 0.0874801\tbest: 0.0874801 (400)\ttotal: 24.1s\tremaining: 3m 35s\n",
      "600:\tlearn: 0.0645910\ttest: 0.0865869\tbest: 0.0865609 (592)\ttotal: 36.1s\tremaining: 3m 23s\n",
      "800:\tlearn: 0.0596569\ttest: 0.0864447\tbest: 0.0864351 (791)\ttotal: 47.7s\tremaining: 3m 10s\n",
      "1000:\tlearn: 0.0556620\ttest: 0.0864000\tbest: 0.0863619 (975)\ttotal: 59.3s\tremaining: 2m 57s\n",
      "1200:\tlearn: 0.0521332\ttest: 0.0863878\tbest: 0.0863573 (1091)\ttotal: 1m 10s\tremaining: 2m 44s\n",
      "1400:\tlearn: 0.0488930\ttest: 0.0863223\tbest: 0.0862738 (1360)\ttotal: 1m 22s\tremaining: 2m 32s\n",
      "1600:\tlearn: 0.0461349\ttest: 0.0863845\tbest: 0.0862738 (1360)\ttotal: 1m 36s\tremaining: 2m 24s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08627377461\n",
      "bestIteration = 1360\n",
      "\n",
      "Shrink model to first 1361 iterations.\n",
      "0.06462032148863424\n",
      "0:\tlearn: 0.1848991\ttest: 0.1881676\tbest: 0.1881676 (0)\ttotal: 133ms\tremaining: 8m 51s\n",
      "200:\tlearn: 0.0792342\ttest: 0.0858766\tbest: 0.0858714 (199)\ttotal: 11.8s\tremaining: 3m 42s\n",
      "400:\tlearn: 0.0708559\ttest: 0.0845749\tbest: 0.0845720 (399)\ttotal: 23.9s\tremaining: 3m 34s\n",
      "600:\tlearn: 0.0648152\ttest: 0.0842417\tbest: 0.0842408 (599)\ttotal: 35.8s\tremaining: 3m 22s\n",
      "800:\tlearn: 0.0597860\ttest: 0.0837967\tbest: 0.0837558 (788)\ttotal: 47.3s\tremaining: 3m 9s\n",
      "1000:\tlearn: 0.0555915\ttest: 0.0837015\tbest: 0.0836609 (898)\ttotal: 59.6s\tremaining: 2m 58s\n",
      "1200:\tlearn: 0.0520045\ttest: 0.0837421\tbest: 0.0836117 (1050)\ttotal: 1m 11s\tremaining: 2m 46s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08361169778\n",
      "bestIteration = 1050\n",
      "\n",
      "Shrink model to first 1051 iterations.\n",
      "0.07507178372575213\n",
      "0:\tlearn: 0.1849538\ttest: 0.1886207\tbest: 0.1886207 (0)\ttotal: 69.8ms\tremaining: 4m 38s\n",
      "200:\tlearn: 0.0789381\ttest: 0.0878139\tbest: 0.0878032 (196)\ttotal: 11.5s\tremaining: 3m 37s\n",
      "400:\tlearn: 0.0706148\ttest: 0.0864515\tbest: 0.0864415 (399)\ttotal: 23.2s\tremaining: 3m 28s\n",
      "600:\tlearn: 0.0645326\ttest: 0.0860135\tbest: 0.0859568 (588)\ttotal: 34.6s\tremaining: 3m 15s\n",
      "800:\tlearn: 0.0595736\ttest: 0.0857346\tbest: 0.0857346 (800)\ttotal: 46.7s\tremaining: 3m 6s\n",
      "1000:\tlearn: 0.0555579\ttest: 0.0862512\tbest: 0.0857327 (801)\ttotal: 58.8s\tremaining: 2m 56s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08573272591\n",
      "bestIteration = 801\n",
      "\n",
      "Shrink model to first 802 iterations.\n",
      "0.08578837442132087\n",
      "0:\tlearn: 0.1852456\ttest: 0.1804112\tbest: 0.1804112 (0)\ttotal: 82.7ms\tremaining: 5m 30s\n",
      "200:\tlearn: 0.0788326\ttest: 0.0890292\tbest: 0.0890292 (200)\ttotal: 11.4s\tremaining: 3m 35s\n",
      "400:\tlearn: 0.0706625\ttest: 0.0877492\tbest: 0.0877005 (376)\ttotal: 22.7s\tremaining: 3m 23s\n",
      "600:\tlearn: 0.0646014\ttest: 0.0877686\tbest: 0.0876318 (520)\ttotal: 34.3s\tremaining: 3m 14s\n",
      "800:\tlearn: 0.0595725\ttest: 0.0878758\tbest: 0.0876318 (520)\ttotal: 46.3s\tremaining: 3m 4s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08763179855\n",
      "bestIteration = 520\n",
      "\n",
      "Shrink model to first 521 iterations.\n",
      "0.0967423491409751\n",
      "0:\tlearn: 0.1851816\ttest: 0.1820001\tbest: 0.1820001 (0)\ttotal: 69.7ms\tremaining: 4m 38s\n",
      "200:\tlearn: 0.0792737\ttest: 0.0858313\tbest: 0.0858313 (200)\ttotal: 12.1s\tremaining: 3m 48s\n",
      "400:\tlearn: 0.0709130\ttest: 0.0833458\tbest: 0.0833458 (400)\ttotal: 23.6s\tremaining: 3m 31s\n",
      "600:\tlearn: 0.0649529\ttest: 0.0827877\tbest: 0.0827791 (590)\ttotal: 35.4s\tremaining: 3m 19s\n",
      "800:\tlearn: 0.0598872\ttest: 0.0823467\tbest: 0.0822759 (786)\ttotal: 47.4s\tremaining: 3m 9s\n",
      "1000:\tlearn: 0.0557087\ttest: 0.0821719\tbest: 0.0821719 (1000)\ttotal: 60s\tremaining: 2m 59s\n",
      "1200:\tlearn: 0.0521593\ttest: 0.0820818\tbest: 0.0820185 (1169)\ttotal: 1m 13s\tremaining: 2m 50s\n",
      "1400:\tlearn: 0.0489453\ttest: 0.0822092\tbest: 0.0820185 (1169)\ttotal: 1m 26s\tremaining: 2m 40s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08201846055\n",
      "bestIteration = 1169\n",
      "\n",
      "Shrink model to first 1170 iterations.\n",
      "0.10699465673999842\n",
      "0:\tlearn: 0.1852026\ttest: 0.1821770\tbest: 0.1821770 (0)\ttotal: 47.2ms\tremaining: 3m 8s\n",
      "200:\tlearn: 0.0791478\ttest: 0.0881408\tbest: 0.0881408 (200)\ttotal: 13.8s\tremaining: 4m 20s\n",
      "400:\tlearn: 0.0705764\ttest: 0.0867596\tbest: 0.0867334 (370)\ttotal: 26.2s\tremaining: 3m 55s\n",
      "600:\tlearn: 0.0645211\ttest: 0.0866637\tbest: 0.0865029 (576)\ttotal: 38s\tremaining: 3m 35s\n",
      "800:\tlearn: 0.0594116\ttest: 0.0867552\tbest: 0.0865029 (576)\ttotal: 49.9s\tremaining: 3m 19s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.0865029287\n",
      "bestIteration = 576\n",
      "\n",
      "Shrink model to first 577 iterations.\n",
      "0.1178075227905786\n",
      "0:\tlearn: 0.1850668\ttest: 0.1852730\tbest: 0.1852730 (0)\ttotal: 53.6ms\tremaining: 3m 34s\n",
      "200:\tlearn: 0.0790001\ttest: 0.0863291\tbest: 0.0863291 (200)\ttotal: 11.9s\tremaining: 3m 45s\n",
      "400:\tlearn: 0.0706880\ttest: 0.0855534\tbest: 0.0854558 (373)\ttotal: 23.9s\tremaining: 3m 34s\n",
      "600:\tlearn: 0.0646093\ttest: 0.0854192\tbest: 0.0853614 (593)\ttotal: 35.3s\tremaining: 3m 19s\n",
      "800:\tlearn: 0.0595907\ttest: 0.0854903\tbest: 0.0853133 (613)\ttotal: 47.2s\tremaining: 3m 8s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08531332824\n",
      "bestIteration = 613\n",
      "\n",
      "Shrink model to first 614 iterations.\n",
      "0.12847168881762955\n",
      "0:\tlearn: 0.1846692\ttest: 0.1920088\tbest: 0.1920088 (0)\ttotal: 54.5ms\tremaining: 3m 38s\n",
      "200:\tlearn: 0.0786935\ttest: 0.0948170\tbest: 0.0948170 (200)\ttotal: 13.1s\tremaining: 4m 6s\n",
      "400:\tlearn: 0.0701310\ttest: 0.0936642\tbest: 0.0935813 (387)\ttotal: 24.1s\tremaining: 3m 36s\n",
      "600:\tlearn: 0.0638837\ttest: 0.0934638\tbest: 0.0933985 (543)\ttotal: 35.9s\tremaining: 3m 23s\n",
      "800:\tlearn: 0.0589707\ttest: 0.0935903\tbest: 0.0933860 (619)\ttotal: 47.7s\tremaining: 3m 10s\n",
      "1000:\tlearn: 0.0549453\ttest: 0.0932884\tbest: 0.0932278 (962)\ttotal: 59.7s\tremaining: 2m 58s\n",
      "1200:\tlearn: 0.0512677\ttest: 0.0933589\tbest: 0.0931484 (1093)\ttotal: 1m 11s\tremaining: 2m 45s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.09314842158\n",
      "bestIteration = 1093\n",
      "\n",
      "Shrink model to first 1094 iterations.\n",
      "0.14011524157262062\n",
      "0:\tlearn: 0.1850965\ttest: 0.1819078\tbest: 0.1819078 (0)\ttotal: 58.8ms\tremaining: 3m 55s\n",
      "200:\tlearn: 0.0787672\ttest: 0.0922265\tbest: 0.0922218 (199)\ttotal: 11.6s\tremaining: 3m 39s\n",
      "400:\tlearn: 0.0703154\ttest: 0.0913975\tbest: 0.0913639 (396)\ttotal: 22.9s\tremaining: 3m 25s\n",
      "600:\tlearn: 0.0642974\ttest: 0.0912472\tbest: 0.0911811 (595)\ttotal: 37.2s\tremaining: 3m 30s\n",
      "800:\tlearn: 0.0593825\ttest: 0.0914414\tbest: 0.0911811 (595)\ttotal: 48.9s\tremaining: 3m 15s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.09118114301\n",
      "bestIteration = 595\n",
      "\n",
      "Shrink model to first 596 iterations.\n",
      "0.1515128844434557\n",
      "0:\tlearn: 0.1849369\ttest: 0.1860487\tbest: 0.1860487 (0)\ttotal: 59.1ms\tremaining: 3m 56s\n",
      "200:\tlearn: 0.0793338\ttest: 0.0883560\tbest: 0.0883560 (200)\ttotal: 11.7s\tremaining: 3m 40s\n",
      "400:\tlearn: 0.0707158\ttest: 0.0869877\tbest: 0.0869405 (388)\ttotal: 23.3s\tremaining: 3m 28s\n",
      "600:\tlearn: 0.0643931\ttest: 0.0863853\tbest: 0.0863519 (588)\ttotal: 35.1s\tremaining: 3m 18s\n",
      "800:\tlearn: 0.0594359\ttest: 0.0862550\tbest: 0.0862297 (787)\ttotal: 47.1s\tremaining: 3m 7s\n",
      "1000:\tlearn: 0.0553324\ttest: 0.0861190\tbest: 0.0860257 (948)\ttotal: 59s\tremaining: 2m 56s\n",
      "1200:\tlearn: 0.0517938\ttest: 0.0863748\tbest: 0.0860257 (948)\ttotal: 1m 10s\tremaining: 2m 45s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08602573433\n",
      "bestIteration = 948\n",
      "\n",
      "Shrink model to first 949 iterations.\n",
      "0.16226610131793287\n",
      "0:\tlearn: 0.1849618\ttest: 0.1856102\tbest: 0.1856102 (0)\ttotal: 76.2ms\tremaining: 5m 4s\n",
      "200:\tlearn: 0.0790343\ttest: 0.0860681\tbest: 0.0860539 (199)\ttotal: 12s\tremaining: 3m 47s\n",
      "400:\tlearn: 0.0707261\ttest: 0.0849243\tbest: 0.0848285 (387)\ttotal: 23.7s\tremaining: 3m 32s\n",
      "600:\tlearn: 0.0646519\ttest: 0.0843519\tbest: 0.0843519 (600)\ttotal: 35.2s\tremaining: 3m 18s\n",
      "800:\tlearn: 0.0596110\ttest: 0.0845834\tbest: 0.0843519 (600)\ttotal: 46.9s\tremaining: 3m 7s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08435193141\n",
      "bestIteration = 600\n",
      "\n",
      "Shrink model to first 601 iterations.\n",
      "0.17281009279562878\n",
      "0:\tlearn: 0.1850696\ttest: 0.1827113\tbest: 0.1827113 (0)\ttotal: 88ms\tremaining: 5m 52s\n",
      "200:\tlearn: 0.0791174\ttest: 0.0899605\tbest: 0.0899605 (200)\ttotal: 11.6s\tremaining: 3m 39s\n",
      "400:\tlearn: 0.0707133\ttest: 0.0889408\tbest: 0.0888597 (382)\ttotal: 23.4s\tremaining: 3m 29s\n",
      "600:\tlearn: 0.0646395\ttest: 0.0888640\tbest: 0.0887728 (578)\ttotal: 35.4s\tremaining: 3m 20s\n",
      "800:\tlearn: 0.0596337\ttest: 0.0888911\tbest: 0.0887728 (578)\ttotal: 47.3s\tremaining: 3m 9s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08877279239\n",
      "bestIteration = 578\n",
      "\n",
      "Shrink model to first 579 iterations.\n",
      "0.18390669182327898\n",
      "0:\tlearn: 0.1850346\ttest: 0.1837935\tbest: 0.1837935 (0)\ttotal: 73.6ms\tremaining: 4m 54s\n",
      "200:\tlearn: 0.0789157\ttest: 0.0856689\tbest: 0.0856619 (199)\ttotal: 11.7s\tremaining: 3m 40s\n",
      "400:\tlearn: 0.0709492\ttest: 0.0844601\tbest: 0.0844438 (399)\ttotal: 22.9s\tremaining: 3m 25s\n",
      "600:\tlearn: 0.0648051\ttest: 0.0841539\tbest: 0.0840741 (561)\ttotal: 34.3s\tremaining: 3m 13s\n",
      "800:\tlearn: 0.0601136\ttest: 0.0839655\tbest: 0.0838005 (759)\ttotal: 45.7s\tremaining: 3m 2s\n",
      "1000:\tlearn: 0.0557748\ttest: 0.0839764\tbest: 0.0838003 (921)\ttotal: 57.3s\tremaining: 2m 51s\n",
      "1200:\tlearn: 0.0519072\ttest: 0.0840623\tbest: 0.0838003 (921)\ttotal: 1m 9s\tremaining: 2m 41s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08380027591\n",
      "bestIteration = 921\n",
      "\n",
      "Shrink model to first 922 iterations.\n",
      "0.19438172633987538\n",
      "0:\tlearn: 0.1853224\ttest: 0.1762108\tbest: 0.1762108 (0)\ttotal: 78ms\tremaining: 5m 11s\n",
      "200:\tlearn: 0.0792569\ttest: 0.0853801\tbest: 0.0853801 (200)\ttotal: 19.4s\tremaining: 6m 7s\n",
      "400:\tlearn: 0.0709061\ttest: 0.0839270\tbest: 0.0839105 (392)\ttotal: 32.9s\tremaining: 4m 55s\n",
      "600:\tlearn: 0.0647433\ttest: 0.0834432\tbest: 0.0834017 (554)\ttotal: 46.1s\tremaining: 4m 20s\n",
      "800:\tlearn: 0.0597585\ttest: 0.0833720\tbest: 0.0832864 (742)\ttotal: 58.1s\tremaining: 3m 51s\n",
      "1000:\tlearn: 0.0556015\ttest: 0.0835040\tbest: 0.0832864 (742)\ttotal: 1m 9s\tremaining: 3m 28s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08328635891\n",
      "bestIteration = 742\n",
      "\n",
      "Shrink model to first 743 iterations.\n",
      "0.2047925211449731\n",
      "0:\tlearn: 0.1852235\ttest: 0.1790540\tbest: 0.1790540 (0)\ttotal: 74ms\tremaining: 4m 55s\n",
      "200:\tlearn: 0.0792708\ttest: 0.0851926\tbest: 0.0851926 (200)\ttotal: 11.5s\tremaining: 3m 38s\n",
      "400:\tlearn: 0.0706174\ttest: 0.0840148\tbest: 0.0840148 (400)\ttotal: 22.8s\tremaining: 3m 24s\n",
      "600:\tlearn: 0.0646517\ttest: 0.0840670\tbest: 0.0837573 (438)\ttotal: 34.1s\tremaining: 3m 12s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08375733172\n",
      "bestIteration = 438\n",
      "\n",
      "Shrink model to first 439 iterations.\n",
      "0.2152621875731546\n",
      "0:\tlearn: 0.1850089\ttest: 0.1845892\tbest: 0.1845892 (0)\ttotal: 68.1ms\tremaining: 4m 32s\n",
      "200:\tlearn: 0.0791190\ttest: 0.0887795\tbest: 0.0887634 (197)\ttotal: 12s\tremaining: 3m 46s\n",
      "400:\tlearn: 0.0710031\ttest: 0.0869693\tbest: 0.0869693 (400)\ttotal: 23.6s\tremaining: 3m 31s\n",
      "600:\tlearn: 0.0648219\ttest: 0.0871009\tbest: 0.0869352 (450)\ttotal: 34.8s\tremaining: 3m 16s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08693515398\n",
      "bestIteration = 450\n",
      "\n",
      "Shrink model to first 451 iterations.\n",
      "0.22612908179360658\n",
      "0:\tlearn: 0.1849716\ttest: 0.1856464\tbest: 0.1856464 (0)\ttotal: 83.3ms\tremaining: 5m 33s\n",
      "200:\tlearn: 0.0787379\ttest: 0.0922558\tbest: 0.0922325 (199)\ttotal: 11.5s\tremaining: 3m 37s\n",
      "400:\tlearn: 0.0705196\ttest: 0.0905682\tbest: 0.0905682 (400)\ttotal: 23.3s\tremaining: 3m 29s\n",
      "600:\tlearn: 0.0643426\ttest: 0.0901454\tbest: 0.0901007 (572)\ttotal: 35.2s\tremaining: 3m 19s\n",
      "800:\tlearn: 0.0594202\ttest: 0.0899676\tbest: 0.0899523 (793)\ttotal: 46.7s\tremaining: 3m 6s\n",
      "1000:\tlearn: 0.0553266\ttest: 0.0894767\tbest: 0.0894496 (959)\ttotal: 58.4s\tremaining: 2m 55s\n",
      "1200:\tlearn: 0.0518989\ttest: 0.0893037\tbest: 0.0892962 (1197)\ttotal: 1m 10s\tremaining: 2m 43s\n",
      "1400:\tlearn: 0.0488589\ttest: 0.0892469\tbest: 0.0892444 (1398)\ttotal: 1m 21s\tremaining: 2m 31s\n",
      "1600:\tlearn: 0.0460005\ttest: 0.0893208\tbest: 0.0891962 (1421)\ttotal: 1m 33s\tremaining: 2m 19s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08919623722\n",
      "bestIteration = 1421\n",
      "\n",
      "Shrink model to first 1422 iterations.\n",
      "0.23727861145547272\n",
      "0:\tlearn: 0.1849519\ttest: 0.1863269\tbest: 0.1863269 (0)\ttotal: 61.9ms\tremaining: 4m 7s\n",
      "200:\tlearn: 0.0792732\ttest: 0.0842153\tbest: 0.0842153 (200)\ttotal: 11.5s\tremaining: 3m 38s\n",
      "400:\tlearn: 0.0707504\ttest: 0.0826602\tbest: 0.0826186 (391)\ttotal: 22.9s\tremaining: 3m 25s\n",
      "600:\tlearn: 0.0644172\ttest: 0.0822590\tbest: 0.0822108 (574)\ttotal: 34.4s\tremaining: 3m 14s\n",
      "800:\tlearn: 0.0596596\ttest: 0.0822950\tbest: 0.0821107 (676)\ttotal: 46.3s\tremaining: 3m 4s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08211068327\n",
      "bestIteration = 676\n",
      "\n",
      "Shrink model to first 677 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24754244683729387\n",
      "0:\tlearn: 0.1850903\ttest: 0.1826470\tbest: 0.1826470 (0)\ttotal: 76.9ms\tremaining: 5m 7s\n",
      "200:\tlearn: 0.0789114\ttest: 0.0906390\tbest: 0.0905740 (194)\ttotal: 11.7s\tremaining: 3m 41s\n",
      "400:\tlearn: 0.0705453\ttest: 0.0899904\tbest: 0.0899904 (400)\ttotal: 23.1s\tremaining: 3m 27s\n",
      "600:\tlearn: 0.0645252\ttest: 0.0896799\tbest: 0.0896750 (576)\ttotal: 34.3s\tremaining: 3m 14s\n",
      "800:\tlearn: 0.0594512\ttest: 0.0894234\tbest: 0.0894234 (800)\ttotal: 45.7s\tremaining: 3m 2s\n",
      "1000:\tlearn: 0.0553580\ttest: 0.0893488\tbest: 0.0892750 (853)\ttotal: 57.4s\tremaining: 2m 51s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08927495811\n",
      "bestIteration = 853\n",
      "\n",
      "Shrink model to first 854 iterations.\n",
      "0.2587018165809199\n",
      "0:\tlearn: 0.1852167\ttest: 0.1810931\tbest: 0.1810931 (0)\ttotal: 64ms\tremaining: 4m 15s\n",
      "200:\tlearn: 0.0791516\ttest: 0.0872188\tbest: 0.0872138 (197)\ttotal: 11.5s\tremaining: 3m 37s\n",
      "400:\tlearn: 0.0708434\ttest: 0.0867763\tbest: 0.0865895 (307)\ttotal: 23s\tremaining: 3m 26s\n",
      "600:\tlearn: 0.0649100\ttest: 0.0863334\tbest: 0.0863307 (599)\ttotal: 34.2s\tremaining: 3m 13s\n",
      "800:\tlearn: 0.0598525\ttest: 0.0862094\tbest: 0.0861011 (710)\ttotal: 45.6s\tremaining: 3m 1s\n",
      "1000:\tlearn: 0.0557449\ttest: 0.0863384\tbest: 0.0861011 (710)\ttotal: 56.7s\tremaining: 2m 49s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08610109847\n",
      "bestIteration = 710\n",
      "\n",
      "Shrink model to first 711 iterations.\n",
      "0.2694644539015035\n"
     ]
    }
   ],
   "source": [
    "fold_score = 0\n",
    "test_pred = []\n",
    "\n",
    "n = 8\n",
    "#kf = StratifiedKFold(n)\n",
    "kf = KFold(n_splits=25)\n",
    "#kf = StratifiedShuffleSplit(n_splits=20,test_size=0.2)\n",
    "kf.get_n_splits(X)\n",
    "  \n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    Xtrain, Xtest = X.loc[train_index], X.loc[test_index]\n",
    "    ytrain, ytest = y[train_index], y[test_index]\n",
    "\n",
    "    model = CatBoostRegressor(random_seed=34,bootstrap_type='Bayesian', max_depth=8,learning_rate=0.07,\n",
    "                          iterations=4000,silent=True, early_stopping_rounds = 300)\n",
    "    model.fit(Xtrain, ytrain, eval_set=[(Xtest,ytest)], verbose=200)\n",
    "    \n",
    "    pred = model.predict(Xtest)\n",
    "    score = np.sqrt(mean_squared_error(ytest, pred))\n",
    "    fold_score = fold_score + (score/n)\n",
    "    print(fold_score)\n",
    "    \n",
    "    predictions = model.predict(test_df)\n",
    "    test_pred.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "#y_pred = cross_val_predict(estimator=model, X= X y=y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SampleSubmission (1).csv')\n",
    "df['Target'] = np.mean(test_pred, axis = 0)\n",
    "df.to_csv('CatC.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.1876031\ttest: 0.1892605\tbest: 0.1892605 (0)\ttotal: 145ms\tremaining: 4m 50s\n",
      "200:\tlearn: 0.0796527\ttest: 0.0885328\tbest: 0.0885328 (200)\ttotal: 26.8s\tremaining: 3m 59s\n",
      "400:\tlearn: 0.0705571\ttest: 0.0867467\tbest: 0.0867467 (400)\ttotal: 53.4s\tremaining: 3m 32s\n",
      "600:\tlearn: 0.0642140\ttest: 0.0858922\tbest: 0.0858922 (600)\ttotal: 1m 20s\tremaining: 3m 7s\n",
      "800:\tlearn: 0.0590328\ttest: 0.0855283\tbest: 0.0855283 (800)\ttotal: 1m 47s\tremaining: 2m 40s\n",
      "1000:\tlearn: 0.0547120\ttest: 0.0852986\tbest: 0.0852542 (938)\ttotal: 2m 14s\tremaining: 2m 13s\n",
      "1200:\tlearn: 0.0509072\ttest: 0.0851921\tbest: 0.0851688 (1142)\ttotal: 2m 41s\tremaining: 1m 47s\n",
      "1400:\tlearn: 0.0476603\ttest: 0.0851165\tbest: 0.0851081 (1398)\ttotal: 3m 7s\tremaining: 1m 20s\n",
      "1600:\tlearn: 0.0449038\ttest: 0.0851651\tbest: 0.0850969 (1429)\ttotal: 3m 34s\tremaining: 53.5s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08509689908\n",
      "bestIteration = 1429\n",
      "\n",
      "Shrink model to first 1430 iterations.\n",
      "0.010637112401123004\n",
      "0:\tlearn: 0.1876290\ttest: 0.1888425\tbest: 0.1888425 (0)\ttotal: 156ms\tremaining: 5m 12s\n",
      "200:\tlearn: 0.0799454\ttest: 0.0833459\tbest: 0.0833459 (200)\ttotal: 26.6s\tremaining: 3m 58s\n",
      "400:\tlearn: 0.0707629\ttest: 0.0815715\tbest: 0.0815715 (400)\ttotal: 53.5s\tremaining: 3m 33s\n",
      "600:\tlearn: 0.0643905\ttest: 0.0813159\tbest: 0.0812341 (571)\ttotal: 1m 20s\tremaining: 3m 6s\n",
      "800:\tlearn: 0.0592561\ttest: 0.0812158\tbest: 0.0812158 (800)\ttotal: 1m 47s\tremaining: 2m 40s\n",
      "1000:\tlearn: 0.0549114\ttest: 0.0813941\tbest: 0.0811958 (812)\ttotal: 2m 13s\tremaining: 2m 13s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08119584419\n",
      "bestIteration = 812\n",
      "\n",
      "Shrink model to first 813 iterations.\n",
      "0.02078659289277938\n",
      "0:\tlearn: 0.1872939\ttest: 0.1967263\tbest: 0.1967263 (0)\ttotal: 133ms\tremaining: 4m 26s\n",
      "200:\tlearn: 0.0794227\ttest: 0.0910598\tbest: 0.0910598 (200)\ttotal: 27s\tremaining: 4m 1s\n",
      "400:\tlearn: 0.0708157\ttest: 0.0897649\tbest: 0.0897649 (400)\ttotal: 53.7s\tremaining: 3m 34s\n",
      "600:\tlearn: 0.0642862\ttest: 0.0894763\tbest: 0.0893838 (573)\ttotal: 1m 20s\tremaining: 3m 7s\n",
      "800:\tlearn: 0.0591485\ttest: 0.0893627\tbest: 0.0892062 (715)\ttotal: 1m 47s\tremaining: 2m 40s\n",
      "1000:\tlearn: 0.0547432\ttest: 0.0894943\tbest: 0.0892062 (715)\ttotal: 2m 13s\tremaining: 2m 13s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.0892061975\n",
      "bestIteration = 715\n",
      "\n",
      "Shrink model to first 716 iterations.\n",
      "0.03193736749092944\n",
      "0:\tlearn: 0.1875576\ttest: 0.1902164\tbest: 0.1902164 (0)\ttotal: 158ms\tremaining: 5m 16s\n",
      "200:\tlearn: 0.0798433\ttest: 0.0885701\tbest: 0.0885701 (200)\ttotal: 27s\tremaining: 4m 1s\n",
      "400:\tlearn: 0.0709469\ttest: 0.0863966\tbest: 0.0863729 (387)\ttotal: 53.6s\tremaining: 3m 33s\n",
      "600:\tlearn: 0.0644345\ttest: 0.0856551\tbest: 0.0856551 (600)\ttotal: 1m 20s\tremaining: 3m 6s\n",
      "800:\tlearn: 0.0592852\ttest: 0.0853391\tbest: 0.0852814 (722)\ttotal: 1m 46s\tremaining: 2m 39s\n",
      "1000:\tlearn: 0.0550466\ttest: 0.0851706\tbest: 0.0851690 (998)\ttotal: 2m 12s\tremaining: 2m 12s\n",
      "1200:\tlearn: 0.0510821\ttest: 0.0850991\tbest: 0.0850744 (1148)\ttotal: 2m 39s\tremaining: 1m 46s\n",
      "1400:\tlearn: 0.0477305\ttest: 0.0849919\tbest: 0.0849711 (1391)\ttotal: 3m 6s\tremaining: 1m 19s\n",
      "1600:\tlearn: 0.0448588\ttest: 0.0851513\tbest: 0.0849711 (1391)\ttotal: 3m 33s\tremaining: 53.1s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08497112671\n",
      "bestIteration = 1391\n",
      "\n",
      "Shrink model to first 1392 iterations.\n",
      "0.04255875824999193\n",
      "0:\tlearn: 0.1872879\ttest: 0.1952031\tbest: 0.1952031 (0)\ttotal: 114ms\tremaining: 3m 47s\n",
      "200:\tlearn: 0.0793708\ttest: 0.0937773\tbest: 0.0937682 (196)\ttotal: 26.2s\tremaining: 3m 54s\n",
      "400:\tlearn: 0.0706093\ttest: 0.0922826\tbest: 0.0922826 (400)\ttotal: 53.1s\tremaining: 3m 31s\n",
      "600:\tlearn: 0.0639246\ttest: 0.0921710\tbest: 0.0920581 (583)\ttotal: 1m 20s\tremaining: 3m 6s\n",
      "800:\tlearn: 0.0586865\ttest: 0.0922215\tbest: 0.0920581 (583)\ttotal: 1m 46s\tremaining: 2m 40s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.09205808181\n",
      "bestIteration = 583\n",
      "\n",
      "Shrink model to first 584 iterations.\n",
      "0.05406601836231041\n",
      "0:\tlearn: 0.1875494\ttest: 0.1872969\tbest: 0.1872969 (0)\ttotal: 129ms\tremaining: 4m 17s\n",
      "200:\tlearn: 0.0794327\ttest: 0.0899158\tbest: 0.0899158 (200)\ttotal: 26.5s\tremaining: 3m 56s\n",
      "400:\tlearn: 0.0708687\ttest: 0.0876605\tbest: 0.0876541 (398)\ttotal: 52.9s\tremaining: 3m 31s\n",
      "600:\tlearn: 0.0643747\ttest: 0.0866734\tbest: 0.0866656 (590)\ttotal: 1m 20s\tremaining: 3m 6s\n",
      "800:\tlearn: 0.0589893\ttest: 0.0864511\tbest: 0.0864307 (789)\ttotal: 1m 46s\tremaining: 2m 39s\n",
      "1000:\tlearn: 0.0548089\ttest: 0.0863818\tbest: 0.0862708 (880)\ttotal: 2m 13s\tremaining: 2m 13s\n",
      "1200:\tlearn: 0.0511364\ttest: 0.0862894\tbest: 0.0862395 (1150)\ttotal: 2m 40s\tremaining: 1m 46s\n",
      "1400:\tlearn: 0.0478903\ttest: 0.0862644\tbest: 0.0862333 (1384)\ttotal: 3m 6s\tremaining: 1m 19s\n",
      "1600:\tlearn: 0.0451411\ttest: 0.0863359\tbest: 0.0862333 (1384)\ttotal: 3m 33s\tremaining: 53.3s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08623333772\n",
      "bestIteration = 1384\n",
      "\n",
      "Shrink model to first 1385 iterations.\n",
      "0.06484518564194551\n",
      "0:\tlearn: 0.1874307\ttest: 0.1907517\tbest: 0.1907517 (0)\ttotal: 132ms\tremaining: 4m 23s\n",
      "200:\tlearn: 0.0797476\ttest: 0.0865579\tbest: 0.0865579 (200)\ttotal: 26.9s\tremaining: 4m\n",
      "400:\tlearn: 0.0710228\ttest: 0.0847960\tbest: 0.0847885 (396)\ttotal: 53.1s\tremaining: 3m 31s\n",
      "600:\tlearn: 0.0644509\ttest: 0.0844293\tbest: 0.0844061 (514)\ttotal: 1m 19s\tremaining: 3m 4s\n",
      "800:\tlearn: 0.0593069\ttest: 0.0842913\tbest: 0.0842736 (685)\ttotal: 1m 46s\tremaining: 2m 39s\n",
      "1000:\tlearn: 0.0550593\ttest: 0.0843238\tbest: 0.0842295 (921)\ttotal: 2m 13s\tremaining: 2m 12s\n",
      "1200:\tlearn: 0.0513908\ttest: 0.0841877\tbest: 0.0841742 (1188)\ttotal: 2m 39s\tremaining: 1m 46s\n",
      "1400:\tlearn: 0.0480629\ttest: 0.0842190\tbest: 0.0841742 (1188)\ttotal: 3m 7s\tremaining: 1m 19s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08417419305\n",
      "bestIteration = 1188\n",
      "\n",
      "Shrink model to first 1189 iterations.\n",
      "0.07536695979670961\n",
      "0:\tlearn: 0.1874529\ttest: 0.1910808\tbest: 0.1910808 (0)\ttotal: 159ms\tremaining: 5m 17s\n",
      "200:\tlearn: 0.0796445\ttest: 0.0887571\tbest: 0.0887386 (198)\ttotal: 26.7s\tremaining: 3m 59s\n",
      "400:\tlearn: 0.0708058\ttest: 0.0870621\tbest: 0.0869954 (386)\ttotal: 53.3s\tremaining: 3m 32s\n",
      "600:\tlearn: 0.0642994\ttest: 0.0869257\tbest: 0.0869086 (586)\ttotal: 1m 19s\tremaining: 3m 6s\n",
      "800:\tlearn: 0.0592245\ttest: 0.0868058\tbest: 0.0867866 (795)\ttotal: 1m 46s\tremaining: 2m 39s\n",
      "1000:\tlearn: 0.0550776\ttest: 0.0867755\tbest: 0.0867222 (849)\ttotal: 2m 13s\tremaining: 2m 12s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08672217263\n",
      "bestIteration = 849\n",
      "\n",
      "Shrink model to first 850 iterations.\n",
      "0.08620723133767938\n",
      "0:\tlearn: 0.1879222\ttest: 0.1830477\tbest: 0.1830477 (0)\ttotal: 166ms\tremaining: 5m 31s\n",
      "200:\tlearn: 0.0796822\ttest: 0.0893902\tbest: 0.0893750 (198)\ttotal: 26.6s\tremaining: 3m 58s\n",
      "400:\tlearn: 0.0707660\ttest: 0.0880660\tbest: 0.0880496 (390)\ttotal: 53.6s\tremaining: 3m 33s\n",
      "600:\tlearn: 0.0643951\ttest: 0.0876606\tbest: 0.0876606 (600)\ttotal: 1m 20s\tremaining: 3m 8s\n",
      "800:\tlearn: 0.0592483\ttest: 0.0875298\tbest: 0.0875002 (764)\ttotal: 1m 47s\tremaining: 2m 41s\n",
      "1000:\tlearn: 0.0548222\ttest: 0.0877107\tbest: 0.0875002 (764)\ttotal: 2m 14s\tremaining: 2m 14s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08750017998\n",
      "bestIteration = 764\n",
      "\n",
      "Shrink model to first 765 iterations.\n",
      "0.09714475373582902\n",
      "0:\tlearn: 0.1878625\ttest: 0.1846254\tbest: 0.1846254 (0)\ttotal: 137ms\tremaining: 4m 33s\n",
      "200:\tlearn: 0.0798338\ttest: 0.0861879\tbest: 0.0861678 (199)\ttotal: 27s\tremaining: 4m 1s\n",
      "400:\tlearn: 0.0709277\ttest: 0.0833301\tbest: 0.0833301 (400)\ttotal: 54s\tremaining: 3m 35s\n",
      "600:\tlearn: 0.0644542\ttest: 0.0825152\tbest: 0.0824966 (588)\ttotal: 1m 20s\tremaining: 3m 6s\n",
      "800:\tlearn: 0.0591681\ttest: 0.0820025\tbest: 0.0819786 (794)\ttotal: 1m 46s\tremaining: 2m 39s\n",
      "1000:\tlearn: 0.0549745\ttest: 0.0818368\tbest: 0.0818041 (945)\ttotal: 2m 13s\tremaining: 2m 13s\n",
      "1200:\tlearn: 0.0514286\ttest: 0.0818289\tbest: 0.0817648 (1053)\ttotal: 2m 39s\tremaining: 1m 46s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08176481824\n",
      "bestIteration = 1053\n",
      "\n",
      "Shrink model to first 1054 iterations.\n",
      "0.10736535605285552\n",
      "0:\tlearn: 0.1877412\ttest: 0.1847446\tbest: 0.1847446 (0)\ttotal: 131ms\tremaining: 4m 22s\n",
      "200:\tlearn: 0.0795522\ttest: 0.0887038\tbest: 0.0887038 (200)\ttotal: 26.9s\tremaining: 4m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400:\tlearn: 0.0711045\ttest: 0.0876682\tbest: 0.0876682 (400)\ttotal: 53.8s\tremaining: 3m 34s\n",
      "600:\tlearn: 0.0644213\ttest: 0.0874582\tbest: 0.0874433 (596)\ttotal: 1m 20s\tremaining: 3m 7s\n",
      "800:\tlearn: 0.0593300\ttest: 0.0874712\tbest: 0.0873132 (706)\ttotal: 1m 46s\tremaining: 2m 39s\n",
      "1000:\tlearn: 0.0550543\ttest: 0.0876968\tbest: 0.0873132 (706)\ttotal: 2m 13s\tremaining: 2m 13s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08731322948\n",
      "bestIteration = 706\n",
      "\n",
      "Shrink model to first 707 iterations.\n",
      "0.11827950971385935\n",
      "0:\tlearn: 0.1875663\ttest: 0.1879101\tbest: 0.1879101 (0)\ttotal: 132ms\tremaining: 4m 23s\n",
      "200:\tlearn: 0.0795881\ttest: 0.0871093\tbest: 0.0871093 (200)\ttotal: 26.8s\tremaining: 4m\n",
      "400:\tlearn: 0.0709379\ttest: 0.0860479\tbest: 0.0860322 (398)\ttotal: 52.9s\tremaining: 3m 30s\n",
      "600:\tlearn: 0.0643459\ttest: 0.0856123\tbest: 0.0855307 (566)\ttotal: 1m 19s\tremaining: 3m 4s\n",
      "800:\tlearn: 0.0591947\ttest: 0.0856440\tbest: 0.0855307 (566)\ttotal: 1m 46s\tremaining: 2m 38s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.0855307476\n",
      "bestIteration = 566\n",
      "\n",
      "Shrink model to first 567 iterations.\n",
      "0.12897085316691534\n",
      "0:\tlearn: 0.1872457\ttest: 0.1945836\tbest: 0.1945836 (0)\ttotal: 143ms\tremaining: 4m 46s\n",
      "200:\tlearn: 0.0794519\ttest: 0.0952362\tbest: 0.0952362 (200)\ttotal: 27s\tremaining: 4m 1s\n",
      "400:\tlearn: 0.0702645\ttest: 0.0939199\tbest: 0.0938470 (386)\ttotal: 53.8s\tremaining: 3m 34s\n",
      "600:\tlearn: 0.0638654\ttest: 0.0935910\tbest: 0.0935847 (599)\ttotal: 1m 20s\tremaining: 3m 8s\n",
      "800:\tlearn: 0.0585477\ttest: 0.0935230\tbest: 0.0935096 (792)\ttotal: 1m 47s\tremaining: 2m 41s\n",
      "1000:\tlearn: 0.0543664\ttest: 0.0937514\tbest: 0.0934643 (806)\ttotal: 2m 14s\tremaining: 2m 13s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.09346427566\n",
      "bestIteration = 806\n",
      "\n",
      "Shrink model to first 807 iterations.\n",
      "0.14065388768775677\n",
      "0:\tlearn: 0.1878108\ttest: 0.1844689\tbest: 0.1844689 (0)\ttotal: 127ms\tremaining: 4m 14s\n",
      "200:\tlearn: 0.0793420\ttest: 0.0921227\tbest: 0.0921227 (200)\ttotal: 26.8s\tremaining: 4m\n",
      "400:\tlearn: 0.0704334\ttest: 0.0916014\tbest: 0.0913958 (350)\ttotal: 53.4s\tremaining: 3m 32s\n",
      "600:\tlearn: 0.0639190\ttest: 0.0914819\tbest: 0.0913958 (350)\ttotal: 1m 20s\tremaining: 3m 7s\n",
      "800:\tlearn: 0.0587318\ttest: 0.0913533\tbest: 0.0912980 (746)\ttotal: 1m 46s\tremaining: 2m 39s\n",
      "1000:\tlearn: 0.0547464\ttest: 0.0913783\tbest: 0.0912980 (746)\ttotal: 2m 13s\tremaining: 2m 13s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.09129797298\n",
      "bestIteration = 746\n",
      "\n",
      "Shrink model to first 747 iterations.\n",
      "0.15206613431366967\n",
      "0:\tlearn: 0.1876371\ttest: 0.1888462\tbest: 0.1888462 (0)\ttotal: 118ms\tremaining: 3m 55s\n",
      "200:\tlearn: 0.0796215\ttest: 0.0887847\tbest: 0.0887378 (196)\ttotal: 26.9s\tremaining: 4m 1s\n",
      "400:\tlearn: 0.0706342\ttest: 0.0875594\tbest: 0.0874951 (392)\ttotal: 54s\tremaining: 3m 35s\n",
      "600:\tlearn: 0.0641690\ttest: 0.0869690\tbest: 0.0869690 (600)\ttotal: 1m 20s\tremaining: 3m 8s\n",
      "800:\tlearn: 0.0589431\ttest: 0.0868457\tbest: 0.0867950 (772)\ttotal: 1m 47s\tremaining: 2m 41s\n",
      "1000:\tlearn: 0.0549092\ttest: 0.0869084\tbest: 0.0867950 (772)\ttotal: 2m 14s\tremaining: 2m 13s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08679495453\n",
      "bestIteration = 772\n",
      "\n",
      "Shrink model to first 773 iterations.\n",
      "0.16291550371183414\n",
      "0:\tlearn: 0.1875586\ttest: 0.1882844\tbest: 0.1882844 (0)\ttotal: 127ms\tremaining: 4m 14s\n",
      "200:\tlearn: 0.0797393\ttest: 0.0864393\tbest: 0.0864393 (200)\ttotal: 26.9s\tremaining: 4m\n",
      "400:\tlearn: 0.0709605\ttest: 0.0849194\tbest: 0.0849005 (398)\ttotal: 53.8s\tremaining: 3m 34s\n",
      "600:\tlearn: 0.0646350\ttest: 0.0841227\tbest: 0.0840932 (583)\ttotal: 1m 20s\tremaining: 3m 7s\n",
      "800:\tlearn: 0.0595752\ttest: 0.0840920\tbest: 0.0840316 (789)\ttotal: 1m 47s\tremaining: 2m 41s\n",
      "1000:\tlearn: 0.0551941\ttest: 0.0840235\tbest: 0.0840172 (959)\ttotal: 2m 14s\tremaining: 2m 14s\n",
      "1200:\tlearn: 0.0514230\ttest: 0.0841281\tbest: 0.0839553 (1065)\ttotal: 2m 41s\tremaining: 1m 47s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08395529154\n",
      "bestIteration = 1065\n",
      "\n",
      "Shrink model to first 1066 iterations.\n",
      "0.17340991521160581\n",
      "0:\tlearn: 0.1877806\ttest: 0.1853816\tbest: 0.1853816 (0)\ttotal: 131ms\tremaining: 4m 22s\n",
      "200:\tlearn: 0.0796046\ttest: 0.0906881\tbest: 0.0906636 (197)\ttotal: 26.4s\tremaining: 3m 56s\n",
      "400:\tlearn: 0.0705610\ttest: 0.0895597\tbest: 0.0894961 (388)\ttotal: 53.2s\tremaining: 3m 32s\n",
      "600:\tlearn: 0.0641914\ttest: 0.0896289\tbest: 0.0894693 (582)\ttotal: 1m 20s\tremaining: 3m 7s\n",
      "800:\tlearn: 0.0590007\ttest: 0.0896350\tbest: 0.0894693 (582)\ttotal: 1m 47s\tremaining: 2m 40s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08946928336\n",
      "bestIteration = 582\n",
      "\n",
      "Shrink model to first 583 iterations.\n",
      "0.18459357562015602\n",
      "0:\tlearn: 0.1877429\ttest: 0.1864889\tbest: 0.1864889 (0)\ttotal: 162ms\tremaining: 5m 23s\n",
      "200:\tlearn: 0.0794893\ttest: 0.0864748\tbest: 0.0864748 (200)\ttotal: 27.2s\tremaining: 4m 3s\n",
      "400:\tlearn: 0.0708404\ttest: 0.0850536\tbest: 0.0850278 (396)\ttotal: 54s\tremaining: 3m 35s\n",
      "600:\tlearn: 0.0643463\ttest: 0.0848697\tbest: 0.0847911 (565)\ttotal: 1m 21s\tremaining: 3m 8s\n",
      "800:\tlearn: 0.0592904\ttest: 0.0847939\tbest: 0.0847381 (757)\ttotal: 1m 47s\tremaining: 2m 41s\n",
      "1000:\tlearn: 0.0549514\ttest: 0.0847401\tbest: 0.0847147 (826)\ttotal: 2m 14s\tremaining: 2m 14s\n",
      "1200:\tlearn: 0.0511807\ttest: 0.0846494\tbest: 0.0846044 (1166)\ttotal: 2m 41s\tremaining: 1m 47s\n",
      "1400:\tlearn: 0.0478084\ttest: 0.0845150\tbest: 0.0844835 (1388)\ttotal: 3m 7s\tremaining: 1m 20s\n",
      "1600:\tlearn: 0.0449685\ttest: 0.0845785\tbest: 0.0844835 (1388)\ttotal: 3m 34s\tremaining: 53.5s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08448345241\n",
      "bestIteration = 1388\n",
      "\n",
      "Shrink model to first 1389 iterations.\n",
      "0.19515400719926118\n",
      "0:\tlearn: 0.1880340\ttest: 0.1788673\tbest: 0.1788673 (0)\ttotal: 128ms\tremaining: 4m 15s\n",
      "200:\tlearn: 0.0799582\ttest: 0.0856289\tbest: 0.0856199 (198)\ttotal: 26.3s\tremaining: 3m 55s\n",
      "400:\tlearn: 0.0711781\ttest: 0.0840086\tbest: 0.0839853 (374)\ttotal: 53.4s\tremaining: 3m 32s\n",
      "600:\tlearn: 0.0647157\ttest: 0.0834833\tbest: 0.0834430 (594)\ttotal: 1m 20s\tremaining: 3m 6s\n",
      "800:\tlearn: 0.0595535\ttest: 0.0834857\tbest: 0.0833447 (648)\ttotal: 1m 47s\tremaining: 2m 40s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08334472663\n",
      "bestIteration = 648\n",
      "\n",
      "Shrink model to first 649 iterations.\n",
      "0.20557209796103565\n",
      "0:\tlearn: 0.1879271\ttest: 0.1818013\tbest: 0.1818013 (0)\ttotal: 171ms\tremaining: 5m 41s\n",
      "200:\tlearn: 0.0795814\ttest: 0.0862792\tbest: 0.0862792 (200)\ttotal: 27s\tremaining: 4m 1s\n",
      "400:\tlearn: 0.0705345\ttest: 0.0846642\tbest: 0.0846429 (395)\ttotal: 54.2s\tremaining: 3m 36s\n",
      "600:\tlearn: 0.0643176\ttest: 0.0842787\tbest: 0.0842711 (599)\ttotal: 1m 20s\tremaining: 3m 7s\n",
      "800:\tlearn: 0.0591869\ttest: 0.0842241\tbest: 0.0841720 (738)\ttotal: 1m 47s\tremaining: 2m 41s\n",
      "1000:\tlearn: 0.0549293\ttest: 0.0843271\tbest: 0.0841720 (738)\ttotal: 2m 14s\tremaining: 2m 14s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08417196212\n",
      "bestIteration = 738\n",
      "\n",
      "Shrink model to first 739 iterations.\n",
      "0.21609359318459156\n",
      "0:\tlearn: 0.1876000\ttest: 0.1871531\tbest: 0.1871531 (0)\ttotal: 135ms\tremaining: 4m 29s\n",
      "200:\tlearn: 0.0798985\ttest: 0.0883789\tbest: 0.0883743 (198)\ttotal: 26.6s\tremaining: 3m 58s\n",
      "400:\tlearn: 0.0708951\ttest: 0.0865258\tbest: 0.0865258 (400)\ttotal: 53.7s\tremaining: 3m 33s\n",
      "600:\tlearn: 0.0646219\ttest: 0.0860865\tbest: 0.0860850 (589)\ttotal: 1m 20s\tremaining: 3m 6s\n",
      "800:\tlearn: 0.0594827\ttest: 0.0858547\tbest: 0.0858547 (800)\ttotal: 1m 47s\tremaining: 2m 40s\n",
      "1000:\tlearn: 0.0549622\ttest: 0.0856488\tbest: 0.0855953 (992)\ttotal: 2m 13s\tremaining: 2m 13s\n",
      "1200:\tlearn: 0.0511947\ttest: 0.0856974\tbest: 0.0855953 (992)\ttotal: 2m 40s\tremaining: 1m 46s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08559528857\n",
      "bestIteration = 992\n",
      "\n",
      "Shrink model to first 993 iterations.\n",
      "0.22679300423905885\n",
      "0:\tlearn: 0.1876783\ttest: 0.1882017\tbest: 0.1882017 (0)\ttotal: 152ms\tremaining: 5m 3s\n",
      "200:\tlearn: 0.0794219\ttest: 0.0926183\tbest: 0.0926183 (200)\ttotal: 26.6s\tremaining: 3m 58s\n",
      "400:\tlearn: 0.0704388\ttest: 0.0903666\tbest: 0.0903666 (400)\ttotal: 53.6s\tremaining: 3m 33s\n",
      "600:\tlearn: 0.0640796\ttest: 0.0897713\tbest: 0.0897621 (593)\ttotal: 1m 20s\tremaining: 3m 6s\n",
      "800:\tlearn: 0.0589629\ttest: 0.0895461\tbest: 0.0894851 (789)\ttotal: 1m 47s\tremaining: 2m 40s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000:\tlearn: 0.0546128\ttest: 0.0896000\tbest: 0.0894851 (789)\ttotal: 2m 13s\tremaining: 2m 13s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08948507011\n",
      "bestIteration = 789\n",
      "\n",
      "Shrink model to first 790 iterations.\n",
      "0.23797863802302868\n",
      "0:\tlearn: 0.1876470\ttest: 0.1891009\tbest: 0.1891009 (0)\ttotal: 155ms\tremaining: 5m 10s\n",
      "200:\tlearn: 0.0797780\ttest: 0.0841868\tbest: 0.0841868 (200)\ttotal: 27s\tremaining: 4m 1s\n",
      "400:\tlearn: 0.0708538\ttest: 0.0822561\tbest: 0.0822438 (398)\ttotal: 53.9s\tremaining: 3m 34s\n",
      "600:\tlearn: 0.0644327\ttest: 0.0816361\tbest: 0.0816091 (598)\ttotal: 1m 20s\tremaining: 3m 7s\n",
      "800:\tlearn: 0.0592288\ttest: 0.0815969\tbest: 0.0815159 (771)\ttotal: 1m 47s\tremaining: 2m 41s\n",
      "1000:\tlearn: 0.0547073\ttest: 0.0814394\tbest: 0.0814175 (987)\ttotal: 2m 14s\tremaining: 2m 13s\n",
      "1200:\tlearn: 0.0510514\ttest: 0.0815792\tbest: 0.0814175 (987)\ttotal: 2m 41s\tremaining: 1m 47s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08141747724\n",
      "bestIteration = 987\n",
      "\n",
      "Shrink model to first 988 iterations.\n",
      "0.24815582265985872\n",
      "0:\tlearn: 0.1877967\ttest: 0.1852759\tbest: 0.1852759 (0)\ttotal: 130ms\tremaining: 4m 20s\n",
      "200:\tlearn: 0.0795507\ttest: 0.0915501\tbest: 0.0915501 (200)\ttotal: 26.6s\tremaining: 3m 58s\n",
      "400:\tlearn: 0.0705992\ttest: 0.0902293\tbest: 0.0902258 (390)\ttotal: 53.5s\tremaining: 3m 33s\n",
      "600:\tlearn: 0.0641792\ttest: 0.0897924\tbest: 0.0897611 (588)\ttotal: 1m 20s\tremaining: 3m 7s\n",
      "800:\tlearn: 0.0589498\ttest: 0.0896848\tbest: 0.0896165 (718)\ttotal: 1m 47s\tremaining: 2m 41s\n",
      "1000:\tlearn: 0.0547904\ttest: 0.0899005\tbest: 0.0896165 (718)\ttotal: 2m 15s\tremaining: 2m 15s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.0896164512\n",
      "bestIteration = 718\n",
      "\n",
      "Shrink model to first 719 iterations.\n",
      "0.25935787902986585\n",
      "0:\tlearn: 0.1878819\ttest: 0.1838186\tbest: 0.1838186 (0)\ttotal: 108ms\tremaining: 3m 36s\n",
      "200:\tlearn: 0.0796744\ttest: 0.0870666\tbest: 0.0870666 (200)\ttotal: 26.6s\tremaining: 3m 58s\n",
      "400:\tlearn: 0.0707161\ttest: 0.0856217\tbest: 0.0855821 (397)\ttotal: 53.8s\tremaining: 3m 34s\n",
      "600:\tlearn: 0.0644814\ttest: 0.0857227\tbest: 0.0855821 (397)\ttotal: 1m 20s\tremaining: 3m 7s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.08558207043\n",
      "bestIteration = 397\n",
      "\n",
      "Shrink model to first 398 iterations.\n",
      "0.27005563784998804\n"
     ]
    }
   ],
   "source": [
    "fold_score = 0\n",
    "t_pred = []\n",
    "\n",
    "n = 8\n",
    "kf = StratifiedKFold(n)\n",
    "kf = KFold(n_splits=25)\n",
    "kf.get_n_splits(X)\n",
    "  \n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    Xtrain, Xtest = X.loc[train_index], X.loc[test_index]\n",
    "    ytrain, ytest = y[train_index], y[test_index]\n",
    "\n",
    "    model = CatBoostRegressor(random_seed=34,bootstrap_type='Bayesian', max_depth=10,learning_rate=0.2,\n",
    "                          iterations=2000,silent=True, early_stopping_rounds = 300)\n",
    "    model.fit(Xtrain, ytrain, eval_set=[(Xtest,ytest)], verbose=200)\n",
    "    \n",
    "    pred = model.predict(Xtest)\n",
    "    score = np.sqrt(mean_squared_error(ytest, pred))\n",
    "    fold_score = fold_score + (score/n)\n",
    "    print(fold_score)\n",
    "    \n",
    "    predictions = model.predict(test_df)\n",
    "    t_pred.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SampleSubmission (1).csv')\n",
    "df['Target'] = np.mean(t_pred, axis = 0)\n",
    "df.to_csv('CatCCC.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error,log_loss\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'objective':'regression','num_leaves':8,\n",
    "         'learning_rate':0.02, 'n_estimators':10000,\n",
    "         'max_bin': 55, \"bagging_fraction\": 0.2,\n",
    "         \"bagging_freq\": 5, \"feature_fraction\": 0.4,\n",
    "         \"feature_fraction_seed\":9, \"bagging_seed\":9,\n",
    "         \"min_data_in_leaf\":6,\n",
    "         \"metric\": 'rmse',\n",
    "         \"verbosity\": 1,\n",
    "         \"verbose_eval\": False,\n",
    "        'early_stopping_rounds': 300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n0\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 0.107053\tvalid_1's rmse: 0.10733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 0.0978605\tvalid_1's rmse: 0.0984028\n",
      "[300]\ttraining's rmse: 0.0948461\tvalid_1's rmse: 0.0955402\n",
      "[400]\ttraining's rmse: 0.0931435\tvalid_1's rmse: 0.0941077\n",
      "[500]\ttraining's rmse: 0.0919596\tvalid_1's rmse: 0.0931301\n",
      "[600]\ttraining's rmse: 0.0910619\tvalid_1's rmse: 0.0923819\n",
      "[700]\ttraining's rmse: 0.0903109\tvalid_1's rmse: 0.0918779\n",
      "[800]\ttraining's rmse: 0.0895998\tvalid_1's rmse: 0.0915201\n",
      "[900]\ttraining's rmse: 0.0890143\tvalid_1's rmse: 0.0912944\n",
      "[1000]\ttraining's rmse: 0.0884739\tvalid_1's rmse: 0.0909413\n",
      "[1100]\ttraining's rmse: 0.0879637\tvalid_1's rmse: 0.0907315\n",
      "[1200]\ttraining's rmse: 0.0874286\tvalid_1's rmse: 0.0904148\n",
      "[1300]\ttraining's rmse: 0.0869918\tvalid_1's rmse: 0.0901538\n",
      "[1400]\ttraining's rmse: 0.0866261\tvalid_1's rmse: 0.089935\n",
      "[1500]\ttraining's rmse: 0.0862279\tvalid_1's rmse: 0.0897676\n",
      "[1600]\ttraining's rmse: 0.0858625\tvalid_1's rmse: 0.0895459\n",
      "[1700]\ttraining's rmse: 0.0855089\tvalid_1's rmse: 0.0895002\n",
      "[1800]\ttraining's rmse: 0.0851634\tvalid_1's rmse: 0.089311\n",
      "[1900]\ttraining's rmse: 0.0848354\tvalid_1's rmse: 0.0890765\n",
      "[2000]\ttraining's rmse: 0.0845374\tvalid_1's rmse: 0.0890053\n",
      "[2100]\ttraining's rmse: 0.0842203\tvalid_1's rmse: 0.0889734\n",
      "[2200]\ttraining's rmse: 0.0839436\tvalid_1's rmse: 0.0888819\n",
      "[2300]\ttraining's rmse: 0.0836551\tvalid_1's rmse: 0.0887881\n",
      "[2400]\ttraining's rmse: 0.0833453\tvalid_1's rmse: 0.0887142\n",
      "[2500]\ttraining's rmse: 0.0830835\tvalid_1's rmse: 0.0886429\n",
      "[2600]\ttraining's rmse: 0.0828196\tvalid_1's rmse: 0.0886326\n",
      "[2700]\ttraining's rmse: 0.0825749\tvalid_1's rmse: 0.0885595\n",
      "[2800]\ttraining's rmse: 0.0823323\tvalid_1's rmse: 0.0884772\n",
      "[2900]\ttraining's rmse: 0.0821149\tvalid_1's rmse: 0.0883875\n",
      "[3000]\ttraining's rmse: 0.0818852\tvalid_1's rmse: 0.0884089\n",
      "[3100]\ttraining's rmse: 0.0816793\tvalid_1's rmse: 0.0882895\n",
      "[3200]\ttraining's rmse: 0.0814608\tvalid_1's rmse: 0.0882631\n",
      "[3300]\ttraining's rmse: 0.0812636\tvalid_1's rmse: 0.0882206\n",
      "[3400]\ttraining's rmse: 0.0810528\tvalid_1's rmse: 0.0881737\n",
      "[3500]\ttraining's rmse: 0.0808364\tvalid_1's rmse: 0.0881114\n",
      "[3600]\ttraining's rmse: 0.0806305\tvalid_1's rmse: 0.0881001\n",
      "[3700]\ttraining's rmse: 0.0804194\tvalid_1's rmse: 0.0880815\n",
      "[3800]\ttraining's rmse: 0.0802012\tvalid_1's rmse: 0.0880376\n",
      "[3900]\ttraining's rmse: 0.0800007\tvalid_1's rmse: 0.0881013\n",
      "[4000]\ttraining's rmse: 0.0797982\tvalid_1's rmse: 0.0880834\n",
      "[4100]\ttraining's rmse: 0.0796159\tvalid_1's rmse: 0.0880088\n",
      "[4200]\ttraining's rmse: 0.0794543\tvalid_1's rmse: 0.0880272\n",
      "[4300]\ttraining's rmse: 0.0792544\tvalid_1's rmse: 0.0880055\n",
      "[4400]\ttraining's rmse: 0.0790737\tvalid_1's rmse: 0.088023\n",
      "[4500]\ttraining's rmse: 0.0788992\tvalid_1's rmse: 0.0881026\n",
      "[4600]\ttraining's rmse: 0.0787241\tvalid_1's rmse: 0.0880489\n",
      "Early stopping, best iteration is:\n",
      "[4329]\ttraining's rmse: 0.0792074\tvalid_1's rmse: 0.0879873\n",
      "fold n1\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 0.107356\tvalid_1's rmse: 0.105436\n",
      "[200]\ttraining's rmse: 0.0981761\tvalid_1's rmse: 0.0966796\n",
      "[300]\ttraining's rmse: 0.0951019\tvalid_1's rmse: 0.0939795\n",
      "[400]\ttraining's rmse: 0.0934368\tvalid_1's rmse: 0.0927978\n",
      "[500]\ttraining's rmse: 0.092246\tvalid_1's rmse: 0.0919304\n",
      "[600]\ttraining's rmse: 0.0913365\tvalid_1's rmse: 0.09148\n",
      "[700]\ttraining's rmse: 0.0905349\tvalid_1's rmse: 0.090961\n",
      "[800]\ttraining's rmse: 0.0898076\tvalid_1's rmse: 0.0905821\n",
      "[900]\ttraining's rmse: 0.0891481\tvalid_1's rmse: 0.0902848\n",
      "[1000]\ttraining's rmse: 0.0885685\tvalid_1's rmse: 0.0898835\n",
      "[1100]\ttraining's rmse: 0.0880625\tvalid_1's rmse: 0.0896744\n",
      "[1200]\ttraining's rmse: 0.0875358\tvalid_1's rmse: 0.0893976\n",
      "[1300]\ttraining's rmse: 0.0871601\tvalid_1's rmse: 0.0892487\n",
      "[1400]\ttraining's rmse: 0.0867102\tvalid_1's rmse: 0.0891546\n",
      "[1500]\ttraining's rmse: 0.0862947\tvalid_1's rmse: 0.0888492\n",
      "[1600]\ttraining's rmse: 0.0859221\tvalid_1's rmse: 0.088773\n",
      "[1700]\ttraining's rmse: 0.0855462\tvalid_1's rmse: 0.0887159\n",
      "[1800]\ttraining's rmse: 0.0852012\tvalid_1's rmse: 0.0888214\n",
      "[1900]\ttraining's rmse: 0.0848652\tvalid_1's rmse: 0.0887538\n",
      "[2000]\ttraining's rmse: 0.0845492\tvalid_1's rmse: 0.0885875\n",
      "[2100]\ttraining's rmse: 0.0842382\tvalid_1's rmse: 0.0885998\n",
      "[2200]\ttraining's rmse: 0.0839512\tvalid_1's rmse: 0.0884917\n",
      "[2300]\ttraining's rmse: 0.0836666\tvalid_1's rmse: 0.0884028\n",
      "[2400]\ttraining's rmse: 0.0834141\tvalid_1's rmse: 0.0883658\n",
      "[2500]\ttraining's rmse: 0.0831188\tvalid_1's rmse: 0.0881713\n",
      "[2600]\ttraining's rmse: 0.082877\tvalid_1's rmse: 0.0880875\n",
      "[2700]\ttraining's rmse: 0.0826051\tvalid_1's rmse: 0.0879224\n",
      "[2800]\ttraining's rmse: 0.0823491\tvalid_1's rmse: 0.0879168\n",
      "[2900]\ttraining's rmse: 0.0821004\tvalid_1's rmse: 0.0879606\n",
      "[3000]\ttraining's rmse: 0.0818491\tvalid_1's rmse: 0.0878788\n",
      "[3100]\ttraining's rmse: 0.0815962\tvalid_1's rmse: 0.0878084\n",
      "[3200]\ttraining's rmse: 0.0813832\tvalid_1's rmse: 0.0877904\n",
      "[3300]\ttraining's rmse: 0.0811607\tvalid_1's rmse: 0.0878181\n",
      "[3400]\ttraining's rmse: 0.0809399\tvalid_1's rmse: 0.0877817\n",
      "[3500]\ttraining's rmse: 0.0807324\tvalid_1's rmse: 0.0876943\n",
      "[3600]\ttraining's rmse: 0.0805279\tvalid_1's rmse: 0.0876484\n",
      "[3700]\ttraining's rmse: 0.0803264\tvalid_1's rmse: 0.0876514\n",
      "[3800]\ttraining's rmse: 0.0801433\tvalid_1's rmse: 0.0875978\n",
      "[3900]\ttraining's rmse: 0.0799114\tvalid_1's rmse: 0.0875066\n",
      "[4000]\ttraining's rmse: 0.0797249\tvalid_1's rmse: 0.0874316\n",
      "[4100]\ttraining's rmse: 0.0795285\tvalid_1's rmse: 0.0873655\n",
      "[4200]\ttraining's rmse: 0.0793416\tvalid_1's rmse: 0.0873373\n",
      "[4300]\ttraining's rmse: 0.0791511\tvalid_1's rmse: 0.0873851\n",
      "[4400]\ttraining's rmse: 0.0789597\tvalid_1's rmse: 0.0873268\n",
      "[4500]\ttraining's rmse: 0.0787834\tvalid_1's rmse: 0.0873123\n",
      "[4600]\ttraining's rmse: 0.0786016\tvalid_1's rmse: 0.087282\n",
      "[4700]\ttraining's rmse: 0.0784174\tvalid_1's rmse: 0.0871975\n",
      "[4800]\ttraining's rmse: 0.0782316\tvalid_1's rmse: 0.0871326\n",
      "[4900]\ttraining's rmse: 0.0780666\tvalid_1's rmse: 0.087158\n",
      "[5000]\ttraining's rmse: 0.0778933\tvalid_1's rmse: 0.0871897\n",
      "[5100]\ttraining's rmse: 0.0777385\tvalid_1's rmse: 0.0872088\n",
      "[5200]\ttraining's rmse: 0.0775814\tvalid_1's rmse: 0.087253\n",
      "Early stopping, best iteration is:\n",
      "[4931]\ttraining's rmse: 0.0780298\tvalid_1's rmse: 0.0870662\n",
      "fold n2\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 0.106485\tvalid_1's rmse: 0.111214\n",
      "[200]\ttraining's rmse: 0.097234\tvalid_1's rmse: 0.102587\n",
      "[300]\ttraining's rmse: 0.0942985\tvalid_1's rmse: 0.100051\n",
      "[400]\ttraining's rmse: 0.0925682\tvalid_1's rmse: 0.0987076\n",
      "[500]\ttraining's rmse: 0.0913221\tvalid_1's rmse: 0.0977019\n",
      "[600]\ttraining's rmse: 0.0904195\tvalid_1's rmse: 0.0971039\n",
      "[700]\ttraining's rmse: 0.0896912\tvalid_1's rmse: 0.0965723\n",
      "[800]\ttraining's rmse: 0.0889885\tvalid_1's rmse: 0.096039\n",
      "[900]\ttraining's rmse: 0.0883935\tvalid_1's rmse: 0.0956973\n",
      "[1000]\ttraining's rmse: 0.0878617\tvalid_1's rmse: 0.0954945\n",
      "[1100]\ttraining's rmse: 0.0873729\tvalid_1's rmse: 0.0952642\n",
      "[1200]\ttraining's rmse: 0.0869325\tvalid_1's rmse: 0.0951064\n",
      "[1300]\ttraining's rmse: 0.086486\tvalid_1's rmse: 0.0948302\n",
      "[1400]\ttraining's rmse: 0.0860599\tvalid_1's rmse: 0.0946698\n",
      "[1500]\ttraining's rmse: 0.0856814\tvalid_1's rmse: 0.0944483\n",
      "[1600]\ttraining's rmse: 0.0853165\tvalid_1's rmse: 0.0942355\n",
      "[1700]\ttraining's rmse: 0.0849793\tvalid_1's rmse: 0.0939654\n",
      "[1800]\ttraining's rmse: 0.0846274\tvalid_1's rmse: 0.0939121\n",
      "[1900]\ttraining's rmse: 0.0843262\tvalid_1's rmse: 0.0937367\n",
      "[2000]\ttraining's rmse: 0.0840082\tvalid_1's rmse: 0.0936122\n",
      "[2100]\ttraining's rmse: 0.0837208\tvalid_1's rmse: 0.0935548\n",
      "[2200]\ttraining's rmse: 0.0834258\tvalid_1's rmse: 0.0934883\n",
      "[2300]\ttraining's rmse: 0.0831597\tvalid_1's rmse: 0.0933118\n",
      "[2400]\ttraining's rmse: 0.0829031\tvalid_1's rmse: 0.0931807\n",
      "[2500]\ttraining's rmse: 0.0826557\tvalid_1's rmse: 0.0930924\n",
      "[2600]\ttraining's rmse: 0.0824184\tvalid_1's rmse: 0.0931158\n",
      "[2700]\ttraining's rmse: 0.0821579\tvalid_1's rmse: 0.0930172\n",
      "[2800]\ttraining's rmse: 0.0819436\tvalid_1's rmse: 0.0929555\n",
      "[2900]\ttraining's rmse: 0.0817055\tvalid_1's rmse: 0.0929357\n",
      "[3000]\ttraining's rmse: 0.0814824\tvalid_1's rmse: 0.0929246\n",
      "[3100]\ttraining's rmse: 0.0812407\tvalid_1's rmse: 0.0928542\n",
      "[3200]\ttraining's rmse: 0.0810323\tvalid_1's rmse: 0.0927966\n",
      "[3300]\ttraining's rmse: 0.080807\tvalid_1's rmse: 0.0927617\n",
      "[3400]\ttraining's rmse: 0.0806008\tvalid_1's rmse: 0.0927224\n",
      "[3500]\ttraining's rmse: 0.080418\tvalid_1's rmse: 0.0928246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3600]\ttraining's rmse: 0.0802199\tvalid_1's rmse: 0.0928292\n",
      "Early stopping, best iteration is:\n",
      "[3396]\ttraining's rmse: 0.080609\tvalid_1's rmse: 0.0927145\n",
      "fold n3\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 0.106999\tvalid_1's rmse: 0.108334\n",
      "[200]\ttraining's rmse: 0.0979165\tvalid_1's rmse: 0.0989767\n",
      "[300]\ttraining's rmse: 0.095013\tvalid_1's rmse: 0.0960152\n",
      "[400]\ttraining's rmse: 0.0932724\tvalid_1's rmse: 0.0944846\n",
      "[500]\ttraining's rmse: 0.0919816\tvalid_1's rmse: 0.0933899\n",
      "[600]\ttraining's rmse: 0.091067\tvalid_1's rmse: 0.0927336\n",
      "[700]\ttraining's rmse: 0.090273\tvalid_1's rmse: 0.0922734\n",
      "[800]\ttraining's rmse: 0.0895917\tvalid_1's rmse: 0.0918203\n",
      "[900]\ttraining's rmse: 0.0889877\tvalid_1's rmse: 0.0914981\n",
      "[1000]\ttraining's rmse: 0.0884425\tvalid_1's rmse: 0.0912467\n",
      "[1100]\ttraining's rmse: 0.0879443\tvalid_1's rmse: 0.0909303\n",
      "[1200]\ttraining's rmse: 0.0874534\tvalid_1's rmse: 0.0907251\n",
      "[1300]\ttraining's rmse: 0.0869892\tvalid_1's rmse: 0.0905398\n",
      "[1400]\ttraining's rmse: 0.0865866\tvalid_1's rmse: 0.0903532\n",
      "[1500]\ttraining's rmse: 0.0861944\tvalid_1's rmse: 0.0902036\n",
      "[1600]\ttraining's rmse: 0.0858368\tvalid_1's rmse: 0.0900724\n",
      "[1700]\ttraining's rmse: 0.0854989\tvalid_1's rmse: 0.089946\n",
      "[1800]\ttraining's rmse: 0.085151\tvalid_1's rmse: 0.0898757\n",
      "[1900]\ttraining's rmse: 0.0848586\tvalid_1's rmse: 0.0898604\n",
      "[2000]\ttraining's rmse: 0.0845112\tvalid_1's rmse: 0.0897596\n",
      "[2100]\ttraining's rmse: 0.0842101\tvalid_1's rmse: 0.0896585\n",
      "[2200]\ttraining's rmse: 0.0839058\tvalid_1's rmse: 0.0896574\n",
      "[2300]\ttraining's rmse: 0.0836228\tvalid_1's rmse: 0.0896455\n",
      "[2400]\ttraining's rmse: 0.08335\tvalid_1's rmse: 0.0895848\n",
      "[2500]\ttraining's rmse: 0.0830936\tvalid_1's rmse: 0.0895267\n",
      "[2600]\ttraining's rmse: 0.0828324\tvalid_1's rmse: 0.0894916\n",
      "[2700]\ttraining's rmse: 0.082606\tvalid_1's rmse: 0.0894271\n",
      "[2800]\ttraining's rmse: 0.0823703\tvalid_1's rmse: 0.0894123\n",
      "[2900]\ttraining's rmse: 0.0821364\tvalid_1's rmse: 0.0892202\n",
      "[3000]\ttraining's rmse: 0.0818992\tvalid_1's rmse: 0.0892737\n",
      "[3100]\ttraining's rmse: 0.0816662\tvalid_1's rmse: 0.0891305\n",
      "[3200]\ttraining's rmse: 0.0814903\tvalid_1's rmse: 0.0891312\n",
      "[3300]\ttraining's rmse: 0.0812693\tvalid_1's rmse: 0.0890702\n",
      "[3400]\ttraining's rmse: 0.0810347\tvalid_1's rmse: 0.0890908\n",
      "[3500]\ttraining's rmse: 0.0808359\tvalid_1's rmse: 0.0890724\n",
      "[3600]\ttraining's rmse: 0.0806417\tvalid_1's rmse: 0.0890448\n",
      "[3700]\ttraining's rmse: 0.0804268\tvalid_1's rmse: 0.0890686\n",
      "[3800]\ttraining's rmse: 0.080207\tvalid_1's rmse: 0.0890204\n",
      "[3900]\ttraining's rmse: 0.0799943\tvalid_1's rmse: 0.0889972\n",
      "[4000]\ttraining's rmse: 0.0797962\tvalid_1's rmse: 0.088974\n",
      "[4100]\ttraining's rmse: 0.079612\tvalid_1's rmse: 0.088867\n",
      "[4200]\ttraining's rmse: 0.079434\tvalid_1's rmse: 0.0888903\n",
      "[4300]\ttraining's rmse: 0.0792608\tvalid_1's rmse: 0.0888377\n",
      "[4400]\ttraining's rmse: 0.0790659\tvalid_1's rmse: 0.0888365\n",
      "[4500]\ttraining's rmse: 0.0788838\tvalid_1's rmse: 0.0887598\n",
      "[4600]\ttraining's rmse: 0.0786858\tvalid_1's rmse: 0.088739\n",
      "[4700]\ttraining's rmse: 0.0785115\tvalid_1's rmse: 0.0888017\n",
      "[4800]\ttraining's rmse: 0.078336\tvalid_1's rmse: 0.0886622\n",
      "[4900]\ttraining's rmse: 0.0781764\tvalid_1's rmse: 0.0887114\n",
      "[5000]\ttraining's rmse: 0.0780202\tvalid_1's rmse: 0.0887988\n",
      "[5100]\ttraining's rmse: 0.0778524\tvalid_1's rmse: 0.088877\n",
      "Early stopping, best iteration is:\n",
      "[4838]\ttraining's rmse: 0.0782761\tvalid_1's rmse: 0.0886492\n",
      "fold n4\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 0.107132\tvalid_1's rmse: 0.107122\n",
      "[200]\ttraining's rmse: 0.0977564\tvalid_1's rmse: 0.0981989\n",
      "[300]\ttraining's rmse: 0.0947316\tvalid_1's rmse: 0.0955122\n",
      "[400]\ttraining's rmse: 0.0929841\tvalid_1's rmse: 0.0942763\n",
      "[500]\ttraining's rmse: 0.0917719\tvalid_1's rmse: 0.0935678\n",
      "[600]\ttraining's rmse: 0.0908038\tvalid_1's rmse: 0.0930908\n",
      "[700]\ttraining's rmse: 0.0899674\tvalid_1's rmse: 0.0925771\n",
      "[800]\ttraining's rmse: 0.0892352\tvalid_1's rmse: 0.0922234\n",
      "[900]\ttraining's rmse: 0.0886543\tvalid_1's rmse: 0.092162\n",
      "[1000]\ttraining's rmse: 0.0880893\tvalid_1's rmse: 0.0920611\n",
      "[1100]\ttraining's rmse: 0.0875463\tvalid_1's rmse: 0.0918971\n",
      "[1200]\ttraining's rmse: 0.0871021\tvalid_1's rmse: 0.0918593\n",
      "[1300]\ttraining's rmse: 0.0866056\tvalid_1's rmse: 0.091729\n",
      "[1400]\ttraining's rmse: 0.086186\tvalid_1's rmse: 0.0915989\n",
      "[1500]\ttraining's rmse: 0.0857849\tvalid_1's rmse: 0.0915437\n",
      "[1600]\ttraining's rmse: 0.0853655\tvalid_1's rmse: 0.0913876\n",
      "[1700]\ttraining's rmse: 0.0849597\tvalid_1's rmse: 0.0911373\n",
      "[1800]\ttraining's rmse: 0.0846303\tvalid_1's rmse: 0.091026\n",
      "[1900]\ttraining's rmse: 0.0842929\tvalid_1's rmse: 0.091032\n",
      "[2000]\ttraining's rmse: 0.0839713\tvalid_1's rmse: 0.0908881\n",
      "[2100]\ttraining's rmse: 0.0836631\tvalid_1's rmse: 0.0908046\n",
      "[2200]\ttraining's rmse: 0.0833349\tvalid_1's rmse: 0.0907962\n",
      "[2300]\ttraining's rmse: 0.0830555\tvalid_1's rmse: 0.0908242\n",
      "[2400]\ttraining's rmse: 0.0827731\tvalid_1's rmse: 0.0908234\n",
      "[2500]\ttraining's rmse: 0.0825087\tvalid_1's rmse: 0.0908295\n",
      "Early stopping, best iteration is:\n",
      "[2265]\ttraining's rmse: 0.0831607\tvalid_1's rmse: 0.0906878\n",
      "fold n5\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 0.107022\tvalid_1's rmse: 0.108393\n",
      "[200]\ttraining's rmse: 0.0977669\tvalid_1's rmse: 0.0994121\n",
      "[300]\ttraining's rmse: 0.0947186\tvalid_1's rmse: 0.096675\n",
      "[400]\ttraining's rmse: 0.0930661\tvalid_1's rmse: 0.0955529\n",
      "[500]\ttraining's rmse: 0.0918034\tvalid_1's rmse: 0.0947807\n",
      "[600]\ttraining's rmse: 0.0908507\tvalid_1's rmse: 0.0941594\n",
      "[700]\ttraining's rmse: 0.090036\tvalid_1's rmse: 0.0937417\n",
      "[800]\ttraining's rmse: 0.0893291\tvalid_1's rmse: 0.0933953\n",
      "[900]\ttraining's rmse: 0.0887745\tvalid_1's rmse: 0.0931155\n",
      "[1000]\ttraining's rmse: 0.0882003\tvalid_1's rmse: 0.0928093\n",
      "[1100]\ttraining's rmse: 0.087719\tvalid_1's rmse: 0.0927086\n",
      "[1200]\ttraining's rmse: 0.0872571\tvalid_1's rmse: 0.0925197\n",
      "[1300]\ttraining's rmse: 0.0868384\tvalid_1's rmse: 0.0922797\n",
      "[1400]\ttraining's rmse: 0.0863941\tvalid_1's rmse: 0.0921572\n",
      "[1500]\ttraining's rmse: 0.0859955\tvalid_1's rmse: 0.0920723\n",
      "[1600]\ttraining's rmse: 0.0856055\tvalid_1's rmse: 0.091893\n",
      "[1700]\ttraining's rmse: 0.0852419\tvalid_1's rmse: 0.0917046\n",
      "[1800]\ttraining's rmse: 0.084899\tvalid_1's rmse: 0.0916971\n",
      "[1900]\ttraining's rmse: 0.0846193\tvalid_1's rmse: 0.0916304\n",
      "[2000]\ttraining's rmse: 0.0843259\tvalid_1's rmse: 0.0916102\n",
      "[2100]\ttraining's rmse: 0.0840014\tvalid_1's rmse: 0.0915964\n",
      "[2200]\ttraining's rmse: 0.0837055\tvalid_1's rmse: 0.0916732\n",
      "[2300]\ttraining's rmse: 0.083439\tvalid_1's rmse: 0.0916606\n",
      "[2400]\ttraining's rmse: 0.0831561\tvalid_1's rmse: 0.0916188\n",
      "Early stopping, best iteration is:\n",
      "[2125]\ttraining's rmse: 0.0839362\tvalid_1's rmse: 0.0915673\n",
      "fold n6\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 0.107135\tvalid_1's rmse: 0.107772\n",
      "[200]\ttraining's rmse: 0.0978778\tvalid_1's rmse: 0.0987081\n",
      "[300]\ttraining's rmse: 0.0949378\tvalid_1's rmse: 0.0959859\n",
      "[400]\ttraining's rmse: 0.0932785\tvalid_1's rmse: 0.0947385\n",
      "[500]\ttraining's rmse: 0.0920982\tvalid_1's rmse: 0.0937509\n",
      "[600]\ttraining's rmse: 0.0911598\tvalid_1's rmse: 0.0931088\n",
      "[700]\ttraining's rmse: 0.0903758\tvalid_1's rmse: 0.0925734\n",
      "[800]\ttraining's rmse: 0.0897084\tvalid_1's rmse: 0.0924296\n",
      "[900]\ttraining's rmse: 0.0890871\tvalid_1's rmse: 0.0921095\n",
      "[1000]\ttraining's rmse: 0.0884885\tvalid_1's rmse: 0.0918398\n",
      "[1100]\ttraining's rmse: 0.0879614\tvalid_1's rmse: 0.0916222\n",
      "[1200]\ttraining's rmse: 0.0874268\tvalid_1's rmse: 0.0914596\n",
      "[1300]\ttraining's rmse: 0.0869789\tvalid_1's rmse: 0.0911257\n",
      "[1400]\ttraining's rmse: 0.0865364\tvalid_1's rmse: 0.0909639\n",
      "[1500]\ttraining's rmse: 0.0861277\tvalid_1's rmse: 0.0908422\n",
      "[1600]\ttraining's rmse: 0.0857658\tvalid_1's rmse: 0.0906637\n",
      "[1700]\ttraining's rmse: 0.0854131\tvalid_1's rmse: 0.0904337\n",
      "[1800]\ttraining's rmse: 0.0850754\tvalid_1's rmse: 0.0903645\n",
      "[1900]\ttraining's rmse: 0.084729\tvalid_1's rmse: 0.0903592\n",
      "[2000]\ttraining's rmse: 0.0843943\tvalid_1's rmse: 0.0903202\n",
      "[2100]\ttraining's rmse: 0.0840711\tvalid_1's rmse: 0.0901661\n",
      "[2200]\ttraining's rmse: 0.0837613\tvalid_1's rmse: 0.0900392\n",
      "[2300]\ttraining's rmse: 0.0834624\tvalid_1's rmse: 0.0899717\n",
      "[2400]\ttraining's rmse: 0.0831739\tvalid_1's rmse: 0.0899081\n",
      "[2500]\ttraining's rmse: 0.0829208\tvalid_1's rmse: 0.0898786\n",
      "[2600]\ttraining's rmse: 0.0827064\tvalid_1's rmse: 0.0899255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2700]\ttraining's rmse: 0.0824493\tvalid_1's rmse: 0.0898696\n",
      "[2800]\ttraining's rmse: 0.0822148\tvalid_1's rmse: 0.089958\n",
      "Early stopping, best iteration is:\n",
      "[2546]\ttraining's rmse: 0.0828364\tvalid_1's rmse: 0.0897917\n",
      "fold n7\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 0.106834\tvalid_1's rmse: 0.108365\n",
      "[200]\ttraining's rmse: 0.0976058\tvalid_1's rmse: 0.0998723\n",
      "[300]\ttraining's rmse: 0.0945468\tvalid_1's rmse: 0.0976631\n",
      "[400]\ttraining's rmse: 0.0928986\tvalid_1's rmse: 0.0965758\n",
      "[500]\ttraining's rmse: 0.091664\tvalid_1's rmse: 0.095851\n",
      "[600]\ttraining's rmse: 0.0907595\tvalid_1's rmse: 0.0952874\n",
      "[700]\ttraining's rmse: 0.0899642\tvalid_1's rmse: 0.0948246\n",
      "[800]\ttraining's rmse: 0.0893448\tvalid_1's rmse: 0.0945629\n",
      "[900]\ttraining's rmse: 0.0887416\tvalid_1's rmse: 0.0943277\n",
      "[1000]\ttraining's rmse: 0.088157\tvalid_1's rmse: 0.0940035\n",
      "[1100]\ttraining's rmse: 0.0876781\tvalid_1's rmse: 0.0936583\n",
      "[1200]\ttraining's rmse: 0.0872167\tvalid_1's rmse: 0.0934405\n",
      "[1300]\ttraining's rmse: 0.0867826\tvalid_1's rmse: 0.0931966\n",
      "[1400]\ttraining's rmse: 0.0863652\tvalid_1's rmse: 0.0929974\n",
      "[1500]\ttraining's rmse: 0.0859309\tvalid_1's rmse: 0.0928344\n",
      "[1600]\ttraining's rmse: 0.0855769\tvalid_1's rmse: 0.0926718\n",
      "[1700]\ttraining's rmse: 0.0852262\tvalid_1's rmse: 0.0925498\n",
      "[1800]\ttraining's rmse: 0.0848625\tvalid_1's rmse: 0.0923642\n",
      "[1900]\ttraining's rmse: 0.0845402\tvalid_1's rmse: 0.0922483\n",
      "[2000]\ttraining's rmse: 0.0842125\tvalid_1's rmse: 0.0920966\n",
      "[2100]\ttraining's rmse: 0.0839068\tvalid_1's rmse: 0.0920865\n",
      "[2200]\ttraining's rmse: 0.0836235\tvalid_1's rmse: 0.0920003\n",
      "[2300]\ttraining's rmse: 0.0833239\tvalid_1's rmse: 0.0919328\n",
      "[2400]\ttraining's rmse: 0.0830347\tvalid_1's rmse: 0.091805\n",
      "[2500]\ttraining's rmse: 0.0827698\tvalid_1's rmse: 0.0918496\n",
      "[2600]\ttraining's rmse: 0.0825196\tvalid_1's rmse: 0.0918116\n",
      "[2700]\ttraining's rmse: 0.0822935\tvalid_1's rmse: 0.0917144\n",
      "[2800]\ttraining's rmse: 0.0820092\tvalid_1's rmse: 0.0916276\n",
      "[2900]\ttraining's rmse: 0.0817606\tvalid_1's rmse: 0.0915868\n",
      "[3000]\ttraining's rmse: 0.0815012\tvalid_1's rmse: 0.0916406\n",
      "[3100]\ttraining's rmse: 0.0812714\tvalid_1's rmse: 0.0916495\n",
      "Early stopping, best iteration is:\n",
      "[2869]\ttraining's rmse: 0.0818267\tvalid_1's rmse: 0.0915733\n",
      "fold n8\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 0.107374\tvalid_1's rmse: 0.103848\n",
      "[200]\ttraining's rmse: 0.0980441\tvalid_1's rmse: 0.0946038\n",
      "[300]\ttraining's rmse: 0.0950862\tvalid_1's rmse: 0.0917881\n",
      "[400]\ttraining's rmse: 0.0933167\tvalid_1's rmse: 0.0902108\n",
      "[500]\ttraining's rmse: 0.0920593\tvalid_1's rmse: 0.0892027\n",
      "[600]\ttraining's rmse: 0.0911269\tvalid_1's rmse: 0.0886826\n",
      "[700]\ttraining's rmse: 0.0903487\tvalid_1's rmse: 0.0882745\n",
      "[800]\ttraining's rmse: 0.0896409\tvalid_1's rmse: 0.0878245\n",
      "[900]\ttraining's rmse: 0.0889998\tvalid_1's rmse: 0.0875519\n",
      "[1000]\ttraining's rmse: 0.0884256\tvalid_1's rmse: 0.0872419\n",
      "[1100]\ttraining's rmse: 0.0878957\tvalid_1's rmse: 0.0870059\n",
      "[1200]\ttraining's rmse: 0.0874197\tvalid_1's rmse: 0.0868321\n",
      "[1300]\ttraining's rmse: 0.0869361\tvalid_1's rmse: 0.0866691\n",
      "[1400]\ttraining's rmse: 0.0865436\tvalid_1's rmse: 0.0866703\n",
      "[1500]\ttraining's rmse: 0.086158\tvalid_1's rmse: 0.0865358\n",
      "[1600]\ttraining's rmse: 0.0857717\tvalid_1's rmse: 0.0864192\n",
      "[1700]\ttraining's rmse: 0.0854382\tvalid_1's rmse: 0.0863399\n",
      "[1800]\ttraining's rmse: 0.0850984\tvalid_1's rmse: 0.0862976\n",
      "[1900]\ttraining's rmse: 0.0847734\tvalid_1's rmse: 0.0861368\n",
      "[2000]\ttraining's rmse: 0.0844566\tvalid_1's rmse: 0.0861491\n",
      "[2100]\ttraining's rmse: 0.0841496\tvalid_1's rmse: 0.0860573\n",
      "[2200]\ttraining's rmse: 0.08385\tvalid_1's rmse: 0.0859761\n",
      "[2300]\ttraining's rmse: 0.0835614\tvalid_1's rmse: 0.0860388\n",
      "[2400]\ttraining's rmse: 0.0832726\tvalid_1's rmse: 0.0860306\n",
      "Early stopping, best iteration is:\n",
      "[2147]\ttraining's rmse: 0.083998\tvalid_1's rmse: 0.0859608\n",
      "fold n9\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 0.106944\tvalid_1's rmse: 0.107348\n",
      "[200]\ttraining's rmse: 0.0975705\tvalid_1's rmse: 0.0992949\n",
      "[300]\ttraining's rmse: 0.0944727\tvalid_1's rmse: 0.0968491\n",
      "[400]\ttraining's rmse: 0.0927915\tvalid_1's rmse: 0.0957147\n",
      "[500]\ttraining's rmse: 0.0915884\tvalid_1's rmse: 0.0948419\n",
      "[600]\ttraining's rmse: 0.0906873\tvalid_1's rmse: 0.094263\n",
      "[700]\ttraining's rmse: 0.0899345\tvalid_1's rmse: 0.0938804\n",
      "[800]\ttraining's rmse: 0.0891878\tvalid_1's rmse: 0.0934427\n",
      "[900]\ttraining's rmse: 0.0885525\tvalid_1's rmse: 0.0930042\n",
      "[1000]\ttraining's rmse: 0.0880558\tvalid_1's rmse: 0.0926745\n",
      "[1100]\ttraining's rmse: 0.0875399\tvalid_1's rmse: 0.0923273\n",
      "[1200]\ttraining's rmse: 0.0870596\tvalid_1's rmse: 0.0921198\n",
      "[1300]\ttraining's rmse: 0.0866115\tvalid_1's rmse: 0.0919549\n",
      "[1400]\ttraining's rmse: 0.0861937\tvalid_1's rmse: 0.0917847\n",
      "[1500]\ttraining's rmse: 0.0858065\tvalid_1's rmse: 0.0916348\n",
      "[1600]\ttraining's rmse: 0.0854391\tvalid_1's rmse: 0.0915906\n",
      "[1700]\ttraining's rmse: 0.0850588\tvalid_1's rmse: 0.0914587\n",
      "[1800]\ttraining's rmse: 0.0847399\tvalid_1's rmse: 0.0913316\n",
      "[1900]\ttraining's rmse: 0.0844177\tvalid_1's rmse: 0.0911589\n",
      "[2000]\ttraining's rmse: 0.0841294\tvalid_1's rmse: 0.0911149\n",
      "[2100]\ttraining's rmse: 0.0838085\tvalid_1's rmse: 0.0911147\n",
      "[2200]\ttraining's rmse: 0.0835298\tvalid_1's rmse: 0.0910376\n",
      "[2300]\ttraining's rmse: 0.0832231\tvalid_1's rmse: 0.0908901\n",
      "[2400]\ttraining's rmse: 0.0829431\tvalid_1's rmse: 0.0908177\n",
      "[2500]\ttraining's rmse: 0.0826733\tvalid_1's rmse: 0.0907729\n",
      "[2600]\ttraining's rmse: 0.0824006\tvalid_1's rmse: 0.090651\n",
      "[2700]\ttraining's rmse: 0.0821621\tvalid_1's rmse: 0.0905743\n",
      "[2800]\ttraining's rmse: 0.0819145\tvalid_1's rmse: 0.090471\n",
      "[2900]\ttraining's rmse: 0.081695\tvalid_1's rmse: 0.0904194\n",
      "[3000]\ttraining's rmse: 0.0814598\tvalid_1's rmse: 0.0903355\n",
      "[3100]\ttraining's rmse: 0.0812489\tvalid_1's rmse: 0.0902722\n",
      "[3200]\ttraining's rmse: 0.0810063\tvalid_1's rmse: 0.0901798\n",
      "[3300]\ttraining's rmse: 0.0807991\tvalid_1's rmse: 0.0901165\n",
      "[3400]\ttraining's rmse: 0.0805773\tvalid_1's rmse: 0.0900633\n",
      "[3500]\ttraining's rmse: 0.0803564\tvalid_1's rmse: 0.0900315\n",
      "[3600]\ttraining's rmse: 0.0801563\tvalid_1's rmse: 0.09004\n",
      "[3700]\ttraining's rmse: 0.079956\tvalid_1's rmse: 0.0900495\n",
      "[3800]\ttraining's rmse: 0.0797583\tvalid_1's rmse: 0.0899817\n",
      "[3900]\ttraining's rmse: 0.0795439\tvalid_1's rmse: 0.0900063\n",
      "[4000]\ttraining's rmse: 0.0793529\tvalid_1's rmse: 0.0898939\n",
      "[4100]\ttraining's rmse: 0.0791901\tvalid_1's rmse: 0.0898012\n",
      "[4200]\ttraining's rmse: 0.0789938\tvalid_1's rmse: 0.0897928\n",
      "[4300]\ttraining's rmse: 0.078812\tvalid_1's rmse: 0.0897958\n",
      "[4400]\ttraining's rmse: 0.0786247\tvalid_1's rmse: 0.0897274\n",
      "[4500]\ttraining's rmse: 0.0784139\tvalid_1's rmse: 0.089753\n",
      "[4600]\ttraining's rmse: 0.0782285\tvalid_1's rmse: 0.0897614\n",
      "[4700]\ttraining's rmse: 0.0780466\tvalid_1's rmse: 0.0897541\n",
      "Early stopping, best iteration is:\n",
      "[4462]\ttraining's rmse: 0.0784884\tvalid_1's rmse: 0.0896535\n",
      "CV score: 0.08959 \n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "features = [c for c in train_df.columns if c not in ['Target']]\n",
    "target = train_df['Target']\n",
    "\n",
    "folds = KFold(n_splits=10, shuffle=True, random_state=15)\n",
    "oof_lgb = np.zeros(len(train_df))\n",
    "predictions_lgb = np.zeros(len(test_df))\n",
    "start = time.time()\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
    "    print(\"fold n{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "\n",
    "    num_round = 13000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 500)\n",
    "    oof_lgb[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    predictions_lgb += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "oof_lgb[oof_lgb < 0] = 0\n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof_lgb, target)**0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SampleSubmission (1).csv')\n",
    "df['Target'] = predictions_lgb\n",
    "df.to_csv('LGBM.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 29, ## using 29 and 30\n",
    "     'min_data_in_leaf': 50, \n",
    "     'objective':'regression',\n",
    "     'max_depth': 18,\n",
    "     'learning_rate': 0.006,\n",
    "     \"boosting\": \"gbdt\",\n",
    "     \"feature_fraction\": 0.2,\n",
    "     \"bagging_freq\": 0,\n",
    "     \"bagging_fraction\": 1.0 ,\n",
    "     \"bagging_seed\": 4,\n",
    "     \"metric\": 'rmse',\n",
    "     \"verbosity\": 1,\n",
    "     \"verbose_eval\": False,\n",
    "    \"early_stopping_rounds\" : 300\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n0\n",
      "Training until validation scores don't improve for 300 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 0.14661\tvalid_1's rmse: 0.147758\n",
      "[200]\ttraining's rmse: 0.123237\tvalid_1's rmse: 0.124645\n",
      "[300]\ttraining's rmse: 0.111497\tvalid_1's rmse: 0.113291\n",
      "[400]\ttraining's rmse: 0.104883\tvalid_1's rmse: 0.107037\n",
      "[500]\ttraining's rmse: 0.100622\tvalid_1's rmse: 0.103078\n",
      "[600]\ttraining's rmse: 0.097559\tvalid_1's rmse: 0.100287\n",
      "[700]\ttraining's rmse: 0.0952818\tvalid_1's rmse: 0.0982746\n",
      "[800]\ttraining's rmse: 0.0934468\tvalid_1's rmse: 0.0967272\n",
      "[900]\ttraining's rmse: 0.0919156\tvalid_1's rmse: 0.0954864\n",
      "[1000]\ttraining's rmse: 0.0906328\tvalid_1's rmse: 0.0944547\n",
      "[1100]\ttraining's rmse: 0.0895783\tvalid_1's rmse: 0.0936308\n",
      "[1200]\ttraining's rmse: 0.0886572\tvalid_1's rmse: 0.0929765\n",
      "[1300]\ttraining's rmse: 0.0878594\tvalid_1's rmse: 0.0924175\n",
      "[1400]\ttraining's rmse: 0.0871481\tvalid_1's rmse: 0.0919256\n",
      "[1500]\ttraining's rmse: 0.0865106\tvalid_1's rmse: 0.0915031\n",
      "[1600]\ttraining's rmse: 0.0859233\tvalid_1's rmse: 0.0911367\n",
      "[1700]\ttraining's rmse: 0.0853804\tvalid_1's rmse: 0.0908071\n",
      "[1800]\ttraining's rmse: 0.0848774\tvalid_1's rmse: 0.0904972\n",
      "[1900]\ttraining's rmse: 0.084406\tvalid_1's rmse: 0.0902138\n",
      "[2000]\ttraining's rmse: 0.0839578\tvalid_1's rmse: 0.0899432\n",
      "[2100]\ttraining's rmse: 0.0835325\tvalid_1's rmse: 0.0896875\n",
      "[2200]\ttraining's rmse: 0.0831329\tvalid_1's rmse: 0.0894535\n",
      "[2300]\ttraining's rmse: 0.0827683\tvalid_1's rmse: 0.0892535\n",
      "[2400]\ttraining's rmse: 0.0824116\tvalid_1's rmse: 0.0890746\n",
      "[2500]\ttraining's rmse: 0.0820741\tvalid_1's rmse: 0.0889315\n",
      "[2600]\ttraining's rmse: 0.0817561\tvalid_1's rmse: 0.0887999\n",
      "[2700]\ttraining's rmse: 0.0814511\tvalid_1's rmse: 0.0886905\n",
      "[2800]\ttraining's rmse: 0.0811496\tvalid_1's rmse: 0.0886014\n",
      "[2900]\ttraining's rmse: 0.0808579\tvalid_1's rmse: 0.0885033\n",
      "[3000]\ttraining's rmse: 0.0805749\tvalid_1's rmse: 0.0884088\n",
      "[3100]\ttraining's rmse: 0.0803051\tvalid_1's rmse: 0.0883231\n",
      "[3200]\ttraining's rmse: 0.080043\tvalid_1's rmse: 0.0882417\n",
      "[3300]\ttraining's rmse: 0.0797876\tvalid_1's rmse: 0.0881907\n",
      "[3400]\ttraining's rmse: 0.0795282\tvalid_1's rmse: 0.0881259\n",
      "[3500]\ttraining's rmse: 0.079277\tvalid_1's rmse: 0.0880766\n",
      "[3600]\ttraining's rmse: 0.0790303\tvalid_1's rmse: 0.0880296\n",
      "[3700]\ttraining's rmse: 0.0787948\tvalid_1's rmse: 0.0879716\n",
      "[3800]\ttraining's rmse: 0.0785656\tvalid_1's rmse: 0.0879387\n",
      "[3900]\ttraining's rmse: 0.0783454\tvalid_1's rmse: 0.0878931\n",
      "[4000]\ttraining's rmse: 0.0781293\tvalid_1's rmse: 0.0878629\n",
      "[4100]\ttraining's rmse: 0.077921\tvalid_1's rmse: 0.087849\n",
      "[4200]\ttraining's rmse: 0.0777113\tvalid_1's rmse: 0.0878276\n",
      "[4300]\ttraining's rmse: 0.0775034\tvalid_1's rmse: 0.0878084\n",
      "[4400]\ttraining's rmse: 0.077295\tvalid_1's rmse: 0.0877864\n",
      "[4500]\ttraining's rmse: 0.0771002\tvalid_1's rmse: 0.0877562\n",
      "[4600]\ttraining's rmse: 0.0769007\tvalid_1's rmse: 0.0877322\n",
      "[4700]\ttraining's rmse: 0.0767133\tvalid_1's rmse: 0.0877225\n",
      "[4800]\ttraining's rmse: 0.0765233\tvalid_1's rmse: 0.0877177\n",
      "[4900]\ttraining's rmse: 0.0763324\tvalid_1's rmse: 0.0877092\n",
      "[5000]\ttraining's rmse: 0.0761503\tvalid_1's rmse: 0.0877048\n",
      "[5100]\ttraining's rmse: 0.075959\tvalid_1's rmse: 0.0877051\n",
      "[5200]\ttraining's rmse: 0.0757772\tvalid_1's rmse: 0.0876976\n",
      "[5300]\ttraining's rmse: 0.0755948\tvalid_1's rmse: 0.0876873\n",
      "[5400]\ttraining's rmse: 0.0754097\tvalid_1's rmse: 0.0876704\n",
      "[5500]\ttraining's rmse: 0.0752336\tvalid_1's rmse: 0.0876596\n",
      "[5600]\ttraining's rmse: 0.0750623\tvalid_1's rmse: 0.0876432\n",
      "[5700]\ttraining's rmse: 0.0748892\tvalid_1's rmse: 0.0876293\n",
      "[5800]\ttraining's rmse: 0.0747196\tvalid_1's rmse: 0.0876165\n",
      "[5900]\ttraining's rmse: 0.074545\tvalid_1's rmse: 0.0875974\n",
      "[6000]\ttraining's rmse: 0.0743767\tvalid_1's rmse: 0.0875889\n",
      "[6100]\ttraining's rmse: 0.0742126\tvalid_1's rmse: 0.0875646\n",
      "[6200]\ttraining's rmse: 0.0740439\tvalid_1's rmse: 0.0875481\n",
      "[6300]\ttraining's rmse: 0.0738789\tvalid_1's rmse: 0.0875321\n",
      "[6400]\ttraining's rmse: 0.0737094\tvalid_1's rmse: 0.087519\n",
      "[6500]\ttraining's rmse: 0.0735409\tvalid_1's rmse: 0.0875145\n",
      "[6600]\ttraining's rmse: 0.0733776\tvalid_1's rmse: 0.0875152\n",
      "[6700]\ttraining's rmse: 0.0732211\tvalid_1's rmse: 0.087508\n",
      "[6800]\ttraining's rmse: 0.0730612\tvalid_1's rmse: 0.0874966\n",
      "[6900]\ttraining's rmse: 0.0729019\tvalid_1's rmse: 0.087491\n",
      "[7000]\ttraining's rmse: 0.0727461\tvalid_1's rmse: 0.0874997\n",
      "[7100]\ttraining's rmse: 0.0725902\tvalid_1's rmse: 0.087515\n",
      "[7200]\ttraining's rmse: 0.0724355\tvalid_1's rmse: 0.0875171\n",
      "Early stopping, best iteration is:\n",
      "[6900]\ttraining's rmse: 0.0729019\tvalid_1's rmse: 0.087491\n",
      "fold n1\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 0.146962\tvalid_1's rmse: 0.145466\n",
      "[200]\ttraining's rmse: 0.12355\tvalid_1's rmse: 0.122537\n",
      "[300]\ttraining's rmse: 0.111813\tvalid_1's rmse: 0.111059\n",
      "[400]\ttraining's rmse: 0.105189\tvalid_1's rmse: 0.104656\n",
      "[500]\ttraining's rmse: 0.100899\tvalid_1's rmse: 0.100588\n",
      "[600]\ttraining's rmse: 0.097823\tvalid_1's rmse: 0.0977786\n",
      "[700]\ttraining's rmse: 0.0955261\tvalid_1's rmse: 0.0957284\n",
      "[800]\ttraining's rmse: 0.0936808\tvalid_1's rmse: 0.0941701\n",
      "[900]\ttraining's rmse: 0.092141\tvalid_1's rmse: 0.0929362\n",
      "[1000]\ttraining's rmse: 0.0908332\tvalid_1's rmse: 0.0919362\n",
      "[1100]\ttraining's rmse: 0.089737\tvalid_1's rmse: 0.0911284\n",
      "[1200]\ttraining's rmse: 0.0887937\tvalid_1's rmse: 0.0904595\n",
      "[1300]\ttraining's rmse: 0.0879825\tvalid_1's rmse: 0.0899203\n",
      "[1400]\ttraining's rmse: 0.0872557\tvalid_1's rmse: 0.0894756\n",
      "[1500]\ttraining's rmse: 0.0866075\tvalid_1's rmse: 0.0891149\n",
      "[1600]\ttraining's rmse: 0.0860141\tvalid_1's rmse: 0.0887771\n",
      "[1700]\ttraining's rmse: 0.0854612\tvalid_1's rmse: 0.0884923\n",
      "[1800]\ttraining's rmse: 0.084959\tvalid_1's rmse: 0.0882448\n",
      "[1900]\ttraining's rmse: 0.0844958\tvalid_1's rmse: 0.088045\n",
      "[2000]\ttraining's rmse: 0.0840403\tvalid_1's rmse: 0.0878683\n",
      "[2100]\ttraining's rmse: 0.08361\tvalid_1's rmse: 0.0877046\n",
      "[2200]\ttraining's rmse: 0.0831986\tvalid_1's rmse: 0.0875699\n",
      "[2300]\ttraining's rmse: 0.0828002\tvalid_1's rmse: 0.0874597\n",
      "[2400]\ttraining's rmse: 0.0824348\tvalid_1's rmse: 0.0873755\n",
      "[2500]\ttraining's rmse: 0.0820922\tvalid_1's rmse: 0.0873128\n",
      "[2600]\ttraining's rmse: 0.0817676\tvalid_1's rmse: 0.0872627\n",
      "[2700]\ttraining's rmse: 0.0814579\tvalid_1's rmse: 0.0871991\n",
      "[2800]\ttraining's rmse: 0.0811604\tvalid_1's rmse: 0.0871622\n",
      "[2900]\ttraining's rmse: 0.0808645\tvalid_1's rmse: 0.0871264\n",
      "[3000]\ttraining's rmse: 0.0805764\tvalid_1's rmse: 0.0870683\n",
      "[3100]\ttraining's rmse: 0.080308\tvalid_1's rmse: 0.0870234\n",
      "[3200]\ttraining's rmse: 0.0800458\tvalid_1's rmse: 0.0869902\n",
      "[3300]\ttraining's rmse: 0.0797901\tvalid_1's rmse: 0.0869548\n",
      "[3400]\ttraining's rmse: 0.079531\tvalid_1's rmse: 0.0869107\n",
      "[3500]\ttraining's rmse: 0.0792741\tvalid_1's rmse: 0.0868935\n",
      "[3600]\ttraining's rmse: 0.0790241\tvalid_1's rmse: 0.0868766\n",
      "[3700]\ttraining's rmse: 0.0787823\tvalid_1's rmse: 0.0868581\n",
      "[3800]\ttraining's rmse: 0.0785353\tvalid_1's rmse: 0.0868218\n",
      "[3900]\ttraining's rmse: 0.0783039\tvalid_1's rmse: 0.086802\n",
      "[4000]\ttraining's rmse: 0.078076\tvalid_1's rmse: 0.0867806\n",
      "[4100]\ttraining's rmse: 0.0778556\tvalid_1's rmse: 0.0867621\n",
      "[4200]\ttraining's rmse: 0.0776454\tvalid_1's rmse: 0.0867438\n",
      "[4300]\ttraining's rmse: 0.077436\tvalid_1's rmse: 0.086731\n",
      "[4400]\ttraining's rmse: 0.0772289\tvalid_1's rmse: 0.086705\n",
      "[4500]\ttraining's rmse: 0.077022\tvalid_1's rmse: 0.086693\n",
      "[4600]\ttraining's rmse: 0.0768263\tvalid_1's rmse: 0.0866799\n",
      "[4700]\ttraining's rmse: 0.0766244\tvalid_1's rmse: 0.0866758\n",
      "[4800]\ttraining's rmse: 0.0764271\tvalid_1's rmse: 0.0866664\n",
      "[4900]\ttraining's rmse: 0.0762336\tvalid_1's rmse: 0.0866621\n",
      "[5000]\ttraining's rmse: 0.0760453\tvalid_1's rmse: 0.0866618\n",
      "[5100]\ttraining's rmse: 0.0758569\tvalid_1's rmse: 0.0866597\n",
      "[5200]\ttraining's rmse: 0.0756686\tvalid_1's rmse: 0.0866525\n",
      "[5300]\ttraining's rmse: 0.0754862\tvalid_1's rmse: 0.0866525\n",
      "[5400]\ttraining's rmse: 0.0753124\tvalid_1's rmse: 0.0866659\n",
      "[5500]\ttraining's rmse: 0.0751372\tvalid_1's rmse: 0.0866748\n",
      "Early stopping, best iteration is:\n",
      "[5240]\ttraining's rmse: 0.0755957\tvalid_1's rmse: 0.0866469\n",
      "fold n2\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 0.146428\tvalid_1's rmse: 0.150132\n",
      "[200]\ttraining's rmse: 0.12299\tvalid_1's rmse: 0.127431\n",
      "[300]\ttraining's rmse: 0.111233\tvalid_1's rmse: 0.116279\n",
      "[400]\ttraining's rmse: 0.104601\tvalid_1's rmse: 0.110167\n",
      "[500]\ttraining's rmse: 0.100312\tvalid_1's rmse: 0.106333\n",
      "[600]\ttraining's rmse: 0.0972368\tvalid_1's rmse: 0.103718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700]\ttraining's rmse: 0.0949402\tvalid_1's rmse: 0.101843\n",
      "[800]\ttraining's rmse: 0.0930744\tvalid_1's rmse: 0.100371\n",
      "[900]\ttraining's rmse: 0.0915298\tvalid_1's rmse: 0.0991793\n",
      "[1000]\ttraining's rmse: 0.0902387\tvalid_1's rmse: 0.0982075\n",
      "[1100]\ttraining's rmse: 0.0891736\tvalid_1's rmse: 0.0974965\n",
      "[1200]\ttraining's rmse: 0.0882585\tvalid_1's rmse: 0.0968992\n",
      "[1300]\ttraining's rmse: 0.0874434\tvalid_1's rmse: 0.0964225\n",
      "[1400]\ttraining's rmse: 0.0867241\tvalid_1's rmse: 0.0960254\n",
      "[1500]\ttraining's rmse: 0.0860781\tvalid_1's rmse: 0.0957025\n",
      "[1600]\ttraining's rmse: 0.0854928\tvalid_1's rmse: 0.0954049\n",
      "[1700]\ttraining's rmse: 0.0849518\tvalid_1's rmse: 0.0951068\n",
      "[1800]\ttraining's rmse: 0.0844401\tvalid_1's rmse: 0.0948547\n",
      "[1900]\ttraining's rmse: 0.0839562\tvalid_1's rmse: 0.0946388\n",
      "[2000]\ttraining's rmse: 0.0835028\tvalid_1's rmse: 0.09444\n",
      "[2100]\ttraining's rmse: 0.0830796\tvalid_1's rmse: 0.0942664\n",
      "[2200]\ttraining's rmse: 0.0826864\tvalid_1's rmse: 0.0941167\n",
      "[2300]\ttraining's rmse: 0.0823295\tvalid_1's rmse: 0.0939725\n",
      "[2400]\ttraining's rmse: 0.0819848\tvalid_1's rmse: 0.0938625\n",
      "[2500]\ttraining's rmse: 0.0816555\tvalid_1's rmse: 0.0937577\n",
      "[2600]\ttraining's rmse: 0.0813356\tvalid_1's rmse: 0.0936533\n",
      "[2700]\ttraining's rmse: 0.0810227\tvalid_1's rmse: 0.0935532\n",
      "[2800]\ttraining's rmse: 0.0807179\tvalid_1's rmse: 0.0934671\n",
      "[2900]\ttraining's rmse: 0.0804278\tvalid_1's rmse: 0.0933761\n",
      "[3000]\ttraining's rmse: 0.0801501\tvalid_1's rmse: 0.0933057\n",
      "[3100]\ttraining's rmse: 0.0798895\tvalid_1's rmse: 0.093237\n",
      "[3200]\ttraining's rmse: 0.0796281\tvalid_1's rmse: 0.0931572\n",
      "[3300]\ttraining's rmse: 0.0793715\tvalid_1's rmse: 0.0930681\n",
      "[3400]\ttraining's rmse: 0.0791249\tvalid_1's rmse: 0.0929867\n",
      "[3500]\ttraining's rmse: 0.0788818\tvalid_1's rmse: 0.0929154\n",
      "[3600]\ttraining's rmse: 0.078648\tvalid_1's rmse: 0.0928576\n",
      "[3700]\ttraining's rmse: 0.0784181\tvalid_1's rmse: 0.0928208\n",
      "[3800]\ttraining's rmse: 0.0781928\tvalid_1's rmse: 0.0927924\n",
      "[3900]\ttraining's rmse: 0.0779776\tvalid_1's rmse: 0.0927617\n",
      "[4000]\ttraining's rmse: 0.0777657\tvalid_1's rmse: 0.0927383\n",
      "[4100]\ttraining's rmse: 0.0775531\tvalid_1's rmse: 0.0927114\n",
      "[4200]\ttraining's rmse: 0.0773398\tvalid_1's rmse: 0.092678\n",
      "[4300]\ttraining's rmse: 0.0771318\tvalid_1's rmse: 0.0926805\n",
      "[4400]\ttraining's rmse: 0.0769326\tvalid_1's rmse: 0.092687\n",
      "[4500]\ttraining's rmse: 0.0767326\tvalid_1's rmse: 0.0926787\n",
      "[4600]\ttraining's rmse: 0.0765347\tvalid_1's rmse: 0.0926675\n",
      "[4700]\ttraining's rmse: 0.0763398\tvalid_1's rmse: 0.0926586\n",
      "[4800]\ttraining's rmse: 0.0761518\tvalid_1's rmse: 0.0926407\n",
      "[4900]\ttraining's rmse: 0.0759672\tvalid_1's rmse: 0.0926146\n",
      "[5000]\ttraining's rmse: 0.0757856\tvalid_1's rmse: 0.092611\n",
      "[5100]\ttraining's rmse: 0.0755956\tvalid_1's rmse: 0.0925958\n",
      "[5200]\ttraining's rmse: 0.0754131\tvalid_1's rmse: 0.0925758\n",
      "[5300]\ttraining's rmse: 0.0752276\tvalid_1's rmse: 0.0925694\n",
      "[5400]\ttraining's rmse: 0.075048\tvalid_1's rmse: 0.0925622\n",
      "[5500]\ttraining's rmse: 0.0748645\tvalid_1's rmse: 0.0925479\n",
      "[5600]\ttraining's rmse: 0.0746775\tvalid_1's rmse: 0.0925464\n",
      "[5700]\ttraining's rmse: 0.0744981\tvalid_1's rmse: 0.0925562\n",
      "[5800]\ttraining's rmse: 0.0743169\tvalid_1's rmse: 0.0925185\n",
      "[5900]\ttraining's rmse: 0.0741463\tvalid_1's rmse: 0.0924945\n",
      "[6000]\ttraining's rmse: 0.073984\tvalid_1's rmse: 0.0924629\n",
      "[6100]\ttraining's rmse: 0.0738226\tvalid_1's rmse: 0.0924335\n",
      "[6200]\ttraining's rmse: 0.0736557\tvalid_1's rmse: 0.0924211\n",
      "[6300]\ttraining's rmse: 0.0734944\tvalid_1's rmse: 0.0923943\n",
      "[6400]\ttraining's rmse: 0.073327\tvalid_1's rmse: 0.0923708\n",
      "[6500]\ttraining's rmse: 0.0731643\tvalid_1's rmse: 0.0923562\n",
      "[6600]\ttraining's rmse: 0.0730008\tvalid_1's rmse: 0.0923577\n",
      "[6700]\ttraining's rmse: 0.0728424\tvalid_1's rmse: 0.0923496\n",
      "[6800]\ttraining's rmse: 0.0726913\tvalid_1's rmse: 0.0923441\n",
      "[6900]\ttraining's rmse: 0.0725332\tvalid_1's rmse: 0.0923257\n",
      "[7000]\ttraining's rmse: 0.0723829\tvalid_1's rmse: 0.0923177\n",
      "[7100]\ttraining's rmse: 0.0722321\tvalid_1's rmse: 0.0923169\n",
      "[7200]\ttraining's rmse: 0.0720813\tvalid_1's rmse: 0.092312\n",
      "[7300]\ttraining's rmse: 0.0719255\tvalid_1's rmse: 0.0922981\n",
      "[7400]\ttraining's rmse: 0.0717728\tvalid_1's rmse: 0.0922744\n",
      "[7500]\ttraining's rmse: 0.0716217\tvalid_1's rmse: 0.092265\n",
      "[7600]\ttraining's rmse: 0.0714783\tvalid_1's rmse: 0.0922633\n",
      "[7700]\ttraining's rmse: 0.0713325\tvalid_1's rmse: 0.0922632\n",
      "[7800]\ttraining's rmse: 0.0711832\tvalid_1's rmse: 0.0922627\n",
      "[7900]\ttraining's rmse: 0.0710324\tvalid_1's rmse: 0.0922621\n",
      "[8000]\ttraining's rmse: 0.0708984\tvalid_1's rmse: 0.0922571\n",
      "[8100]\ttraining's rmse: 0.0707593\tvalid_1's rmse: 0.0922692\n",
      "[8200]\ttraining's rmse: 0.0706215\tvalid_1's rmse: 0.0922648\n",
      "Early stopping, best iteration is:\n",
      "[7986]\ttraining's rmse: 0.0709189\tvalid_1's rmse: 0.0922549\n",
      "fold n3\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 0.146486\tvalid_1's rmse: 0.14919\n",
      "[200]\ttraining's rmse: 0.123118\tvalid_1's rmse: 0.126257\n",
      "[300]\ttraining's rmse: 0.111428\tvalid_1's rmse: 0.115059\n",
      "[400]\ttraining's rmse: 0.104838\tvalid_1's rmse: 0.108877\n",
      "[500]\ttraining's rmse: 0.100565\tvalid_1's rmse: 0.104936\n",
      "[600]\ttraining's rmse: 0.0975352\tvalid_1's rmse: 0.102196\n",
      "[700]\ttraining's rmse: 0.0952536\tvalid_1's rmse: 0.100094\n",
      "[800]\ttraining's rmse: 0.0934056\tvalid_1's rmse: 0.0984251\n",
      "[900]\ttraining's rmse: 0.0918789\tvalid_1's rmse: 0.0970702\n",
      "[1000]\ttraining's rmse: 0.0906021\tvalid_1's rmse: 0.0959865\n",
      "[1100]\ttraining's rmse: 0.0895385\tvalid_1's rmse: 0.095108\n",
      "[1200]\ttraining's rmse: 0.0886032\tvalid_1's rmse: 0.0943345\n",
      "[1300]\ttraining's rmse: 0.0877924\tvalid_1's rmse: 0.0936629\n",
      "[1400]\ttraining's rmse: 0.0870602\tvalid_1's rmse: 0.0931174\n",
      "[1500]\ttraining's rmse: 0.0864065\tvalid_1's rmse: 0.0926761\n",
      "[1600]\ttraining's rmse: 0.0857905\tvalid_1's rmse: 0.092285\n",
      "[1700]\ttraining's rmse: 0.0852373\tvalid_1's rmse: 0.0919504\n",
      "[1800]\ttraining's rmse: 0.0847404\tvalid_1's rmse: 0.091681\n",
      "[1900]\ttraining's rmse: 0.0842715\tvalid_1's rmse: 0.0914607\n",
      "[2000]\ttraining's rmse: 0.0838223\tvalid_1's rmse: 0.0912353\n",
      "[2100]\ttraining's rmse: 0.0834056\tvalid_1's rmse: 0.0910326\n",
      "[2200]\ttraining's rmse: 0.0830128\tvalid_1's rmse: 0.0908471\n",
      "[2300]\ttraining's rmse: 0.0826315\tvalid_1's rmse: 0.0906903\n",
      "[2400]\ttraining's rmse: 0.0822677\tvalid_1's rmse: 0.0905649\n",
      "[2500]\ttraining's rmse: 0.081903\tvalid_1's rmse: 0.0904273\n",
      "[2600]\ttraining's rmse: 0.0815649\tvalid_1's rmse: 0.090296\n",
      "[2700]\ttraining's rmse: 0.0812434\tvalid_1's rmse: 0.0901883\n",
      "[2800]\ttraining's rmse: 0.0809257\tvalid_1's rmse: 0.090078\n",
      "[2900]\ttraining's rmse: 0.080618\tvalid_1's rmse: 0.0899917\n",
      "[3000]\ttraining's rmse: 0.0803269\tvalid_1's rmse: 0.0899057\n",
      "[3100]\ttraining's rmse: 0.0800483\tvalid_1's rmse: 0.0898168\n",
      "[3200]\ttraining's rmse: 0.0797769\tvalid_1's rmse: 0.0897314\n",
      "[3300]\ttraining's rmse: 0.0795167\tvalid_1's rmse: 0.08966\n",
      "[3400]\ttraining's rmse: 0.0792632\tvalid_1's rmse: 0.0895834\n",
      "[3500]\ttraining's rmse: 0.0790094\tvalid_1's rmse: 0.089534\n",
      "[3600]\ttraining's rmse: 0.0787712\tvalid_1's rmse: 0.0894848\n",
      "[3700]\ttraining's rmse: 0.0785379\tvalid_1's rmse: 0.0894377\n",
      "[3800]\ttraining's rmse: 0.0783098\tvalid_1's rmse: 0.089397\n",
      "[3900]\ttraining's rmse: 0.0780842\tvalid_1's rmse: 0.0893527\n",
      "[4000]\ttraining's rmse: 0.0778704\tvalid_1's rmse: 0.0893056\n",
      "[4100]\ttraining's rmse: 0.0776692\tvalid_1's rmse: 0.0892779\n",
      "[4200]\ttraining's rmse: 0.0774661\tvalid_1's rmse: 0.0892486\n",
      "[4300]\ttraining's rmse: 0.0772685\tvalid_1's rmse: 0.0892073\n",
      "[4400]\ttraining's rmse: 0.0770695\tvalid_1's rmse: 0.0891779\n",
      "[4500]\ttraining's rmse: 0.0768724\tvalid_1's rmse: 0.0891565\n",
      "[4600]\ttraining's rmse: 0.0766815\tvalid_1's rmse: 0.0891388\n",
      "[4700]\ttraining's rmse: 0.076488\tvalid_1's rmse: 0.0891221\n",
      "[4800]\ttraining's rmse: 0.0762923\tvalid_1's rmse: 0.0891017\n",
      "[4900]\ttraining's rmse: 0.0760992\tvalid_1's rmse: 0.0890967\n",
      "[5000]\ttraining's rmse: 0.0759083\tvalid_1's rmse: 0.0890921\n",
      "[5100]\ttraining's rmse: 0.0757282\tvalid_1's rmse: 0.0890841\n",
      "[5200]\ttraining's rmse: 0.0755514\tvalid_1's rmse: 0.0890814\n",
      "[5300]\ttraining's rmse: 0.0753714\tvalid_1's rmse: 0.0890804\n",
      "[5400]\ttraining's rmse: 0.0751971\tvalid_1's rmse: 0.0890864\n",
      "Early stopping, best iteration is:\n",
      "[5144]\ttraining's rmse: 0.0756501\tvalid_1's rmse: 0.0890765\n",
      "fold n4\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 0.146758\tvalid_1's rmse: 0.146791\n",
      "[200]\ttraining's rmse: 0.123308\tvalid_1's rmse: 0.124196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttraining's rmse: 0.11154\tvalid_1's rmse: 0.113038\n",
      "[400]\ttraining's rmse: 0.104873\tvalid_1's rmse: 0.106962\n",
      "[500]\ttraining's rmse: 0.100559\tvalid_1's rmse: 0.103148\n",
      "[600]\ttraining's rmse: 0.0974572\tvalid_1's rmse: 0.100509\n",
      "[700]\ttraining's rmse: 0.0951573\tvalid_1's rmse: 0.0986452\n",
      "[800]\ttraining's rmse: 0.0933029\tvalid_1's rmse: 0.0971902\n",
      "[900]\ttraining's rmse: 0.0917382\tvalid_1's rmse: 0.0960331\n",
      "[1000]\ttraining's rmse: 0.0904159\tvalid_1's rmse: 0.0951107\n",
      "[1100]\ttraining's rmse: 0.0893327\tvalid_1's rmse: 0.0944099\n",
      "[1200]\ttraining's rmse: 0.0883804\tvalid_1's rmse: 0.0938174\n",
      "[1300]\ttraining's rmse: 0.0875451\tvalid_1's rmse: 0.0933445\n",
      "[1400]\ttraining's rmse: 0.0867948\tvalid_1's rmse: 0.0929657\n",
      "[1500]\ttraining's rmse: 0.0861353\tvalid_1's rmse: 0.0926692\n",
      "[1600]\ttraining's rmse: 0.0855301\tvalid_1's rmse: 0.0924192\n",
      "[1700]\ttraining's rmse: 0.0849763\tvalid_1's rmse: 0.0922037\n",
      "[1800]\ttraining's rmse: 0.0844595\tvalid_1's rmse: 0.0920334\n",
      "[1900]\ttraining's rmse: 0.0839702\tvalid_1's rmse: 0.0918699\n",
      "[2000]\ttraining's rmse: 0.0835055\tvalid_1's rmse: 0.0917303\n",
      "[2100]\ttraining's rmse: 0.0830871\tvalid_1's rmse: 0.0915952\n",
      "[2200]\ttraining's rmse: 0.0826985\tvalid_1's rmse: 0.0915076\n",
      "[2300]\ttraining's rmse: 0.0823229\tvalid_1's rmse: 0.0914465\n",
      "[2400]\ttraining's rmse: 0.0819542\tvalid_1's rmse: 0.0913875\n",
      "[2500]\ttraining's rmse: 0.081603\tvalid_1's rmse: 0.0913514\n",
      "[2600]\ttraining's rmse: 0.0812718\tvalid_1's rmse: 0.0913205\n",
      "[2700]\ttraining's rmse: 0.0809544\tvalid_1's rmse: 0.0912837\n",
      "[2800]\ttraining's rmse: 0.080655\tvalid_1's rmse: 0.0912528\n",
      "[2900]\ttraining's rmse: 0.080361\tvalid_1's rmse: 0.0912158\n",
      "[3000]\ttraining's rmse: 0.08007\tvalid_1's rmse: 0.0911798\n",
      "[3100]\ttraining's rmse: 0.0797835\tvalid_1's rmse: 0.0911438\n",
      "[3200]\ttraining's rmse: 0.0795115\tvalid_1's rmse: 0.0911082\n",
      "[3300]\ttraining's rmse: 0.0792542\tvalid_1's rmse: 0.0910903\n",
      "[3400]\ttraining's rmse: 0.0790062\tvalid_1's rmse: 0.0910626\n",
      "[3500]\ttraining's rmse: 0.0787573\tvalid_1's rmse: 0.0910419\n",
      "[3600]\ttraining's rmse: 0.0785135\tvalid_1's rmse: 0.0910216\n",
      "[3700]\ttraining's rmse: 0.0782701\tvalid_1's rmse: 0.0909993\n",
      "[3800]\ttraining's rmse: 0.0780289\tvalid_1's rmse: 0.0909809\n",
      "[3900]\ttraining's rmse: 0.0778037\tvalid_1's rmse: 0.0909666\n",
      "[4000]\ttraining's rmse: 0.0775855\tvalid_1's rmse: 0.0909595\n",
      "[4100]\ttraining's rmse: 0.0773721\tvalid_1's rmse: 0.0909414\n",
      "[4200]\ttraining's rmse: 0.0771561\tvalid_1's rmse: 0.0909355\n",
      "[4300]\ttraining's rmse: 0.0769481\tvalid_1's rmse: 0.0909349\n",
      "[4400]\ttraining's rmse: 0.0767393\tvalid_1's rmse: 0.0909428\n",
      "[4500]\ttraining's rmse: 0.0765275\tvalid_1's rmse: 0.0909334\n",
      "[4600]\ttraining's rmse: 0.076324\tvalid_1's rmse: 0.0909355\n",
      "[4700]\ttraining's rmse: 0.0761328\tvalid_1's rmse: 0.0909585\n",
      "[4800]\ttraining's rmse: 0.0759384\tvalid_1's rmse: 0.0909841\n",
      "Early stopping, best iteration is:\n",
      "[4521]\ttraining's rmse: 0.0764846\tvalid_1's rmse: 0.0909286\n",
      "fold n5\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 0.146718\tvalid_1's rmse: 0.147315\n",
      "[200]\ttraining's rmse: 0.123265\tvalid_1's rmse: 0.124893\n",
      "[300]\ttraining's rmse: 0.111493\tvalid_1's rmse: 0.113814\n",
      "[400]\ttraining's rmse: 0.104856\tvalid_1's rmse: 0.107812\n",
      "[500]\ttraining's rmse: 0.100555\tvalid_1's rmse: 0.104024\n",
      "[600]\ttraining's rmse: 0.0974913\tvalid_1's rmse: 0.101415\n",
      "[700]\ttraining's rmse: 0.0952089\tvalid_1's rmse: 0.0995122\n",
      "[800]\ttraining's rmse: 0.0933593\tvalid_1's rmse: 0.0980155\n",
      "[900]\ttraining's rmse: 0.0918131\tvalid_1's rmse: 0.0968459\n",
      "[1000]\ttraining's rmse: 0.0905156\tvalid_1's rmse: 0.0958643\n",
      "[1100]\ttraining's rmse: 0.0894484\tvalid_1's rmse: 0.0950753\n",
      "[1200]\ttraining's rmse: 0.0885333\tvalid_1's rmse: 0.0944465\n",
      "[1300]\ttraining's rmse: 0.0877256\tvalid_1's rmse: 0.0939285\n",
      "[1400]\ttraining's rmse: 0.0870011\tvalid_1's rmse: 0.0934892\n",
      "[1500]\ttraining's rmse: 0.0863467\tvalid_1's rmse: 0.0931276\n",
      "[1600]\ttraining's rmse: 0.0857489\tvalid_1's rmse: 0.0928046\n",
      "[1700]\ttraining's rmse: 0.0851901\tvalid_1's rmse: 0.0925147\n",
      "[1800]\ttraining's rmse: 0.0846709\tvalid_1's rmse: 0.0922774\n",
      "[1900]\ttraining's rmse: 0.0842027\tvalid_1's rmse: 0.0920866\n",
      "[2000]\ttraining's rmse: 0.0837459\tvalid_1's rmse: 0.0919042\n",
      "[2100]\ttraining's rmse: 0.0833135\tvalid_1's rmse: 0.0917306\n",
      "[2200]\ttraining's rmse: 0.0829079\tvalid_1's rmse: 0.0915862\n",
      "[2300]\ttraining's rmse: 0.0825353\tvalid_1's rmse: 0.0914518\n",
      "[2400]\ttraining's rmse: 0.0821792\tvalid_1's rmse: 0.0913394\n",
      "[2500]\ttraining's rmse: 0.0818252\tvalid_1's rmse: 0.0912421\n",
      "[2600]\ttraining's rmse: 0.0814918\tvalid_1's rmse: 0.0911513\n",
      "[2700]\ttraining's rmse: 0.0811766\tvalid_1's rmse: 0.0910571\n",
      "[2800]\ttraining's rmse: 0.0808745\tvalid_1's rmse: 0.0909895\n",
      "[2900]\ttraining's rmse: 0.0805893\tvalid_1's rmse: 0.0909253\n",
      "[3000]\ttraining's rmse: 0.0803065\tvalid_1's rmse: 0.0908759\n",
      "[3100]\ttraining's rmse: 0.0800302\tvalid_1's rmse: 0.0908393\n",
      "[3200]\ttraining's rmse: 0.0797569\tvalid_1's rmse: 0.0907702\n",
      "[3300]\ttraining's rmse: 0.0794969\tvalid_1's rmse: 0.0907239\n",
      "[3400]\ttraining's rmse: 0.0792384\tvalid_1's rmse: 0.0906723\n",
      "[3500]\ttraining's rmse: 0.0789835\tvalid_1's rmse: 0.0906163\n",
      "[3600]\ttraining's rmse: 0.0787381\tvalid_1's rmse: 0.0905727\n",
      "[3700]\ttraining's rmse: 0.0784996\tvalid_1's rmse: 0.090528\n",
      "[3800]\ttraining's rmse: 0.0782655\tvalid_1's rmse: 0.0904816\n",
      "[3900]\ttraining's rmse: 0.0780362\tvalid_1's rmse: 0.0904462\n",
      "[4000]\ttraining's rmse: 0.0778096\tvalid_1's rmse: 0.0904206\n",
      "[4100]\ttraining's rmse: 0.0775904\tvalid_1's rmse: 0.090395\n",
      "[4200]\ttraining's rmse: 0.0773716\tvalid_1's rmse: 0.0903638\n",
      "[4300]\ttraining's rmse: 0.0771558\tvalid_1's rmse: 0.0903413\n",
      "[4400]\ttraining's rmse: 0.0769496\tvalid_1's rmse: 0.090316\n",
      "[4500]\ttraining's rmse: 0.0767454\tvalid_1's rmse: 0.0903057\n",
      "[4600]\ttraining's rmse: 0.0765529\tvalid_1's rmse: 0.0902942\n",
      "[4700]\ttraining's rmse: 0.0763662\tvalid_1's rmse: 0.0902695\n",
      "[4800]\ttraining's rmse: 0.076179\tvalid_1's rmse: 0.0902594\n",
      "[4900]\ttraining's rmse: 0.0760018\tvalid_1's rmse: 0.0902488\n",
      "[5000]\ttraining's rmse: 0.0758132\tvalid_1's rmse: 0.090239\n",
      "[5100]\ttraining's rmse: 0.0756318\tvalid_1's rmse: 0.090224\n",
      "[5200]\ttraining's rmse: 0.0754565\tvalid_1's rmse: 0.090197\n",
      "[5300]\ttraining's rmse: 0.0752771\tvalid_1's rmse: 0.0901927\n",
      "[5400]\ttraining's rmse: 0.0751014\tvalid_1's rmse: 0.0901995\n",
      "[5500]\ttraining's rmse: 0.0749306\tvalid_1's rmse: 0.0902025\n",
      "Early stopping, best iteration is:\n",
      "[5242]\ttraining's rmse: 0.0753824\tvalid_1's rmse: 0.0901877\n",
      "fold n6\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 0.146773\tvalid_1's rmse: 0.147079\n",
      "[200]\ttraining's rmse: 0.123375\tvalid_1's rmse: 0.124067\n",
      "[300]\ttraining's rmse: 0.111644\tvalid_1's rmse: 0.112692\n",
      "[400]\ttraining's rmse: 0.105018\tvalid_1's rmse: 0.106348\n",
      "[500]\ttraining's rmse: 0.100737\tvalid_1's rmse: 0.102367\n",
      "[600]\ttraining's rmse: 0.0976807\tvalid_1's rmse: 0.0995773\n",
      "[700]\ttraining's rmse: 0.0954022\tvalid_1's rmse: 0.0976085\n",
      "[800]\ttraining's rmse: 0.0935496\tvalid_1's rmse: 0.0960583\n",
      "[900]\ttraining's rmse: 0.0920117\tvalid_1's rmse: 0.0948398\n",
      "[1000]\ttraining's rmse: 0.0907093\tvalid_1's rmse: 0.0938331\n",
      "[1100]\ttraining's rmse: 0.089634\tvalid_1's rmse: 0.0930847\n",
      "[1200]\ttraining's rmse: 0.0887029\tvalid_1's rmse: 0.0924828\n",
      "[1300]\ttraining's rmse: 0.0878954\tvalid_1's rmse: 0.0919909\n",
      "[1400]\ttraining's rmse: 0.0871751\tvalid_1's rmse: 0.0915759\n",
      "[1500]\ttraining's rmse: 0.0865278\tvalid_1's rmse: 0.0912475\n",
      "[1600]\ttraining's rmse: 0.0859366\tvalid_1's rmse: 0.090909\n",
      "[1700]\ttraining's rmse: 0.0854051\tvalid_1's rmse: 0.0906392\n",
      "[1800]\ttraining's rmse: 0.0848843\tvalid_1's rmse: 0.0903857\n",
      "[1900]\ttraining's rmse: 0.0843863\tvalid_1's rmse: 0.0901571\n",
      "[2000]\ttraining's rmse: 0.0839353\tvalid_1's rmse: 0.0899563\n",
      "[2100]\ttraining's rmse: 0.0835115\tvalid_1's rmse: 0.0897546\n",
      "[2200]\ttraining's rmse: 0.0831036\tvalid_1's rmse: 0.0896007\n",
      "[2300]\ttraining's rmse: 0.0827244\tvalid_1's rmse: 0.0894601\n",
      "[2400]\ttraining's rmse: 0.0823662\tvalid_1's rmse: 0.089351\n",
      "[2500]\ttraining's rmse: 0.0820231\tvalid_1's rmse: 0.0892612\n",
      "[2600]\ttraining's rmse: 0.0816894\tvalid_1's rmse: 0.0891686\n",
      "[2700]\ttraining's rmse: 0.0813683\tvalid_1's rmse: 0.089089\n",
      "[2800]\ttraining's rmse: 0.0810614\tvalid_1's rmse: 0.0890077\n",
      "[2900]\ttraining's rmse: 0.0807643\tvalid_1's rmse: 0.0889332\n",
      "[3000]\ttraining's rmse: 0.0804804\tvalid_1's rmse: 0.0888962\n",
      "[3100]\ttraining's rmse: 0.0802081\tvalid_1's rmse: 0.0888552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3200]\ttraining's rmse: 0.0799434\tvalid_1's rmse: 0.0888027\n",
      "[3300]\ttraining's rmse: 0.0796847\tvalid_1's rmse: 0.0887614\n",
      "[3400]\ttraining's rmse: 0.0794269\tvalid_1's rmse: 0.0887354\n",
      "[3500]\ttraining's rmse: 0.0791821\tvalid_1's rmse: 0.0887287\n",
      "[3600]\ttraining's rmse: 0.0789454\tvalid_1's rmse: 0.0887275\n",
      "[3700]\ttraining's rmse: 0.0787171\tvalid_1's rmse: 0.0887046\n",
      "[3800]\ttraining's rmse: 0.0784882\tvalid_1's rmse: 0.0886798\n",
      "[3900]\ttraining's rmse: 0.0782668\tvalid_1's rmse: 0.0886645\n",
      "[4000]\ttraining's rmse: 0.0780512\tvalid_1's rmse: 0.0886655\n",
      "[4100]\ttraining's rmse: 0.0778355\tvalid_1's rmse: 0.0886705\n",
      "[4200]\ttraining's rmse: 0.0776299\tvalid_1's rmse: 0.0886766\n",
      "Early stopping, best iteration is:\n",
      "[3920]\ttraining's rmse: 0.078221\tvalid_1's rmse: 0.0886587\n",
      "fold n7\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 0.146581\tvalid_1's rmse: 0.148723\n",
      "[200]\ttraining's rmse: 0.12318\tvalid_1's rmse: 0.125477\n",
      "[300]\ttraining's rmse: 0.111415\tvalid_1's rmse: 0.114164\n",
      "[400]\ttraining's rmse: 0.104773\tvalid_1's rmse: 0.108087\n",
      "[500]\ttraining's rmse: 0.100462\tvalid_1's rmse: 0.104375\n",
      "[600]\ttraining's rmse: 0.0974042\tvalid_1's rmse: 0.101879\n",
      "[700]\ttraining's rmse: 0.0951083\tvalid_1's rmse: 0.100066\n",
      "[800]\ttraining's rmse: 0.0932388\tvalid_1's rmse: 0.0986357\n",
      "[900]\ttraining's rmse: 0.0916783\tvalid_1's rmse: 0.0974992\n",
      "[1000]\ttraining's rmse: 0.0903639\tvalid_1's rmse: 0.0965787\n",
      "[1100]\ttraining's rmse: 0.0892915\tvalid_1's rmse: 0.0958812\n",
      "[1200]\ttraining's rmse: 0.0883479\tvalid_1's rmse: 0.0952916\n",
      "[1300]\ttraining's rmse: 0.0875263\tvalid_1's rmse: 0.0948539\n",
      "[1400]\ttraining's rmse: 0.0867896\tvalid_1's rmse: 0.0944616\n",
      "[1500]\ttraining's rmse: 0.08614\tvalid_1's rmse: 0.0941331\n",
      "[1600]\ttraining's rmse: 0.0855517\tvalid_1's rmse: 0.0938519\n",
      "[1700]\ttraining's rmse: 0.0849966\tvalid_1's rmse: 0.0935732\n",
      "[1800]\ttraining's rmse: 0.0844725\tvalid_1's rmse: 0.0933469\n",
      "[1900]\ttraining's rmse: 0.0839822\tvalid_1's rmse: 0.0931674\n",
      "[2000]\ttraining's rmse: 0.0835257\tvalid_1's rmse: 0.0930186\n",
      "[2100]\ttraining's rmse: 0.083099\tvalid_1's rmse: 0.0928915\n",
      "[2200]\ttraining's rmse: 0.0827056\tvalid_1's rmse: 0.092793\n",
      "[2300]\ttraining's rmse: 0.0823351\tvalid_1's rmse: 0.0926918\n",
      "[2400]\ttraining's rmse: 0.0819703\tvalid_1's rmse: 0.092577\n",
      "[2500]\ttraining's rmse: 0.081631\tvalid_1's rmse: 0.092468\n",
      "[2600]\ttraining's rmse: 0.0813097\tvalid_1's rmse: 0.0923913\n",
      "[2700]\ttraining's rmse: 0.0810096\tvalid_1's rmse: 0.0923143\n",
      "[2800]\ttraining's rmse: 0.0807212\tvalid_1's rmse: 0.0922648\n",
      "[2900]\ttraining's rmse: 0.0804365\tvalid_1's rmse: 0.0921974\n",
      "[3000]\ttraining's rmse: 0.0801526\tvalid_1's rmse: 0.0921145\n",
      "[3100]\ttraining's rmse: 0.0798789\tvalid_1's rmse: 0.0920361\n",
      "[3200]\ttraining's rmse: 0.0796113\tvalid_1's rmse: 0.0919788\n",
      "[3300]\ttraining's rmse: 0.0793489\tvalid_1's rmse: 0.0919427\n",
      "[3400]\ttraining's rmse: 0.0790979\tvalid_1's rmse: 0.091904\n",
      "[3500]\ttraining's rmse: 0.0788511\tvalid_1's rmse: 0.0918376\n",
      "[3600]\ttraining's rmse: 0.0786078\tvalid_1's rmse: 0.0917867\n",
      "[3700]\ttraining's rmse: 0.0783717\tvalid_1's rmse: 0.0917324\n",
      "[3800]\ttraining's rmse: 0.0781426\tvalid_1's rmse: 0.0916928\n",
      "[3900]\ttraining's rmse: 0.0779158\tvalid_1's rmse: 0.0916441\n",
      "[4000]\ttraining's rmse: 0.0777045\tvalid_1's rmse: 0.0916364\n",
      "[4100]\ttraining's rmse: 0.0774966\tvalid_1's rmse: 0.0916007\n",
      "[4200]\ttraining's rmse: 0.0772873\tvalid_1's rmse: 0.0915732\n",
      "[4300]\ttraining's rmse: 0.0770856\tvalid_1's rmse: 0.0915461\n",
      "[4400]\ttraining's rmse: 0.0768872\tvalid_1's rmse: 0.0915271\n",
      "[4500]\ttraining's rmse: 0.0766887\tvalid_1's rmse: 0.0914998\n",
      "[4600]\ttraining's rmse: 0.0764883\tvalid_1's rmse: 0.0914699\n",
      "[4700]\ttraining's rmse: 0.0762971\tvalid_1's rmse: 0.0914389\n",
      "[4800]\ttraining's rmse: 0.0760998\tvalid_1's rmse: 0.0914202\n",
      "[4900]\ttraining's rmse: 0.0759042\tvalid_1's rmse: 0.0913899\n",
      "[5000]\ttraining's rmse: 0.0757089\tvalid_1's rmse: 0.0913655\n",
      "[5100]\ttraining's rmse: 0.0755185\tvalid_1's rmse: 0.0913565\n",
      "[5200]\ttraining's rmse: 0.0753337\tvalid_1's rmse: 0.0913535\n",
      "[5300]\ttraining's rmse: 0.0751537\tvalid_1's rmse: 0.0913389\n",
      "[5400]\ttraining's rmse: 0.0749701\tvalid_1's rmse: 0.0913259\n",
      "[5500]\ttraining's rmse: 0.0747918\tvalid_1's rmse: 0.0913108\n",
      "[5600]\ttraining's rmse: 0.0746151\tvalid_1's rmse: 0.0913002\n",
      "[5700]\ttraining's rmse: 0.074444\tvalid_1's rmse: 0.0912941\n",
      "[5800]\ttraining's rmse: 0.0742675\tvalid_1's rmse: 0.0912809\n",
      "[5900]\ttraining's rmse: 0.0740949\tvalid_1's rmse: 0.0912814\n",
      "[6000]\ttraining's rmse: 0.0739201\tvalid_1's rmse: 0.0912763\n",
      "[6100]\ttraining's rmse: 0.0737513\tvalid_1's rmse: 0.0912858\n",
      "[6200]\ttraining's rmse: 0.0735878\tvalid_1's rmse: 0.0912881\n",
      "Early stopping, best iteration is:\n",
      "[5954]\ttraining's rmse: 0.0740008\tvalid_1's rmse: 0.0912706\n",
      "fold n8\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 0.146991\tvalid_1's rmse: 0.144237\n",
      "[200]\ttraining's rmse: 0.123602\tvalid_1's rmse: 0.121192\n",
      "[300]\ttraining's rmse: 0.111883\tvalid_1's rmse: 0.109933\n",
      "[400]\ttraining's rmse: 0.105238\tvalid_1's rmse: 0.103709\n",
      "[500]\ttraining's rmse: 0.100956\tvalid_1's rmse: 0.0997771\n",
      "[600]\ttraining's rmse: 0.0979014\tvalid_1's rmse: 0.0970352\n",
      "[700]\ttraining's rmse: 0.0956046\tvalid_1's rmse: 0.0950971\n",
      "[800]\ttraining's rmse: 0.0937582\tvalid_1's rmse: 0.0935465\n",
      "[900]\ttraining's rmse: 0.0922087\tvalid_1's rmse: 0.0922509\n",
      "[1000]\ttraining's rmse: 0.0909063\tvalid_1's rmse: 0.0912406\n",
      "[1100]\ttraining's rmse: 0.0898311\tvalid_1's rmse: 0.0904504\n",
      "[1200]\ttraining's rmse: 0.0888954\tvalid_1's rmse: 0.089801\n",
      "[1300]\ttraining's rmse: 0.088085\tvalid_1's rmse: 0.0892813\n",
      "[1400]\ttraining's rmse: 0.0873614\tvalid_1's rmse: 0.0888503\n",
      "[1500]\ttraining's rmse: 0.0867022\tvalid_1's rmse: 0.0884975\n",
      "[1600]\ttraining's rmse: 0.0860881\tvalid_1's rmse: 0.0881949\n",
      "[1700]\ttraining's rmse: 0.0855318\tvalid_1's rmse: 0.0879259\n",
      "[1800]\ttraining's rmse: 0.0849954\tvalid_1's rmse: 0.0876462\n",
      "[1900]\ttraining's rmse: 0.0845059\tvalid_1's rmse: 0.0874031\n",
      "[2000]\ttraining's rmse: 0.0840507\tvalid_1's rmse: 0.0871921\n",
      "[2100]\ttraining's rmse: 0.0836067\tvalid_1's rmse: 0.0869826\n",
      "[2200]\ttraining's rmse: 0.0832057\tvalid_1's rmse: 0.0868469\n",
      "[2300]\ttraining's rmse: 0.0828276\tvalid_1's rmse: 0.0867263\n",
      "[2400]\ttraining's rmse: 0.0824664\tvalid_1's rmse: 0.086616\n",
      "[2500]\ttraining's rmse: 0.0821308\tvalid_1's rmse: 0.0864979\n",
      "[2600]\ttraining's rmse: 0.0817902\tvalid_1's rmse: 0.0863819\n",
      "[2700]\ttraining's rmse: 0.0814569\tvalid_1's rmse: 0.0862946\n",
      "[2800]\ttraining's rmse: 0.081136\tvalid_1's rmse: 0.0862105\n",
      "[2900]\ttraining's rmse: 0.0808298\tvalid_1's rmse: 0.0861512\n",
      "[3000]\ttraining's rmse: 0.0805354\tvalid_1's rmse: 0.0861076\n",
      "[3100]\ttraining's rmse: 0.0802572\tvalid_1's rmse: 0.0860523\n",
      "[3200]\ttraining's rmse: 0.0799814\tvalid_1's rmse: 0.0860002\n",
      "[3300]\ttraining's rmse: 0.0797152\tvalid_1's rmse: 0.0859844\n",
      "[3400]\ttraining's rmse: 0.0794479\tvalid_1's rmse: 0.0859425\n",
      "[3500]\ttraining's rmse: 0.0791953\tvalid_1's rmse: 0.0859126\n",
      "[3600]\ttraining's rmse: 0.0789477\tvalid_1's rmse: 0.085901\n",
      "[3700]\ttraining's rmse: 0.0787057\tvalid_1's rmse: 0.0859069\n",
      "[3800]\ttraining's rmse: 0.0784677\tvalid_1's rmse: 0.0858967\n",
      "[3900]\ttraining's rmse: 0.078242\tvalid_1's rmse: 0.0858952\n",
      "[4000]\ttraining's rmse: 0.0780171\tvalid_1's rmse: 0.0858955\n",
      "[4100]\ttraining's rmse: 0.0778015\tvalid_1's rmse: 0.0859038\n",
      "Early stopping, best iteration is:\n",
      "[3892]\ttraining's rmse: 0.0782605\tvalid_1's rmse: 0.0858915\n",
      "fold n9\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 0.146729\tvalid_1's rmse: 0.145912\n",
      "[200]\ttraining's rmse: 0.123241\tvalid_1's rmse: 0.123358\n",
      "[300]\ttraining's rmse: 0.111428\tvalid_1's rmse: 0.112586\n",
      "[400]\ttraining's rmse: 0.104784\tvalid_1's rmse: 0.106858\n",
      "[500]\ttraining's rmse: 0.100457\tvalid_1's rmse: 0.103358\n",
      "[600]\ttraining's rmse: 0.0973452\tvalid_1's rmse: 0.10092\n",
      "[700]\ttraining's rmse: 0.0950564\tvalid_1's rmse: 0.0991811\n",
      "[800]\ttraining's rmse: 0.0932016\tvalid_1's rmse: 0.0978249\n",
      "[900]\ttraining's rmse: 0.0916679\tvalid_1's rmse: 0.0967299\n",
      "[1000]\ttraining's rmse: 0.0903764\tvalid_1's rmse: 0.0958357\n",
      "[1100]\ttraining's rmse: 0.0893128\tvalid_1's rmse: 0.0951835\n",
      "[1200]\ttraining's rmse: 0.0883675\tvalid_1's rmse: 0.0946125\n",
      "[1300]\ttraining's rmse: 0.0875585\tvalid_1's rmse: 0.0941109\n",
      "[1400]\ttraining's rmse: 0.0868224\tvalid_1's rmse: 0.0936863\n",
      "[1500]\ttraining's rmse: 0.0861752\tvalid_1's rmse: 0.0933281\n",
      "[1600]\ttraining's rmse: 0.0855854\tvalid_1's rmse: 0.0930291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1700]\ttraining's rmse: 0.0850367\tvalid_1's rmse: 0.092757\n",
      "[1800]\ttraining's rmse: 0.0845235\tvalid_1's rmse: 0.0925227\n",
      "[1900]\ttraining's rmse: 0.0840568\tvalid_1's rmse: 0.092349\n",
      "[2000]\ttraining's rmse: 0.0836179\tvalid_1's rmse: 0.0921756\n",
      "[2100]\ttraining's rmse: 0.0831915\tvalid_1's rmse: 0.09201\n",
      "[2200]\ttraining's rmse: 0.0827929\tvalid_1's rmse: 0.0918763\n",
      "[2300]\ttraining's rmse: 0.0824245\tvalid_1's rmse: 0.0917715\n",
      "[2400]\ttraining's rmse: 0.0820599\tvalid_1's rmse: 0.0916712\n",
      "[2500]\ttraining's rmse: 0.0817029\tvalid_1's rmse: 0.091578\n",
      "[2600]\ttraining's rmse: 0.0813609\tvalid_1's rmse: 0.0915032\n",
      "[2700]\ttraining's rmse: 0.0810446\tvalid_1's rmse: 0.0914426\n",
      "[2800]\ttraining's rmse: 0.0807254\tvalid_1's rmse: 0.091378\n",
      "[2900]\ttraining's rmse: 0.0804219\tvalid_1's rmse: 0.0913197\n",
      "[3000]\ttraining's rmse: 0.0801323\tvalid_1's rmse: 0.0912695\n",
      "[3100]\ttraining's rmse: 0.079848\tvalid_1's rmse: 0.0912124\n",
      "[3200]\ttraining's rmse: 0.0795775\tvalid_1's rmse: 0.0911706\n",
      "[3300]\ttraining's rmse: 0.0793163\tvalid_1's rmse: 0.0911298\n",
      "[3400]\ttraining's rmse: 0.0790608\tvalid_1's rmse: 0.0910945\n",
      "[3500]\ttraining's rmse: 0.0788127\tvalid_1's rmse: 0.0910567\n",
      "[3600]\ttraining's rmse: 0.078577\tvalid_1's rmse: 0.0910368\n",
      "[3700]\ttraining's rmse: 0.0783431\tvalid_1's rmse: 0.0910049\n",
      "[3800]\ttraining's rmse: 0.0781103\tvalid_1's rmse: 0.0909722\n",
      "[3900]\ttraining's rmse: 0.0778797\tvalid_1's rmse: 0.0909595\n",
      "[4000]\ttraining's rmse: 0.0776587\tvalid_1's rmse: 0.0909379\n",
      "[4100]\ttraining's rmse: 0.0774353\tvalid_1's rmse: 0.0909339\n",
      "[4200]\ttraining's rmse: 0.0772135\tvalid_1's rmse: 0.0909119\n",
      "[4300]\ttraining's rmse: 0.0769963\tvalid_1's rmse: 0.0908924\n",
      "[4400]\ttraining's rmse: 0.0767858\tvalid_1's rmse: 0.0908665\n",
      "[4500]\ttraining's rmse: 0.0765834\tvalid_1's rmse: 0.0908571\n",
      "[4600]\ttraining's rmse: 0.0763827\tvalid_1's rmse: 0.0908387\n",
      "[4700]\ttraining's rmse: 0.0761858\tvalid_1's rmse: 0.0908459\n",
      "[4800]\ttraining's rmse: 0.0759895\tvalid_1's rmse: 0.0908345\n",
      "[4900]\ttraining's rmse: 0.0758019\tvalid_1's rmse: 0.090835\n",
      "[5000]\ttraining's rmse: 0.0756185\tvalid_1's rmse: 0.0908246\n",
      "[5100]\ttraining's rmse: 0.0754423\tvalid_1's rmse: 0.0908296\n",
      "[5200]\ttraining's rmse: 0.0752683\tvalid_1's rmse: 0.0908259\n",
      "[5300]\ttraining's rmse: 0.0750958\tvalid_1's rmse: 0.0908223\n",
      "Early stopping, best iteration is:\n",
      "[5010]\ttraining's rmse: 0.0756011\tvalid_1's rmse: 0.0908214\n",
      "CV score: 0.08935 \n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "features = [c for c in train_df.columns if c not in ['Target']]\n",
    "target = train_df['Target']\n",
    "\n",
    "folds = KFold(n_splits=10, shuffle=True, random_state=15)\n",
    "oof_lgb = np.zeros(len(train_df))\n",
    "predictions_lgb = np.zeros(len(test_df))\n",
    "start = time.time()\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
    "    print(\"fold n{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "\n",
    "    num_round = 13000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 500)\n",
    "    oof_lgb[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    predictions_lgb += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "oof_lgb[oof_lgb < 0] = 0\n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof_lgb, target)**0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "sub= ttest[[\"ID\"]]\n",
    "sub['Target'] = predictions_lgb\n",
    "sub.to_csv('postchallengeLtt.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:31:12] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bootstrap_type, early_stopping_rounds, iterations, random_seed, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.24322\n",
      "[99]\tvalidation_0-rmse:0.17918\n",
      "0.022397632042570288\n",
      "[21:31:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bootstrap_type, early_stopping_rounds, iterations, random_seed, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.24534\n",
      "[99]\tvalidation_0-rmse:0.18070\n",
      "0.04498560315884216\n",
      "[21:31:26] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bootstrap_type, early_stopping_rounds, iterations, random_seed, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.24343\n",
      "[99]\tvalidation_0-rmse:0.17858\n",
      "0.06730784934077458\n",
      "[21:31:32] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bootstrap_type, early_stopping_rounds, iterations, random_seed, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.24343\n",
      "[99]\tvalidation_0-rmse:0.17870\n",
      "0.08964528732850358\n",
      "[21:31:37] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bootstrap_type, early_stopping_rounds, iterations, random_seed, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.24715\n",
      "[99]\tvalidation_0-rmse:0.18206\n",
      "0.11240310743882755\n",
      "[21:31:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bootstrap_type, early_stopping_rounds, iterations, random_seed, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.24150\n",
      "[99]\tvalidation_0-rmse:0.17688\n",
      "0.13451355525744435\n",
      "[21:31:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bootstrap_type, early_stopping_rounds, iterations, random_seed, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.24632\n",
      "[99]\tvalidation_0-rmse:0.18106\n",
      "0.1571459852279528\n",
      "[21:31:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { bootstrap_type, early_stopping_rounds, iterations, random_seed, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.24353\n",
      "[99]\tvalidation_0-rmse:0.17842\n",
      "0.17944883693617822\n"
     ]
    }
   ],
   "source": [
    "fold_score = 0\n",
    "t_pred = []\n",
    "\n",
    "n = 8\n",
    "kf = StratifiedKFold(n)\n",
    "kf = KFold(n_splits=8)\n",
    "kf.get_n_splits(X)\n",
    "  \n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    Xtrain, Xtest = X.loc[train_index], X.loc[test_index]\n",
    "    ytrain, ytest = y[train_index], y[test_index]\n",
    "\n",
    "    model = XGBRegressor(random_seed=34,bootstrap_type='Bayesian', max_depth=10, eta=0.004, eval_metric ='rmse',\n",
    "                          iterations=2000,subsample=0.7, colsample_bytree=0.8,silent=False, early_stopping_rounds = 300)\n",
    "    model.fit(Xtrain, ytrain, eval_set=[(Xtest,ytest)], verbose=200)\n",
    "    \n",
    "    pred = model.predict(Xtest)\n",
    "    score = np.sqrt(mean_squared_error(ytest, pred))\n",
    "    fold_score = fold_score + (score/n)\n",
    "    print(fold_score)\n",
    "    \n",
    "    predictions = model.predict(test_df)\n",
    "    t_pred.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "classifier = XGBRegressor(n_estimators = 2000, objective = \"reg:squarederror\")\n",
    "# Create Hyperparameter Search Space\n",
    "\n",
    "param_dist = {\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05,0.08,0.1,0.2],\n",
    "    \"gamma\": [0.5, 0.7,0.9],\n",
    "    \"max_depth\": [5,7,8,9,10],\n",
    "    \"min_child_weight\": [1, 2, 3,5,7],\n",
    "    \"max_delta_step\":[0,1,2,3],\n",
    "    \"reg_lambda\":[0.3,0.5,1],\n",
    "    \"subsample\":[0.3,0.5,0.7,0.9],\n",
    "    \"colsample_bytree\":[0.3,0.4,0.6,0.8]\n",
    "}\n",
    "\n",
    "# create random search\n",
    "# Create randomized search 5-fold cross validation and 100 iterations\n",
    "clf = RandomizedSearchCV(\n",
    " estimator=classifier,\n",
    " param_distributions=param_dist,\n",
    " random_state=1,\n",
    " n_iter=500,\n",
    " cv=5,\n",
    " verbose=0,\n",
    " n_jobs=-1,\n",
    ")\n",
    "# Fit randomized search\n",
    "best_model = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('postchallengeLt.csv')\n",
    "dat1 = pd.read_csv('LGBM.csv')\n",
    "dat2 = pd.read_csv('CatC.csv')\n",
    "dat3 = pd.read_csv('final_sub.csv')\n",
    "dat4 = pd.read_csv('postchallenge.csv')\n",
    "dat5 = pd.read_csv('n1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datt1 = (dat1['Target'] + dat2['Target'])/2\n",
    "datt2 = (dat2['Target'] + dat3['Target'])/2\n",
    "datt3 = (dat['Target'] + dat2['Target'] + dat3['Target']+dat5['Target'])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SampleSubmission (1).csv')\n",
    "df['Target'] = datt1\n",
    "df.to_csv('FL1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target'] = datt2\n",
    "df.to_csv('FL2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target'] = datt3\n",
    "df.to_csv('FL3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat5 = pd.read_csv('FL2.csv')\n",
    "dat6 = pd.read_csv('FL3.csv')\n",
    "dat7 = pd.read_csv('FL4.csv')\n",
    "dat8 = pd.read_csv('FL5.csv')\n",
    "dat9 = pd.read_csv('FL7.csv')\n",
    "dat10 = pd.read_csv('FL1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "datt4 = (dat['Target']+dat1['Target']+dat3['Target']+dat4['Target']+dat5['Target'])/5\n",
    "\n",
    "sub= ttest[[\"ID\"]]\n",
    "sub['Target'] = datt4\n",
    "sub.to_csv('final_.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "datt5 = (dat1['Target'] + dat2['Target'] + dat4['Target']+dat5['Target']+dat6['Target'])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target'] = datt4\n",
    "df.to_csv('F4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target'] = datt5\n",
    "df.to_csv('FL5.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "datt7 = (dat1['Target'] + dat2['Target'] + dat3['Target']+dat7['Target'])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target'] = datt7\n",
    "df.to_csv('FL7.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "datt8 = (dat1['Target'] + dat2['Target'] +dat5['Target']+ dat6['Target']+ dat7['Target']+ \n",
    "         dat8['Target']+ dat9['Target']+ dat10['Target'])/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target'] = datt8\n",
    "df.to_csv('FL8.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "datt9 = (dat1['Target'] + dat2['Target'] + dat3['Target'] + dat4['Target'] + dat5['Target'] + \n",
    "         dat6['Target'] + dat7['Target'] + dat8['Target'] + dat9['Target'] + dat10['Target'])/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target'] = datt9\n",
    "df.to_csv('FL9.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtt1 = 0.38*(dat1['Target']) + 0.35*(dat2['Target']) + 0.22*(dat3['Target']) + 0.05*(dat4['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target'] = dtt1\n",
    "df.to_csv('n1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation function\n",
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, X.values, y, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMRegressor(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso score: 0.1014 (0.0014)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet score: 0.1014 (0.0013)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(ENet)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting score: 0.0877 (0.0011)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:51:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:52:09] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:52:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:52:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:53:13] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Xgboost score: 0.0890 (0.0013)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(model_xgb)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM score: 0.1473 (0.0023)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(model_lgb)\n",
    "print(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([model.predict(X) for model in self.models_])\n",
    "        return np.mean(predictions, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Averaged base models score: 0.0935 (0.0012)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "averaged_models = AveragingModels(models = (ENet, GBoost, lasso))\n",
    "\n",
    "score = rmsle_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1) for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"<ipython-input-98-1b2964bdcbe6>\", line 20, in fit\n",
      "    instance.fit(X[train_index], y[train_index])\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\", line 877, in __getitem__\n",
      "    return self._get_with(key)\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\", line 912, in _get_with\n",
      "    return self.loc[key]\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\", line 895, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1113, in _getitem_axis\n",
      "    return self._getitem_iterable(key, axis=axis)\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1053, in _getitem_iterable\n",
      "    keyarr, indexer = self._get_listlike_indexer(key, axis, raise_missing=False)\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1266, in _get_listlike_indexer\n",
      "    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1322, in _validate_read_indexer\n",
      "    \"Passing list-likes to .loc or [] with any missing labels \"\n",
      "KeyError: \"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: Int64Index([   1,    2,    3,    4,    5,\\n            ...\\n            4285, 4287, 4288, 4289, 4290],\\n           dtype='int64', length=3432). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"<ipython-input-98-1b2964bdcbe6>\", line 20, in fit\n",
      "    instance.fit(X[train_index], y[train_index])\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\", line 877, in __getitem__\n",
      "    return self._get_with(key)\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\", line 912, in _get_with\n",
      "    return self.loc[key]\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\", line 895, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1113, in _getitem_axis\n",
      "    return self._getitem_iterable(key, axis=axis)\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1053, in _getitem_iterable\n",
      "    keyarr, indexer = self._get_listlike_indexer(key, axis, raise_missing=False)\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1266, in _get_listlike_indexer\n",
      "    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1322, in _validate_read_indexer\n",
      "    \"Passing list-likes to .loc or [] with any missing labels \"\n",
      "KeyError: \"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: Int64Index([4291, 4292, 4293, 4294, 4295,\\n            ...\\n            8576, 8577, 8578, 8579, 8580],\\n           dtype='int64', length=3413). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"<ipython-input-98-1b2964bdcbe6>\", line 20, in fit\n",
      "    instance.fit(X[train_index], y[train_index])\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\", line 877, in __getitem__\n",
      "    return self._get_with(key)\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\", line 912, in _get_with\n",
      "    return self.loc[key]\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\", line 895, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1113, in _getitem_axis\n",
      "    return self._getitem_iterable(key, axis=axis)\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1053, in _getitem_iterable\n",
      "    keyarr, indexer = self._get_listlike_indexer(key, axis, raise_missing=False)\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1266, in _get_listlike_indexer\n",
      "    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1322, in _validate_read_indexer\n",
      "    \"Passing list-likes to .loc or [] with any missing labels \"\n",
      "KeyError: \"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: Int64Index([ 8582,  8583,  8585,  8586,  8587,\\n            ...\\n            12867, 12868, 12870, 12871, 12872],\\n           dtype='int64', length=3494). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:619: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"<ipython-input-98-1b2964bdcbe6>\", line 20, in fit\n",
      "    instance.fit(X[train_index], y[train_index])\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\", line 877, in __getitem__\n",
      "    return self._get_with(key)\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\", line 912, in _get_with\n",
      "    return self.loc[key]\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\", line 895, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1113, in _getitem_axis\n",
      "    return self._getitem_iterable(key, axis=axis)\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1053, in _getitem_iterable\n",
      "    keyarr, indexer = self._get_listlike_indexer(key, axis, raise_missing=False)\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1266, in _get_listlike_indexer\n",
      "    self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing)\n",
      "  File \"C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1322, in _validate_read_indexer\n",
      "    \"Passing list-likes to .loc or [] with any missing labels \"\n",
      "KeyError: \"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: Int64Index([12873, 12874, 12876, 12877, 12880,\\n            ...\\n            17158, 17159, 17160, 17161, 17162],\\n           dtype='int64', length=3391). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Averaged models score: nan (nan)\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost),\n",
    "                                                 meta_model = lasso)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06889832667634832\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models.fit(X.values, y)\n",
    "stacked_train_pred = stacked_averaged_models.predict(X.values)\n",
    "stacked_pred = np.expm1(stacked_averaged_models.predict(test_df.values))\n",
    "print(rmsle(y, stacked_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16644971, 0.17563372, 0.96371922, ..., 0.54671661, 0.23441609,\n",
       "       0.39930728])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:20:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "0.08141699609082433\n"
     ]
    }
   ],
   "source": [
    "model_xgb.fit(X, y)\n",
    "xgb_train_pred = model_xgb.predict(X)\n",
    "xgb_pred = np.expm1(model_xgb.predict(test_df))\n",
    "print(rmsle(y, xgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14673680506531425\n"
     ]
    }
   ],
   "source": [
    "model_lgb.fit(X, y)\n",
    "lgb_train_pred = model_lgb.predict(X)\n",
    "lgb_pred = np.expm1(model_lgb.predict(test_df.values))\n",
    "print(rmsle(y, lgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE score on train data:\n",
      "0.06995797561027817\n"
     ]
    }
   ],
   "source": [
    "'''RMSE on the entire Train data when averaging'''\n",
    "\n",
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y,stacked_train_pred*0.9 +\n",
    "               xgb_train_pred*0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = stacked_pred*0.6 + xgb_pred*0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target'] = ensemble\n",
    "df.to_csv('submissionyy.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
