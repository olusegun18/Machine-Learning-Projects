{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import skew,norm  # for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "#Visualizing tools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#preprocessing tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "#ML Algoirthm\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "import sklearn.linear_model as linear_model\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "import sklearn.linear_model as linear_model\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import warnings\n",
    "\n",
    "from scipy.stats import sem\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrain = pd.read_csv('Train.csv')\n",
    "ttest = pd.read_csv('Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(ttrain['close'])):\n",
    "    #if np.isnan(ttrain['close'][i]):\n",
    "        #ttrain.drop([i], axis=0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data = pd.concat([ttrain,ttest]).reset_index(drop=True)\n",
    "fin_data.drop([\"id\",\"asset_id\"], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>url_shares</th>\n",
       "      <th>unique_url_shares</th>\n",
       "      <th>reddit_posts</th>\n",
       "      <th>reddit_posts_score</th>\n",
       "      <th>reddit_comments</th>\n",
       "      <th>...</th>\n",
       "      <th>percent_change_24h_rank</th>\n",
       "      <th>volume_24h_rank</th>\n",
       "      <th>social_volume_24h_rank</th>\n",
       "      <th>social_score_24h_rank</th>\n",
       "      <th>medium</th>\n",
       "      <th>youtube</th>\n",
       "      <th>social_volume</th>\n",
       "      <th>percent_change_24h</th>\n",
       "      <th>market_cap_global</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9422.849081</td>\n",
       "      <td>9428.490628</td>\n",
       "      <td>9422.849081</td>\n",
       "      <td>7.131986e+08</td>\n",
       "      <td>1.737635e+11</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>817.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>606.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4422</td>\n",
       "      <td>1.434516</td>\n",
       "      <td>2.818066e+11</td>\n",
       "      <td>9428.279323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7985.359278</td>\n",
       "      <td>7992.059917</td>\n",
       "      <td>7967.567267</td>\n",
       "      <td>4.004755e+08</td>\n",
       "      <td>1.426942e+11</td>\n",
       "      <td>920.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2159</td>\n",
       "      <td>-2.459507</td>\n",
       "      <td>2.126897e+11</td>\n",
       "      <td>7967.567267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49202.033778</td>\n",
       "      <td>49394.593518</td>\n",
       "      <td>49068.057046</td>\n",
       "      <td>3.017729e+09</td>\n",
       "      <td>9.166977e+11</td>\n",
       "      <td>1446.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>...</td>\n",
       "      <td>692.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10602</td>\n",
       "      <td>4.942448</td>\n",
       "      <td>1.530712e+12</td>\n",
       "      <td>49120.738484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10535.737119</td>\n",
       "      <td>10535.737119</td>\n",
       "      <td>10384.798216</td>\n",
       "      <td>1.150053e+09</td>\n",
       "      <td>1.921183e+11</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>749.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3996</td>\n",
       "      <td>2.609576</td>\n",
       "      <td>3.386925e+11</td>\n",
       "      <td>10384.798216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           open          high           low        volume    market_cap  \\\n",
       "0   9422.849081   9428.490628   9422.849081  7.131986e+08  1.737635e+11   \n",
       "1   7985.359278   7992.059917   7967.567267  4.004755e+08  1.426942e+11   \n",
       "2  49202.033778  49394.593518  49068.057046  3.017729e+09  9.166977e+11   \n",
       "3           NaN           NaN           NaN           NaN           NaN   \n",
       "4  10535.737119  10535.737119  10384.798216  1.150053e+09  1.921183e+11   \n",
       "\n",
       "   url_shares  unique_url_shares  reddit_posts  reddit_posts_score  \\\n",
       "0      1689.0              817.0          55.0               105.0   \n",
       "1       920.0              544.0          20.0               531.0   \n",
       "2      1446.0              975.0          72.0              1152.0   \n",
       "3         NaN                NaN          17.0               424.0   \n",
       "4      1012.0              638.0          24.0                42.0   \n",
       "\n",
       "   reddit_comments  ...  percent_change_24h_rank  volume_24h_rank  \\\n",
       "0             61.0  ...                    606.0              2.0   \n",
       "1            103.0  ...                      NaN              NaN   \n",
       "2            187.0  ...                    692.0              3.0   \n",
       "3            268.0  ...                      NaN              NaN   \n",
       "4             50.0  ...                    749.0              2.0   \n",
       "\n",
       "   social_volume_24h_rank  social_score_24h_rank  medium  youtube  \\\n",
       "0                     1.0                    1.0     2.0      5.0   \n",
       "1                     NaN                    NaN     NaN      NaN   \n",
       "2                     1.0                    1.0     NaN      NaN   \n",
       "3                     NaN                    NaN     NaN      NaN   \n",
       "4                     1.0                    1.0     NaN      2.0   \n",
       "\n",
       "   social_volume  percent_change_24h  market_cap_global         close  \n",
       "0           4422            1.434516       2.818066e+11   9428.279323  \n",
       "1           2159           -2.459507       2.126897e+11   7967.567267  \n",
       "2          10602            4.942448       1.530712e+12  49120.738484  \n",
       "3            285                 NaN                NaN           NaN  \n",
       "4           3996            2.609576       3.386925e+11  10384.798216  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 1159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>76.657473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youtube</th>\n",
       "      <td>62.220219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>close</th>\n",
       "      <td>54.296171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social_score_24h_rank</th>\n",
       "      <td>35.446059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social_volume_24h_rank</th>\n",
       "      <td>35.446059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volume_24h_rank</th>\n",
       "      <td>35.446059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_change_24h_rank</th>\n",
       "      <td>35.446059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_change_24h</th>\n",
       "      <td>33.892012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market_cap_rank</th>\n",
       "      <td>33.796542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market_cap_global</th>\n",
       "      <td>33.536650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market_cap</th>\n",
       "      <td>33.329797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatility</th>\n",
       "      <td>31.987907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>31.881829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url_shares</th>\n",
       "      <td>31.791662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_url_shares</th>\n",
       "      <td>31.791662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_favorites</th>\n",
       "      <td>31.786358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_followers</th>\n",
       "      <td>31.786358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_replies</th>\n",
       "      <td>31.786358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_retweets</th>\n",
       "      <td>31.786358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_quotes</th>\n",
       "      <td>31.786358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Missing Ratio\n",
       "medium                       76.657473\n",
       "youtube                      62.220219\n",
       "close                        54.296171\n",
       "social_score_24h_rank        35.446059\n",
       "social_volume_24h_rank       35.446059\n",
       "volume_24h_rank              35.446059\n",
       "percent_change_24h_rank      35.446059\n",
       "percent_change_24h           33.892012\n",
       "market_cap_rank              33.796542\n",
       "market_cap_global            33.536650\n",
       "market_cap                   33.329797\n",
       "volatility                   31.987907\n",
       "news                         31.881829\n",
       "url_shares                   31.791662\n",
       "unique_url_shares            31.791662\n",
       "tweet_favorites              31.786358\n",
       "tweet_followers              31.786358\n",
       "tweet_replies                31.786358\n",
       "tweet_retweets               31.786358\n",
       "tweet_quotes                 31.786358"
      ]
     },
     "execution_count": 1160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data_na = (fin_data.isnull().sum() / len(fin_data)) * 100\n",
    "fin_data_na = fin_data_na.drop(fin_data_na[fin_data_na == 0].index).sort_values(ascending=False)[:25]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :fin_data_na})\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing With Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fin_data = fin_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop the medium feature. It has too many missing values\n",
    "fin_data.drop(['medium'],axis =1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open                        5933\n",
       "high                        5933\n",
       "low                         5933\n",
       "volume                      5947\n",
       "market_cap                  6284\n",
       "url_shares                  5994\n",
       "unique_url_shares           5994\n",
       "reddit_posts                 341\n",
       "reddit_posts_score           341\n",
       "reddit_comments              343\n",
       "reddit_comments_score        343\n",
       "tweets                      5981\n",
       "tweet_spam                  5981\n",
       "tweet_followers             5993\n",
       "tweet_quotes                5993\n",
       "tweet_retweets              5993\n",
       "tweet_replies               5993\n",
       "tweet_favorites             5993\n",
       "tweet_sentiment1            5981\n",
       "tweet_sentiment2            5981\n",
       "tweet_sentiment3            5981\n",
       "tweet_sentiment4            5981\n",
       "tweet_sentiment5            5981\n",
       "tweet_sentiment_impact1     5981\n",
       "tweet_sentiment_impact2     5981\n",
       "tweet_sentiment_impact3     5981\n",
       "tweet_sentiment_impact4     5981\n",
       "tweet_sentiment_impact5     5981\n",
       "social_score                5981\n",
       "average_sentiment           5981\n",
       "news                        6011\n",
       "price_score                 5981\n",
       "social_impact_score         5981\n",
       "correlation_rank            5981\n",
       "galaxy_score                5981\n",
       "volatility                  6031\n",
       "market_cap_rank             6372\n",
       "percent_change_24h_rank     6683\n",
       "volume_24h_rank             6683\n",
       "social_volume_24h_rank      6683\n",
       "social_score_24h_rank       6683\n",
       "youtube                    11731\n",
       "social_volume                  0\n",
       "percent_change_24h          6390\n",
       "market_cap_global           6323\n",
       "close                      10237\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Most of the missing values are concentrated in the test set, so we fill open, high, and low with the mean of the training set\\n'"
      ]
     },
     "execution_count": 1164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Most of the missing values are concentrated in the test set, so we fill open, high, and low with the mean of the training set\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffillna(col):\n",
    "    for i in col:\n",
    "        fin_data[i].fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['percent_change_24h','social_score_24h_rank','social_volume_24h_rank',\n",
    "         'volume_24h_rank','percent_change_24h_rank','close']\n",
    "ffillna(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill(col):\n",
    "    for i in col:\n",
    "        fin_data[i].ffill(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['volume','unique_url_shares','reddit_posts','tweets','news','youtube',\n",
    "         'tweet_spam','tweet_followers','tweet_quotes','tweet_retweets','tweet_replies','tweet_favorites',\n",
    "         'tweet_sentiment1','tweet_sentiment2','tweet_sentiment3','tweet_sentiment4','tweet_sentiment5',\n",
    "         'social_volume']\n",
    "fill(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfill(col):\n",
    "    for i in col:\n",
    "        fin_data[i].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_col = ['open','high','low','market_cap_rank','market_cap_global','social_volume_24h_rank','market_cap','url_shares',\n",
    "         'reddit_comments','reddit_posts_score','reddit_comments_score','volume_24h_rank','percent_change_24h_rank']\n",
    "mfill(f_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medfill(col):\n",
    "    for i in col:\n",
    "        fin_data[i].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_col = ['tweet_sentiment_impact1','tweet_sentiment_impact2','tweet_sentiment_impact3',\n",
    "           'tweet_sentiment_impact4','tweet_sentiment_impact5','social_score','average_sentiment',\n",
    "          'price_score','social_impact_score','correlation_rank','galaxy_score','volatility']\n",
    "medfill(med_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data['Reddit1'] = fin_data['reddit_posts']*fin_data['reddit_posts_score']\n",
    "fin_data['Reddit2'] = fin_data['reddit_comments']*fin_data['reddit_comments_score']\n",
    "#fin_data['social'] = fin_data['social_score']*fin_data['social_impact_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fin_data['bet'] = fin_data['open']-fin_data['low']\n",
    "fin_data['new'] = fin_data['high']*fin_data['volume']*fin_data['market_cap_rank']\n",
    "fin_data['new2'] = fin_data['high']*fin_data['social_volume_24h_rank']*fin_data['reddit_posts']\n",
    "fin_data['social'] = fin_data['tweets']*fin_data['tweet_retweets']*fin_data['tweet_spam']*fin_data['unique_url_shares']*fin_data['social_impact_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1175,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data['low2'] = fin_data['low']**2\n",
    "fin_data['low3'] = fin_data['low']**3\n",
    "fin_data['high2'] = fin_data['high']**2\n",
    "\n",
    "fin_data['high3'] = fin_data['high']**3\n",
    "fin_data['open2'] = fin_data['open']**2\n",
    "fin_data['open3'] = fin_data['open']**3\n",
    "\n",
    "fin_data['market_cap2'] = fin_data['market_cap']**2\n",
    "fin_data['market_cap3'] = fin_data['market_cap']**3\n",
    "fin_data['market_cap_global2'] = fin_data['market_cap_global']**2\n",
    "\n",
    "fin_data['market_cap_global3'] = fin_data['market_cap_global']**3\n",
    "fin_data['new2_2'] = fin_data['new2']**2\n",
    "fin_data['new22'] = fin_data['new']**2\n",
    "\n",
    "fin_data['new23'] = fin_data['new']**3\n",
    "fin_data['tweet_spam2'] = fin_data['tweet_spam']**2\n",
    "fin_data['reddit_posts2'] = fin_data['reddit_posts']**2\n",
    "\n",
    "fin_data['social_volume2'] = fin_data['social_volume']**2\n",
    "fin_data['social3'] = fin_data['social']**3\n",
    "fin_data['social2'] = fin_data['social']**2\n",
    "\n",
    "fin_data['news3'] = fin_data['news']**3\n",
    "fin_data['volume3'] = fin_data['volume']**3\n",
    "fin_data['volume'] = fin_data['volume']**2\n",
    "\n",
    "fin_data['percent_change_24h'] = fin_data['percent_change_24h']**3\n",
    "#fin_data['social_score_24h_rank'] = fin_data['social_score_24h_rank']**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fin_data['LogReturn'] = np.log(fin_data['close']).shift(-1) - np.log(fin_data['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1177,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data['MA10'] = fin_data['close'].rolling(500).mean()\n",
    "fin_data['MA50'] = fin_data['close'].rolling(1000).mean()\n",
    "fin_data['Shares'] = [1 if fin_data.loc[ei, 'MA10']>fin_data.loc[ei, 'MA50'] else 0 for ei in fin_data.index]\n",
    "#fin_data['Close1'] = fin_data['close'].shift(-1)\n",
    "#fin_data['Profit'] = [fin_data.loc[ei, 'Close1'] - fin_data.loc[ei, 'close'] if fin_data.loc[ei, 'Shares']==1 else 0 for ei in fin_data.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data['PriceDiff'] = fin_data['close'].shift(-1) - fin_data['close']\n",
    "#fin_data['Return'] = fin_data['PriceDiff'] /fin_data['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new23                 135.222905\n",
       "social3               132.840671\n",
       "social2               121.758133\n",
       "new22                 107.523895\n",
       "tweet_quotes           93.979052\n",
       "                         ...    \n",
       "average_sentiment      -0.779066\n",
       "percent_change_24h    -27.116579\n",
       "MA10                         NaN\n",
       "MA50                         NaN\n",
       "PriceDiff                    NaN\n",
       "Length: 75, dtype: float64"
      ]
     },
     "execution_count": 1179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import skew\n",
    "skewness = fin_data.apply(lambda x: skew(x))\n",
    "skewness.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data = fin_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fin_data['MA10'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>url_shares</th>\n",
       "      <th>unique_url_shares</th>\n",
       "      <th>reddit_posts</th>\n",
       "      <th>reddit_posts_score</th>\n",
       "      <th>reddit_comments</th>\n",
       "      <th>...</th>\n",
       "      <th>reddit_posts2</th>\n",
       "      <th>social_volume2</th>\n",
       "      <th>social3</th>\n",
       "      <th>social2</th>\n",
       "      <th>news3</th>\n",
       "      <th>volume3</th>\n",
       "      <th>MA10</th>\n",
       "      <th>MA50</th>\n",
       "      <th>Shares</th>\n",
       "      <th>PriceDiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9422.849081</td>\n",
       "      <td>9428.490628</td>\n",
       "      <td>9422.849081</td>\n",
       "      <td>5.086523e+17</td>\n",
       "      <td>1.737635e+11</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>817.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3025.0</td>\n",
       "      <td>19554084</td>\n",
       "      <td>1.150295e+40</td>\n",
       "      <td>5.095728e+26</td>\n",
       "      <td>328509.0</td>\n",
       "      <td>3.627701e+26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1460.712056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7985.359278</td>\n",
       "      <td>7992.059917</td>\n",
       "      <td>7967.567267</td>\n",
       "      <td>1.603806e+17</td>\n",
       "      <td>1.426942e+11</td>\n",
       "      <td>920.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>400.0</td>\n",
       "      <td>4661281</td>\n",
       "      <td>7.411687e+34</td>\n",
       "      <td>1.764458e+23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.422852e+25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>41153.171217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49202.033778</td>\n",
       "      <td>49394.593518</td>\n",
       "      <td>49068.057046</td>\n",
       "      <td>9.106688e+18</td>\n",
       "      <td>9.166977e+11</td>\n",
       "      <td>1446.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5184.0</td>\n",
       "      <td>112402404</td>\n",
       "      <td>1.078551e+43</td>\n",
       "      <td>4.881582e+28</td>\n",
       "      <td>10648.0</td>\n",
       "      <td>2.748151e+28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-49120.738484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.106688e+18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>...</td>\n",
       "      <td>289.0</td>\n",
       "      <td>81225</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>10648.0</td>\n",
       "      <td>2.748151e+28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10384.798216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10535.737119</td>\n",
       "      <td>10535.737119</td>\n",
       "      <td>10384.798216</td>\n",
       "      <td>1.322623e+18</td>\n",
       "      <td>1.921183e+11</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>576.0</td>\n",
       "      <td>15968016</td>\n",
       "      <td>2.975483e+38</td>\n",
       "      <td>4.456956e+25</td>\n",
       "      <td>10648.0</td>\n",
       "      <td>1.521087e+27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-10384.798216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18849</th>\n",
       "      <td>8266.942912</td>\n",
       "      <td>8266.942912</td>\n",
       "      <td>8259.796103</td>\n",
       "      <td>9.613951e+16</td>\n",
       "      <td>1.491229e+11</td>\n",
       "      <td>618.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>225.0</td>\n",
       "      <td>2232036</td>\n",
       "      <td>1.856380e+32</td>\n",
       "      <td>3.254203e+21</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.980937e+25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18850</th>\n",
       "      <td>10869.612767</td>\n",
       "      <td>10873.493490</td>\n",
       "      <td>10865.827625</td>\n",
       "      <td>4.885116e+17</td>\n",
       "      <td>2.011601e+11</td>\n",
       "      <td>1608.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>49914225</td>\n",
       "      <td>1.468963e+43</td>\n",
       "      <td>5.998010e+28</td>\n",
       "      <td>29791.0</td>\n",
       "      <td>3.414384e+26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18851</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.885116e+17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>30625</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>29791.0</td>\n",
       "      <td>3.414384e+26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18852</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.885116e+17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>29791.0</td>\n",
       "      <td>3.414384e+26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18853</th>\n",
       "      <td>7058.172796</td>\n",
       "      <td>7078.973345</td>\n",
       "      <td>7052.332304</td>\n",
       "      <td>2.238172e+17</td>\n",
       "      <td>1.275507e+11</td>\n",
       "      <td>954.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>400.0</td>\n",
       "      <td>12033961</td>\n",
       "      <td>2.546919e+35</td>\n",
       "      <td>4.018002e+23</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.058864e+26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18854 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               open          high           low        volume    market_cap  \\\n",
       "0       9422.849081   9428.490628   9422.849081  5.086523e+17  1.737635e+11   \n",
       "1       7985.359278   7992.059917   7967.567267  1.603806e+17  1.426942e+11   \n",
       "2      49202.033778  49394.593518  49068.057046  9.106688e+18  9.166977e+11   \n",
       "3          0.000000      0.000000      0.000000  9.106688e+18  0.000000e+00   \n",
       "4      10535.737119  10535.737119  10384.798216  1.322623e+18  1.921183e+11   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "18849   8266.942912   8266.942912   8259.796103  9.613951e+16  1.491229e+11   \n",
       "18850  10869.612767  10873.493490  10865.827625  4.885116e+17  2.011601e+11   \n",
       "18851      0.000000      0.000000      0.000000  4.885116e+17  0.000000e+00   \n",
       "18852      0.000000      0.000000      0.000000  4.885116e+17  0.000000e+00   \n",
       "18853   7058.172796   7078.973345   7052.332304  2.238172e+17  1.275507e+11   \n",
       "\n",
       "       url_shares  unique_url_shares  reddit_posts  reddit_posts_score  \\\n",
       "0          1689.0              817.0          55.0               105.0   \n",
       "1           920.0              544.0          20.0               531.0   \n",
       "2          1446.0              975.0          72.0              1152.0   \n",
       "3             0.0              975.0          17.0               424.0   \n",
       "4          1012.0              638.0          24.0                42.0   \n",
       "...           ...                ...           ...                 ...   \n",
       "18849       618.0              438.0          15.0               202.0   \n",
       "18850      1608.0              911.0          84.0               204.0   \n",
       "18851         0.0              911.0           8.0               139.0   \n",
       "18852         0.0              911.0           6.0                85.0   \n",
       "18853       954.0              672.0          20.0               110.0   \n",
       "\n",
       "       reddit_comments  ...  reddit_posts2  social_volume2       social3  \\\n",
       "0                 61.0  ...         3025.0        19554084  1.150295e+40   \n",
       "1                103.0  ...          400.0         4661281  7.411687e+34   \n",
       "2                187.0  ...         5184.0       112402404  1.078551e+43   \n",
       "3                268.0  ...          289.0           81225  0.000000e+00   \n",
       "4                 50.0  ...          576.0        15968016  2.975483e+38   \n",
       "...                ...  ...            ...             ...           ...   \n",
       "18849             42.0  ...          225.0         2232036  1.856380e+32   \n",
       "18850             45.0  ...         7056.0        49914225  1.468963e+43   \n",
       "18851            167.0  ...           64.0           30625  0.000000e+00   \n",
       "18852              0.0  ...           36.0              36  0.000000e+00   \n",
       "18853             65.0  ...          400.0        12033961  2.546919e+35   \n",
       "\n",
       "            social2     news3       volume3  MA10  MA50  Shares     PriceDiff  \n",
       "0      5.095728e+26  328509.0  3.627701e+26   0.0   0.0       0  -1460.712056  \n",
       "1      1.764458e+23       1.0  6.422852e+25   0.0   0.0       0  41153.171217  \n",
       "2      4.881582e+28   10648.0  2.748151e+28   0.0   0.0       0 -49120.738484  \n",
       "3      0.000000e+00   10648.0  2.748151e+28   0.0   0.0       0  10384.798216  \n",
       "4      4.456956e+25   10648.0  1.521087e+27   0.0   0.0       0 -10384.798216  \n",
       "...             ...       ...           ...   ...   ...     ...           ...  \n",
       "18849  3.254203e+21      27.0  2.980937e+25   0.0   0.0       0      0.000000  \n",
       "18850  5.998010e+28   29791.0  3.414384e+26   0.0   0.0       0      0.000000  \n",
       "18851  0.000000e+00   29791.0  3.414384e+26   0.0   0.0       0      0.000000  \n",
       "18852  0.000000e+00   29791.0  3.414384e+26   0.0   0.0       0      0.000000  \n",
       "18853  4.018002e+23      64.0  1.058864e+26   0.0   0.0       0      0.000000  \n",
       "\n",
       "[18854 rows x 75 columns]"
      ]
     },
     "execution_count": 1182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fin_data.drop(['MA10','MA50','PriceDiff','Close1'],axis =1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n'Close1','Shares'\\n\\n\""
      ]
     },
     "execution_count": 1184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "'Close1','Shares'\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "#scaler = StandardScaler()\n",
    "#fin_data['dist_to_shoreline'] = pd.DataFrame(scaler.fit_transform(fin_data['dist_to_shoreline'].values.reshape(-1,1)))\n",
    "#fin_data['dist_to_capital'] = pd.DataFrame(scaler.fit_transform(fin_data['dist_to_capital'].values.reshape(-1,1)))\n",
    "\n",
    "fin_data['close'] = pd.DataFrame(scaler.fit_transform(fin_data['close'].values.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state=99)\n",
    "split=ttrain.shape[0]\n",
    "train_df=fin_data[:split]\n",
    "test_df=fin_data[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(['close'],axis=1, inplace = True)\n",
    "X =train_df.drop(['close'],axis=1)\n",
    "y = train_df['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,y_train, y_test = train_test_split(X, y,test_size=0.35, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, SGDRegressor, ElasticNet\n",
    "# Instantiate model\n",
    "lm2 = Ridge()\n",
    "# Fit Model\n",
    "lm_model = lm2.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred = lm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007986846340069728"
      ]
     },
     "execution_count": 1190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.34701556e-01],\n",
       "       [ 1.13541075e+04],\n",
       "       [ 6.29702976e+03],\n",
       "       ...,\n",
       "       [-6.73986758e+00],\n",
       "       [-5.52763752e+00],\n",
       "       [ 7.07206940e+03]])"
      ]
     },
     "execution_count": 1193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1192,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lm_model.predict(test_df)\n",
    "real = scaler.inverse_transform(preds.reshape(-1,1))\n",
    "\n",
    "df = pd.read_csv('SampleSubmission.csv')\n",
    "df['close'] = real\n",
    "df.to_csv('Regression2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from scipy.stats import skew\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(mean_squared_error, greater_is_better = False)\n",
    "\n",
    "def rmse_cv_train(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, y_train, scoring = scorer, cv = 50))\n",
    "    return(rmse)\n",
    "\n",
    "def rmse_cv_test(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_test, y_test, scoring = scorer, cv = 50))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha : 0.01\n",
      "Try again for more precision with alphas centered around 0.01\n",
      "Best alpha : 0.013999999999999999\n"
     ]
    }
   ],
   "source": [
    "ridge = RidgeCV(alphas = [0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1, 3, 6, 10, 30, 60])\n",
    "ridge.fit(X_train, y_train)\n",
    "alpha = ridge.alpha_\n",
    "print(\"Best alpha :\", alpha)\n",
    "\n",
    "\n",
    "print(\"Try again for more precision with alphas centered around \" + str(alpha))\n",
    "ridge = RidgeCV(alphas = [alpha * .6, alpha * .65, alpha * .7, alpha * .75, alpha * .8, alpha * .85, \n",
    "                          alpha * .9, alpha * .95, alpha, alpha * 1.05, alpha * 1.1, alpha * 1.15,\n",
    "                          alpha * 1.25, alpha * 1.3, alpha * 1.35, alpha * 1.4], \n",
    "                cv = 15)\n",
    "\n",
    "\n",
    "ridge.fit(X_train, y_train)\n",
    "alpha = ridge.alpha_\n",
    "print(\"Best alpha :\", alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge RMSE on Training set : 48.09278271000508\n",
      "Ridge RMSE on Test set : 343.9843810379643\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Ridge RMSE on Training set :\", rmse_cv_train(ridge).mean())\n",
    "print(\"Ridge RMSE on Test set :\", rmse_cv_test(ridge).mean())\n",
    "y_train_rdg = ridge.predict(X_train)\n",
    "y_test_rdg = ridge.predict(X_test)\n",
    "\n",
    "# Plot residuals\n",
    "plt.scatter(y_train_rdg, y_train_rdg - y_train, c = \"blue\", marker = \"s\", label = \"Training data\")\n",
    "plt.scatter(y_test_rdg, y_test_rdg - y_test, c = \"lightgreen\", marker = \"s\", label = \"Validation data\")\n",
    "plt.title(\"Linear regression with Ridge regularization\")\n",
    "plt.xlabel(\"Predicted values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.hlines(y = 0, xmin = 10.5, xmax = 13.5, color = \"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ridge.predict(test_df)\n",
    "\n",
    "df = pd.read_csv('SampleSubmission.csv')\n",
    "df['close'] = preds\n",
    "df.to_csv('Regression.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.653496453473239\n",
      "12.07740988571283\n",
      "19.70994979376652\n",
      "28.239031004088098\n",
      "33.15741127272694\n",
      "38.90595486027148\n",
      "43.629398116694944\n",
      "49.2546170295813\n",
      "55.09928612339267\n",
      "61.36121904273893\n",
      "67.60497274595414\n",
      "75.1283146150525\n",
      "83.53976616982015\n",
      "114.1610301205951\n",
      "120.2533031341924\n",
      "125.67693935945147\n",
      "132.3480094287574\n",
      "137.35879765715617\n",
      "143.7254337806373\n",
      "147.9757073785552\n",
      "153.18592620204436\n",
      "158.4530335886248\n",
      "165.06973512981543\n",
      "170.77387313153764\n",
      "174.4110596072818\n",
      "180.53866492721357\n",
      "184.44540315209875\n",
      "191.021231303218\n",
      "195.9452089288682\n",
      "201.77139033167225\n",
      "207.2390006892074\n",
      "212.39002434796026\n",
      "218.36305260016678\n",
      "222.6900796421517\n",
      "228.03587214474612\n",
      "233.52114162252778\n",
      "238.34425890564458\n",
      "245.19523005715007\n",
      "251.8657242729377\n",
      "258.19262761459396\n",
      "263.43408785845384\n",
      "269.0078791003161\n",
      "275.24648982070073\n",
      "279.7389851730415\n",
      "284.5509200253108\n",
      "289.62302775783166\n",
      "293.81433688838774\n",
      "300.2720832668114\n",
      "304.85024376134965\n",
      "310.5043794717706\n"
     ]
    }
   ],
   "source": [
    "fold_score = 0\n",
    "t_pred = []\n",
    "\n",
    "n = 8\n",
    "kf = StratifiedKFold(n)\n",
    "kf = KFold(n_splits=50, random_state=1, shuffle = True)\n",
    "kf.get_n_splits(X)\n",
    "  \n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    Xtrain, Xtest = X.loc[train_index], X.loc[test_index]\n",
    "    ytrain, ytest = y[train_index], y[test_index]\n",
    "\n",
    "    model = Ridge(alpha=0.42)\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    \n",
    "    pred = model.predict(Xtest)\n",
    "    score = np.sqrt(mean_squared_error(ytest, pred))\n",
    "    fold_score = fold_score + (score/n)\n",
    "    print(fold_score)\n",
    "    \n",
    "    predictions = model.predict(test_df)\n",
    "    t_pred.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SampleSubmission.csv')\n",
    "df['close'] = np.mean(t_pred, axis = 0)\n",
    "df.to_csv('CatA.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': (np.logspace(-8, 8, 100))} # It will check from 1e-08 to 1e+08\n",
    "ridge = Ridge(normalize=True)\n",
    "ridge_model = GridSearchCV(ridge, params, cv = 10)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "print(ridge_model.best_params_)\n",
    "print(ridge_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(normalize=True, alpha=0.1, fit_intercept=True, solver='sparse_cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fin_data.drop(['reddit_posts','reddit_posts_score','reddit_comments','reddit_comments_score',\n",
    "              #'social_score','social_impact_score'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fin_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "#from statsmodels.tools.tools import add_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\ndef vif_scores(df):\\n    VIF_Scores = pd.DataFrame()\\n    VIF_Scores[\"Independent Features\"] = df.columns\\n    VIF_Scores[\"VIF Scores\"] = [variance_inflation_factor(df.values,i) for i in range(df.shape[1])]\\n    return VIF_Scores\\n\\ndf1 = fin_data.iloc[:,:-1]\\nvif_scores(df1)\\n\\n'"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "def vif_scores(df):\n",
    "    VIF_Scores = pd.DataFrame()\n",
    "    VIF_Scores[\"Independent Features\"] = df.columns\n",
    "    VIF_Scores[\"VIF Scores\"] = [variance_inflation_factor(df.values,i) for i in range(df.shape[1])]\n",
    "    return VIF_Scores\n",
    "\n",
    "df1 = fin_data.iloc[:,:-1]\n",
    "vif_scores(df1)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nlstt = ['open','high','low','volume','market_cap','tweets',\\n        'tweet_followers','tweet_sentiment_impact2','tweet_sentiment_impact4','price_score',\\n        'correlation_rank','galaxy_score','social_volume','market_cap_global']\\n\\nfor i in lstt:\\n    y,fitted = stats.boxcox(fin_data[i], lmbda = None)\\n    fin_data[i] = pd.DataFrame(y)\\n\\n\""
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "lstt = ['open','high','low','volume','market_cap','tweets',\n",
    "        'tweet_followers','tweet_sentiment_impact2','tweet_sentiment_impact4','price_score',\n",
    "        'correlation_rank','galaxy_score','social_volume','market_cap_global']\n",
    "\n",
    "for i in lstt:\n",
    "    y,fitted = stats.boxcox(fin_data[i], lmbda = None)\n",
    "    fin_data[i] = pd.DataFrame(y)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nlstt = df1.columns\\n\\nfor i in lstt:\\n    y = boxcox1p(fin_data[i], 0.1)\\n    fin_data[i] = pd.DataFrame(y)\\n\\n'"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "lstt = df1.columns\n",
    "\n",
    "for i in lstt:\n",
    "    y = boxcox1p(fin_data[i], 0.1)\n",
    "    fin_data[i] = pd.DataFrame(y)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnumeric = fin_data.select_dtypes(include = \\'number\\').columns\\nskew_features = fin_data[numeric].apply(lambda x: skew(x)).sort_values(ascending = False)\\n\\nfrom pandas import DataFrame\\nhigh_skew = skew_features[skew_features > 0.5]\\nskew_index = high_skew.index\\nprint(\"There are {} numerical features with Skew > 0.5:\".format(high_skew.shape[0]))\\nSkewness = pd.DataFrame({\\'Skew\\':high_skew})\\nSkewness.head(20)\\n\\n'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "numeric = fin_data.select_dtypes(include = 'number').columns\n",
    "skew_features = fin_data[numeric].apply(lambda x: skew(x)).sort_values(ascending = False)\n",
    "\n",
    "from pandas import DataFrame\n",
    "high_skew = skew_features[skew_features > 0.5]\n",
    "skew_index = high_skew.index\n",
    "print(\"There are {} numerical features with Skew > 0.5:\".format(high_skew.shape[0]))\n",
    "Skewness = pd.DataFrame({'Skew':high_skew})\n",
    "Skewness.head(20)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in Skewness.index.drop(['close']):\\n    fin_data[i] = np.log1p(fin_data[i])\\n\\n\""
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for i in Skewness.index.drop(['close']):\n",
    "    fin_data[i] = np.log1p(fin_data[i])\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data['bet'] = fin_data['high']-fin_data['low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state=99)\n",
    "split=ttrain.shape[0]\n",
    "train_df=fin_data[:split]\n",
    "test_df=fin_data[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4315: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "test_df.drop(['close'],axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =train_df.drop(['close'],axis=1)\n",
    "y = train_df['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51,)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49,)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8617, 50)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Instantiate model\n",
    "lm2 = LinearRegression()\n",
    "# Fit Model\n",
    "lm2.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred = lm2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions in test set and prepare submission file\n",
    "main_cols = test_df.columns.difference(['close'])\n",
    "predictions = lm2.predict(test_df)\n",
    "\n",
    "ss = pd.read_csv('SampleSubmission.csv')\n",
    "sub_file = ss.copy()\n",
    "sub_file.close = predictions\n",
    "sub_file.to_csv('Basel.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_323Sn2</td>\n",
       "      <td>10.980851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_325SNW</td>\n",
       "      <td>11362.411806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_325uzE</td>\n",
       "      <td>6305.486499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_328qCx</td>\n",
       "      <td>14.479953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_3293uJ</td>\n",
       "      <td>13.796394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         close\n",
       "0  ID_323Sn2     10.980851\n",
       "1  ID_325SNW  11362.411806\n",
       "2  ID_325uzE   6305.486499\n",
       "3  ID_328qCx     14.479953\n",
       "4  ID_3293uJ     13.796394"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import warnings\n",
    "\n",
    "from scipy.stats import sem\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['close'],axis =1)\n",
    "y = train_df['close']\n",
    "train_labels = y\n",
    "\n",
    "test_df = test_df.drop(['close'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "scaler =RobustScaler()\n",
    "\n",
    "\n",
    "for i in X.columns:\n",
    "    X[i] = pd.DataFrame(scaler.fit_transform(X[i].values.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 29, ## using 29 and 30\n",
    "     'min_data_in_leaf': 50, \n",
    "     'objective':'regression',\n",
    "     'max_depth': 18,\n",
    "     'learning_rate': 0.06,\n",
    "     \"boosting\": \"gbdt\",\n",
    "     \"feature_fraction\": 0.2,\n",
    "     \"bagging_freq\": 0,\n",
    "     \"bagging_fraction\": 1.0 ,\n",
    "     \"bagging_seed\": 4,\n",
    "     \"metric\": 'rmse',\n",
    "     \"verbosity\": 1,\n",
    "     \"verbose_eval\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\ttraining's rmse: 532.342\tvalid_1's rmse: 770.523\n",
      "[200]\ttraining's rmse: 330.228\tvalid_1's rmse: 630.245\n",
      "[300]\ttraining's rmse: 247.069\tvalid_1's rmse: 586.55\n",
      "[400]\ttraining's rmse: 199.495\tvalid_1's rmse: 568.121\n",
      "[500]\ttraining's rmse: 167.812\tvalid_1's rmse: 557.442\n",
      "[600]\ttraining's rmse: 144.983\tvalid_1's rmse: 551.767\n",
      "[700]\ttraining's rmse: 126.916\tvalid_1's rmse: 546.383\n",
      "[800]\ttraining's rmse: 112.59\tvalid_1's rmse: 542.696\n",
      "[900]\ttraining's rmse: 101.344\tvalid_1's rmse: 541.092\n",
      "[1000]\ttraining's rmse: 92.0147\tvalid_1's rmse: 539.579\n",
      "[1100]\ttraining's rmse: 83.7268\tvalid_1's rmse: 538.364\n",
      "[1200]\ttraining's rmse: 76.3261\tvalid_1's rmse: 537.886\n",
      "[1300]\ttraining's rmse: 70.0173\tvalid_1's rmse: 537.506\n",
      "[1400]\ttraining's rmse: 64.5075\tvalid_1's rmse: 537.349\n",
      "[1500]\ttraining's rmse: 59.6788\tvalid_1's rmse: 536.726\n",
      "[1600]\ttraining's rmse: 55.184\tvalid_1's rmse: 536.228\n",
      "[1700]\ttraining's rmse: 51.2886\tvalid_1's rmse: 535.531\n",
      "[1800]\ttraining's rmse: 47.6991\tvalid_1's rmse: 534.943\n",
      "[1900]\ttraining's rmse: 44.5014\tvalid_1's rmse: 534.613\n",
      "[2000]\ttraining's rmse: 41.488\tvalid_1's rmse: 534.095\n",
      "[2100]\ttraining's rmse: 38.681\tvalid_1's rmse: 533.908\n",
      "[2200]\ttraining's rmse: 36.3333\tvalid_1's rmse: 533.718\n",
      "[2300]\ttraining's rmse: 34.0542\tvalid_1's rmse: 533.362\n",
      "[2400]\ttraining's rmse: 31.9526\tvalid_1's rmse: 533.227\n",
      "[2500]\ttraining's rmse: 30.0784\tvalid_1's rmse: 533.13\n",
      "[2600]\ttraining's rmse: 28.2332\tvalid_1's rmse: 533.038\n",
      "[2700]\ttraining's rmse: 26.5982\tvalid_1's rmse: 532.721\n",
      "[2800]\ttraining's rmse: 25.0323\tvalid_1's rmse: 532.689\n",
      "[2900]\ttraining's rmse: 23.6612\tvalid_1's rmse: 532.541\n",
      "[3000]\ttraining's rmse: 22.3458\tvalid_1's rmse: 532.362\n",
      "[3100]\ttraining's rmse: 21.0759\tvalid_1's rmse: 532.28\n",
      "[3200]\ttraining's rmse: 19.9374\tvalid_1's rmse: 532.224\n",
      "[3300]\ttraining's rmse: 18.8049\tvalid_1's rmse: 532.149\n",
      "[3400]\ttraining's rmse: 17.8019\tvalid_1's rmse: 532.129\n",
      "[3500]\ttraining's rmse: 16.8539\tvalid_1's rmse: 532.029\n",
      "[3600]\ttraining's rmse: 15.9904\tvalid_1's rmse: 532.002\n",
      "[3700]\ttraining's rmse: 15.1493\tvalid_1's rmse: 531.993\n",
      "[3800]\ttraining's rmse: 14.3746\tvalid_1's rmse: 531.958\n",
      "[3900]\ttraining's rmse: 13.5894\tvalid_1's rmse: 531.943\n",
      "[4000]\ttraining's rmse: 12.9068\tvalid_1's rmse: 531.823\n",
      "[4100]\ttraining's rmse: 12.2529\tvalid_1's rmse: 531.785\n",
      "[4200]\ttraining's rmse: 11.6519\tvalid_1's rmse: 531.735\n",
      "[4300]\ttraining's rmse: 11.0626\tvalid_1's rmse: 531.707\n",
      "[4400]\ttraining's rmse: 10.5376\tvalid_1's rmse: 531.699\n",
      "[4500]\ttraining's rmse: 10.0524\tvalid_1's rmse: 531.659\n",
      "[4600]\ttraining's rmse: 9.56594\tvalid_1's rmse: 531.591\n",
      "[4700]\ttraining's rmse: 9.10856\tvalid_1's rmse: 531.564\n",
      "[4800]\ttraining's rmse: 8.69069\tvalid_1's rmse: 531.547\n",
      "[4900]\ttraining's rmse: 8.30063\tvalid_1's rmse: 531.511\n",
      "[5000]\ttraining's rmse: 7.928\tvalid_1's rmse: 531.5\n",
      "[5100]\ttraining's rmse: 7.54856\tvalid_1's rmse: 531.494\n",
      "[5200]\ttraining's rmse: 7.18972\tvalid_1's rmse: 531.485\n",
      "[5300]\ttraining's rmse: 6.84795\tvalid_1's rmse: 531.477\n",
      "[5400]\ttraining's rmse: 6.51614\tvalid_1's rmse: 531.476\n",
      "[5500]\ttraining's rmse: 6.21226\tvalid_1's rmse: 531.453\n",
      "[5600]\ttraining's rmse: 5.93216\tvalid_1's rmse: 531.443\n",
      "[5700]\ttraining's rmse: 5.68046\tvalid_1's rmse: 531.445\n",
      "[5800]\ttraining's rmse: 5.43261\tvalid_1's rmse: 531.436\n",
      "[5900]\ttraining's rmse: 5.20636\tvalid_1's rmse: 531.403\n",
      "[6000]\ttraining's rmse: 5.00194\tvalid_1's rmse: 531.387\n",
      "[6100]\ttraining's rmse: 4.79422\tvalid_1's rmse: 531.376\n",
      "[6200]\ttraining's rmse: 4.59296\tvalid_1's rmse: 531.367\n",
      "[6300]\ttraining's rmse: 4.39463\tvalid_1's rmse: 531.366\n",
      "[6400]\ttraining's rmse: 4.21836\tvalid_1's rmse: 531.374\n",
      "[6500]\ttraining's rmse: 4.04679\tvalid_1's rmse: 531.372\n",
      "[6600]\ttraining's rmse: 3.88602\tvalid_1's rmse: 531.366\n",
      "[6700]\ttraining's rmse: 3.74153\tvalid_1's rmse: 531.357\n",
      "[6800]\ttraining's rmse: 3.60432\tvalid_1's rmse: 531.358\n",
      "[6900]\ttraining's rmse: 3.46645\tvalid_1's rmse: 531.353\n",
      "[7000]\ttraining's rmse: 3.33443\tvalid_1's rmse: 531.346\n",
      "[7100]\ttraining's rmse: 3.21283\tvalid_1's rmse: 531.338\n",
      "[7200]\ttraining's rmse: 3.10215\tvalid_1's rmse: 531.35\n",
      "[7300]\ttraining's rmse: 2.9914\tvalid_1's rmse: 531.347\n",
      "[7400]\ttraining's rmse: 2.88334\tvalid_1's rmse: 531.337\n",
      "[7500]\ttraining's rmse: 2.77922\tvalid_1's rmse: 531.337\n",
      "[7600]\ttraining's rmse: 2.68655\tvalid_1's rmse: 531.343\n",
      "[7700]\ttraining's rmse: 2.5948\tvalid_1's rmse: 531.341\n",
      "[7800]\ttraining's rmse: 2.50451\tvalid_1's rmse: 531.345\n",
      "[7900]\ttraining's rmse: 2.42469\tvalid_1's rmse: 531.343\n",
      "Early stopping, best iteration is:\n",
      "[7431]\ttraining's rmse: 2.8501\tvalid_1's rmse: 531.331\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\ttraining's rmse: 530.306\tvalid_1's rmse: 725.435\n",
      "[200]\ttraining's rmse: 333.449\tvalid_1's rmse: 600.626\n",
      "[300]\ttraining's rmse: 250.571\tvalid_1's rmse: 554.992\n",
      "[400]\ttraining's rmse: 202.397\tvalid_1's rmse: 535.909\n",
      "[500]\ttraining's rmse: 170.461\tvalid_1's rmse: 524.624\n",
      "[600]\ttraining's rmse: 146.691\tvalid_1's rmse: 516.7\n",
      "[700]\ttraining's rmse: 128.642\tvalid_1's rmse: 511.422\n",
      "[800]\ttraining's rmse: 114.176\tvalid_1's rmse: 507.896\n",
      "[900]\ttraining's rmse: 102.236\tvalid_1's rmse: 506.163\n",
      "[1000]\ttraining's rmse: 92.3831\tvalid_1's rmse: 504.755\n",
      "[1100]\ttraining's rmse: 83.8982\tvalid_1's rmse: 503.566\n",
      "[1200]\ttraining's rmse: 76.6681\tvalid_1's rmse: 501.438\n",
      "[1300]\ttraining's rmse: 70.1504\tvalid_1's rmse: 500.736\n",
      "[1400]\ttraining's rmse: 64.6554\tvalid_1's rmse: 500.278\n",
      "[1500]\ttraining's rmse: 59.7797\tvalid_1's rmse: 499.799\n",
      "[1600]\ttraining's rmse: 55.5017\tvalid_1's rmse: 499.493\n",
      "[1700]\ttraining's rmse: 51.5022\tvalid_1's rmse: 499.191\n",
      "[1800]\ttraining's rmse: 47.9457\tvalid_1's rmse: 498.905\n",
      "[1900]\ttraining's rmse: 44.7041\tvalid_1's rmse: 498.503\n",
      "[2000]\ttraining's rmse: 41.6974\tvalid_1's rmse: 498.124\n",
      "[2100]\ttraining's rmse: 38.9665\tvalid_1's rmse: 497.913\n",
      "[2200]\ttraining's rmse: 36.4921\tvalid_1's rmse: 498.052\n",
      "[2300]\ttraining's rmse: 34.142\tvalid_1's rmse: 497.905\n",
      "[2400]\ttraining's rmse: 32.084\tvalid_1's rmse: 497.836\n",
      "[2500]\ttraining's rmse: 30.1952\tvalid_1's rmse: 497.627\n",
      "[2600]\ttraining's rmse: 28.4224\tvalid_1's rmse: 497.7\n",
      "[2700]\ttraining's rmse: 26.7834\tvalid_1's rmse: 497.565\n",
      "[2800]\ttraining's rmse: 25.2382\tvalid_1's rmse: 497.379\n",
      "[2900]\ttraining's rmse: 23.7563\tvalid_1's rmse: 497.391\n",
      "[3000]\ttraining's rmse: 22.3671\tvalid_1's rmse: 497.302\n",
      "[3100]\ttraining's rmse: 21.0743\tvalid_1's rmse: 497.252\n",
      "[3200]\ttraining's rmse: 19.9433\tvalid_1's rmse: 497.164\n",
      "[3300]\ttraining's rmse: 18.8481\tvalid_1's rmse: 497.062\n",
      "[3400]\ttraining's rmse: 17.8632\tvalid_1's rmse: 497.083\n",
      "[3500]\ttraining's rmse: 16.9079\tvalid_1's rmse: 497.028\n",
      "[3600]\ttraining's rmse: 16.0546\tvalid_1's rmse: 496.994\n",
      "[3700]\ttraining's rmse: 15.2418\tvalid_1's rmse: 496.963\n",
      "[3800]\ttraining's rmse: 14.4707\tvalid_1's rmse: 496.916\n",
      "[3900]\ttraining's rmse: 13.7716\tvalid_1's rmse: 496.856\n",
      "[4000]\ttraining's rmse: 13.1102\tvalid_1's rmse: 496.806\n",
      "[4100]\ttraining's rmse: 12.4613\tvalid_1's rmse: 496.776\n",
      "[4200]\ttraining's rmse: 11.8769\tvalid_1's rmse: 496.76\n",
      "[4300]\ttraining's rmse: 11.3271\tvalid_1's rmse: 496.709\n",
      "[4400]\ttraining's rmse: 10.8016\tvalid_1's rmse: 496.701\n",
      "[4500]\ttraining's rmse: 10.2749\tvalid_1's rmse: 496.703\n",
      "[4600]\ttraining's rmse: 9.80905\tvalid_1's rmse: 496.687\n",
      "[4700]\ttraining's rmse: 9.37152\tvalid_1's rmse: 496.648\n",
      "[4800]\ttraining's rmse: 8.95919\tvalid_1's rmse: 496.587\n",
      "[4900]\ttraining's rmse: 8.57944\tvalid_1's rmse: 496.562\n",
      "[5000]\ttraining's rmse: 8.20618\tvalid_1's rmse: 496.532\n",
      "[5100]\ttraining's rmse: 7.83432\tvalid_1's rmse: 496.528\n",
      "[5200]\ttraining's rmse: 7.51842\tvalid_1's rmse: 496.492\n",
      "[5300]\ttraining's rmse: 7.20966\tvalid_1's rmse: 496.494\n",
      "[5400]\ttraining's rmse: 6.91425\tvalid_1's rmse: 496.478\n",
      "[5500]\ttraining's rmse: 6.63421\tvalid_1's rmse: 496.44\n",
      "[5600]\ttraining's rmse: 6.38034\tvalid_1's rmse: 496.451\n",
      "[5700]\ttraining's rmse: 6.15271\tvalid_1's rmse: 496.447\n",
      "[5800]\ttraining's rmse: 5.91405\tvalid_1's rmse: 496.43\n",
      "[5900]\ttraining's rmse: 5.68716\tvalid_1's rmse: 496.414\n",
      "[6000]\ttraining's rmse: 5.47062\tvalid_1's rmse: 496.407\n",
      "[6100]\ttraining's rmse: 5.29212\tvalid_1's rmse: 496.409\n",
      "[6200]\ttraining's rmse: 5.09623\tvalid_1's rmse: 496.409\n",
      "[6300]\ttraining's rmse: 4.92235\tvalid_1's rmse: 496.407\n",
      "[6400]\ttraining's rmse: 4.75516\tvalid_1's rmse: 496.401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6500]\ttraining's rmse: 4.59321\tvalid_1's rmse: 496.379\n",
      "[6600]\ttraining's rmse: 4.44006\tvalid_1's rmse: 496.383\n",
      "[6700]\ttraining's rmse: 4.29126\tvalid_1's rmse: 496.372\n",
      "[6800]\ttraining's rmse: 4.15204\tvalid_1's rmse: 496.352\n",
      "[6900]\ttraining's rmse: 4.01864\tvalid_1's rmse: 496.349\n",
      "[7000]\ttraining's rmse: 3.89911\tvalid_1's rmse: 496.334\n",
      "[7100]\ttraining's rmse: 3.78321\tvalid_1's rmse: 496.317\n",
      "[7200]\ttraining's rmse: 3.66099\tvalid_1's rmse: 496.31\n",
      "[7300]\ttraining's rmse: 3.55234\tvalid_1's rmse: 496.304\n",
      "[7400]\ttraining's rmse: 3.4443\tvalid_1's rmse: 496.31\n",
      "[7500]\ttraining's rmse: 3.347\tvalid_1's rmse: 496.296\n",
      "[7600]\ttraining's rmse: 3.26535\tvalid_1's rmse: 496.291\n",
      "[7700]\ttraining's rmse: 3.18118\tvalid_1's rmse: 496.28\n",
      "[7800]\ttraining's rmse: 3.10019\tvalid_1's rmse: 496.275\n",
      "[7900]\ttraining's rmse: 3.01933\tvalid_1's rmse: 496.264\n",
      "[8000]\ttraining's rmse: 2.94108\tvalid_1's rmse: 496.256\n",
      "[8100]\ttraining's rmse: 2.86609\tvalid_1's rmse: 496.248\n",
      "[8200]\ttraining's rmse: 2.7988\tvalid_1's rmse: 496.243\n",
      "[8300]\ttraining's rmse: 2.73436\tvalid_1's rmse: 496.24\n",
      "[8400]\ttraining's rmse: 2.67203\tvalid_1's rmse: 496.237\n",
      "[8500]\ttraining's rmse: 2.60734\tvalid_1's rmse: 496.224\n",
      "[8600]\ttraining's rmse: 2.53759\tvalid_1's rmse: 496.217\n",
      "[8700]\ttraining's rmse: 2.4798\tvalid_1's rmse: 496.209\n",
      "[8800]\ttraining's rmse: 2.41966\tvalid_1's rmse: 496.201\n",
      "[8900]\ttraining's rmse: 2.3675\tvalid_1's rmse: 496.197\n",
      "[9000]\ttraining's rmse: 2.31628\tvalid_1's rmse: 496.196\n",
      "[9100]\ttraining's rmse: 2.25611\tvalid_1's rmse: 496.183\n",
      "[9200]\ttraining's rmse: 2.19891\tvalid_1's rmse: 496.181\n",
      "[9300]\ttraining's rmse: 2.15058\tvalid_1's rmse: 496.174\n",
      "[9400]\ttraining's rmse: 2.10629\tvalid_1's rmse: 496.174\n",
      "[9500]\ttraining's rmse: 2.05985\tvalid_1's rmse: 496.163\n",
      "[9600]\ttraining's rmse: 2.01081\tvalid_1's rmse: 496.154\n",
      "[9700]\ttraining's rmse: 1.96685\tvalid_1's rmse: 496.151\n",
      "[9800]\ttraining's rmse: 1.92204\tvalid_1's rmse: 496.153\n",
      "[9900]\ttraining's rmse: 1.87712\tvalid_1's rmse: 496.148\n",
      "[10000]\ttraining's rmse: 1.83803\tvalid_1's rmse: 496.141\n",
      "[10100]\ttraining's rmse: 1.79846\tvalid_1's rmse: 496.138\n",
      "[10200]\ttraining's rmse: 1.76305\tvalid_1's rmse: 496.133\n",
      "[10300]\ttraining's rmse: 1.73001\tvalid_1's rmse: 496.131\n",
      "[10400]\ttraining's rmse: 1.69099\tvalid_1's rmse: 496.126\n",
      "[10500]\ttraining's rmse: 1.66123\tvalid_1's rmse: 496.124\n",
      "[10600]\ttraining's rmse: 1.62972\tvalid_1's rmse: 496.123\n",
      "[10700]\ttraining's rmse: 1.59127\tvalid_1's rmse: 496.117\n",
      "[10800]\ttraining's rmse: 1.55852\tvalid_1's rmse: 496.114\n",
      "[10900]\ttraining's rmse: 1.52759\tvalid_1's rmse: 496.112\n",
      "[11000]\ttraining's rmse: 1.50077\tvalid_1's rmse: 496.105\n",
      "[11100]\ttraining's rmse: 1.46406\tvalid_1's rmse: 496.102\n",
      "[11200]\ttraining's rmse: 1.44038\tvalid_1's rmse: 496.099\n",
      "[11300]\ttraining's rmse: 1.4119\tvalid_1's rmse: 496.095\n",
      "[11400]\ttraining's rmse: 1.37923\tvalid_1's rmse: 496.09\n",
      "[11500]\ttraining's rmse: 1.34973\tvalid_1's rmse: 496.086\n",
      "[11600]\ttraining's rmse: 1.32543\tvalid_1's rmse: 496.083\n",
      "[11700]\ttraining's rmse: 1.29997\tvalid_1's rmse: 496.078\n",
      "[11800]\ttraining's rmse: 1.28002\tvalid_1's rmse: 496.075\n",
      "[11900]\ttraining's rmse: 1.26042\tvalid_1's rmse: 496.074\n",
      "[12000]\ttraining's rmse: 1.23783\tvalid_1's rmse: 496.07\n",
      "[12100]\ttraining's rmse: 1.21978\tvalid_1's rmse: 496.068\n",
      "[12200]\ttraining's rmse: 1.1988\tvalid_1's rmse: 496.068\n",
      "[12300]\ttraining's rmse: 1.17644\tvalid_1's rmse: 496.064\n",
      "[12400]\ttraining's rmse: 1.15633\tvalid_1's rmse: 496.061\n",
      "[12500]\ttraining's rmse: 1.13516\tvalid_1's rmse: 496.057\n",
      "[12600]\ttraining's rmse: 1.11133\tvalid_1's rmse: 496.052\n",
      "[12700]\ttraining's rmse: 1.09208\tvalid_1's rmse: 496.049\n",
      "[12800]\ttraining's rmse: 1.07458\tvalid_1's rmse: 496.049\n",
      "[12900]\ttraining's rmse: 1.05594\tvalid_1's rmse: 496.048\n",
      "[13000]\ttraining's rmse: 1.03395\tvalid_1's rmse: 496.045\n",
      "[13100]\ttraining's rmse: 1.01359\tvalid_1's rmse: 496.042\n",
      "[13200]\ttraining's rmse: 0.993492\tvalid_1's rmse: 496.041\n",
      "[13300]\ttraining's rmse: 0.973935\tvalid_1's rmse: 496.035\n",
      "[13400]\ttraining's rmse: 0.958975\tvalid_1's rmse: 496.034\n",
      "[13500]\ttraining's rmse: 0.942849\tvalid_1's rmse: 496.031\n",
      "[13600]\ttraining's rmse: 0.927423\tvalid_1's rmse: 496.031\n",
      "[13700]\ttraining's rmse: 0.912889\tvalid_1's rmse: 496.028\n",
      "[13800]\ttraining's rmse: 0.896247\tvalid_1's rmse: 496.026\n",
      "[13900]\ttraining's rmse: 0.879779\tvalid_1's rmse: 496.025\n",
      "[14000]\ttraining's rmse: 0.865529\tvalid_1's rmse: 496.022\n",
      "[14100]\ttraining's rmse: 0.849892\tvalid_1's rmse: 496.021\n",
      "[14200]\ttraining's rmse: 0.837516\tvalid_1's rmse: 496.02\n",
      "[14300]\ttraining's rmse: 0.818384\tvalid_1's rmse: 496.017\n",
      "[14400]\ttraining's rmse: 0.801418\tvalid_1's rmse: 496.016\n",
      "[14500]\ttraining's rmse: 0.787877\tvalid_1's rmse: 496.014\n",
      "[14600]\ttraining's rmse: 0.775433\tvalid_1's rmse: 496.011\n",
      "[14700]\ttraining's rmse: 0.762856\tvalid_1's rmse: 496.008\n",
      "[14800]\ttraining's rmse: 0.750865\tvalid_1's rmse: 496.007\n",
      "[14900]\ttraining's rmse: 0.73765\tvalid_1's rmse: 496.006\n",
      "[15000]\ttraining's rmse: 0.72406\tvalid_1's rmse: 496.006\n",
      "[15100]\ttraining's rmse: 0.712159\tvalid_1's rmse: 496.003\n",
      "[15200]\ttraining's rmse: 0.699842\tvalid_1's rmse: 496.001\n",
      "[15300]\ttraining's rmse: 0.689081\tvalid_1's rmse: 496\n",
      "[15400]\ttraining's rmse: 0.679017\tvalid_1's rmse: 496\n",
      "[15500]\ttraining's rmse: 0.67145\tvalid_1's rmse: 495.998\n",
      "[15600]\ttraining's rmse: 0.661193\tvalid_1's rmse: 495.998\n",
      "[15700]\ttraining's rmse: 0.648916\tvalid_1's rmse: 495.996\n",
      "[15800]\ttraining's rmse: 0.638876\tvalid_1's rmse: 495.995\n",
      "[15900]\ttraining's rmse: 0.626401\tvalid_1's rmse: 495.994\n",
      "[16000]\ttraining's rmse: 0.615408\tvalid_1's rmse: 495.993\n",
      "[16100]\ttraining's rmse: 0.604835\tvalid_1's rmse: 495.991\n",
      "[16200]\ttraining's rmse: 0.594185\tvalid_1's rmse: 495.99\n",
      "[16300]\ttraining's rmse: 0.582894\tvalid_1's rmse: 495.989\n",
      "[16400]\ttraining's rmse: 0.572398\tvalid_1's rmse: 495.987\n",
      "[16500]\ttraining's rmse: 0.561879\tvalid_1's rmse: 495.986\n",
      "[16600]\ttraining's rmse: 0.550112\tvalid_1's rmse: 495.984\n",
      "[16700]\ttraining's rmse: 0.542219\tvalid_1's rmse: 495.983\n",
      "[16800]\ttraining's rmse: 0.533121\tvalid_1's rmse: 495.981\n",
      "[16900]\ttraining's rmse: 0.52545\tvalid_1's rmse: 495.98\n",
      "[17000]\ttraining's rmse: 0.517195\tvalid_1's rmse: 495.98\n",
      "[17100]\ttraining's rmse: 0.508677\tvalid_1's rmse: 495.979\n",
      "[17200]\ttraining's rmse: 0.500258\tvalid_1's rmse: 495.979\n",
      "[17300]\ttraining's rmse: 0.490811\tvalid_1's rmse: 495.977\n",
      "[17400]\ttraining's rmse: 0.482021\tvalid_1's rmse: 495.976\n",
      "[17500]\ttraining's rmse: 0.475408\tvalid_1's rmse: 495.975\n",
      "[17600]\ttraining's rmse: 0.465182\tvalid_1's rmse: 495.974\n",
      "[17700]\ttraining's rmse: 0.459807\tvalid_1's rmse: 495.973\n",
      "[17800]\ttraining's rmse: 0.452905\tvalid_1's rmse: 495.972\n",
      "[17900]\ttraining's rmse: 0.444794\tvalid_1's rmse: 495.971\n",
      "[18000]\ttraining's rmse: 0.436074\tvalid_1's rmse: 495.969\n",
      "[18100]\ttraining's rmse: 0.429072\tvalid_1's rmse: 495.969\n",
      "[18200]\ttraining's rmse: 0.422325\tvalid_1's rmse: 495.967\n",
      "[18300]\ttraining's rmse: 0.415587\tvalid_1's rmse: 495.966\n",
      "[18400]\ttraining's rmse: 0.409507\tvalid_1's rmse: 495.966\n",
      "[18500]\ttraining's rmse: 0.403536\tvalid_1's rmse: 495.966\n",
      "[18600]\ttraining's rmse: 0.398543\tvalid_1's rmse: 495.964\n",
      "[18700]\ttraining's rmse: 0.393191\tvalid_1's rmse: 495.963\n",
      "[18800]\ttraining's rmse: 0.388262\tvalid_1's rmse: 495.962\n",
      "[18900]\ttraining's rmse: 0.382153\tvalid_1's rmse: 495.961\n",
      "[19000]\ttraining's rmse: 0.3761\tvalid_1's rmse: 495.959\n",
      "[19100]\ttraining's rmse: 0.370051\tvalid_1's rmse: 495.959\n",
      "[19200]\ttraining's rmse: 0.363693\tvalid_1's rmse: 495.959\n",
      "[19300]\ttraining's rmse: 0.358419\tvalid_1's rmse: 495.958\n",
      "[19400]\ttraining's rmse: 0.353416\tvalid_1's rmse: 495.957\n",
      "[19500]\ttraining's rmse: 0.348214\tvalid_1's rmse: 495.957\n",
      "[19600]\ttraining's rmse: 0.342618\tvalid_1's rmse: 495.956\n",
      "[19700]\ttraining's rmse: 0.336436\tvalid_1's rmse: 495.956\n",
      "[19800]\ttraining's rmse: 0.330534\tvalid_1's rmse: 495.955\n",
      "[19900]\ttraining's rmse: 0.324466\tvalid_1's rmse: 495.954\n",
      "[20000]\ttraining's rmse: 0.320352\tvalid_1's rmse: 495.953\n",
      "[20100]\ttraining's rmse: 0.315453\tvalid_1's rmse: 495.952\n",
      "[20200]\ttraining's rmse: 0.309342\tvalid_1's rmse: 495.952\n",
      "[20300]\ttraining's rmse: 0.303409\tvalid_1's rmse: 495.952\n",
      "[20400]\ttraining's rmse: 0.297759\tvalid_1's rmse: 495.951\n",
      "[20500]\ttraining's rmse: 0.292778\tvalid_1's rmse: 495.95\n",
      "[20600]\ttraining's rmse: 0.289106\tvalid_1's rmse: 495.95\n",
      "[20700]\ttraining's rmse: 0.285996\tvalid_1's rmse: 495.949\n",
      "[20800]\ttraining's rmse: 0.282124\tvalid_1's rmse: 495.949\n",
      "[20900]\ttraining's rmse: 0.27825\tvalid_1's rmse: 495.949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21000]\ttraining's rmse: 0.273771\tvalid_1's rmse: 495.948\n",
      "[21100]\ttraining's rmse: 0.268527\tvalid_1's rmse: 495.947\n",
      "[21200]\ttraining's rmse: 0.263959\tvalid_1's rmse: 495.946\n",
      "[21300]\ttraining's rmse: 0.259872\tvalid_1's rmse: 495.945\n",
      "[21400]\ttraining's rmse: 0.256145\tvalid_1's rmse: 495.945\n",
      "[21500]\ttraining's rmse: 0.252558\tvalid_1's rmse: 495.945\n",
      "[21600]\ttraining's rmse: 0.248419\tvalid_1's rmse: 495.944\n",
      "[21700]\ttraining's rmse: 0.244377\tvalid_1's rmse: 495.943\n",
      "[21800]\ttraining's rmse: 0.240749\tvalid_1's rmse: 495.943\n",
      "[21900]\ttraining's rmse: 0.237833\tvalid_1's rmse: 495.942\n",
      "[22000]\ttraining's rmse: 0.234809\tvalid_1's rmse: 495.942\n",
      "[22100]\ttraining's rmse: 0.230827\tvalid_1's rmse: 495.941\n",
      "[22200]\ttraining's rmse: 0.227836\tvalid_1's rmse: 495.941\n",
      "[22300]\ttraining's rmse: 0.225207\tvalid_1's rmse: 495.94\n",
      "[22400]\ttraining's rmse: 0.221539\tvalid_1's rmse: 495.94\n",
      "[22500]\ttraining's rmse: 0.219006\tvalid_1's rmse: 495.94\n",
      "[22600]\ttraining's rmse: 0.215621\tvalid_1's rmse: 495.939\n",
      "[22700]\ttraining's rmse: 0.212751\tvalid_1's rmse: 495.938\n",
      "[22800]\ttraining's rmse: 0.209626\tvalid_1's rmse: 495.938\n",
      "[22900]\ttraining's rmse: 0.207279\tvalid_1's rmse: 495.938\n",
      "[23000]\ttraining's rmse: 0.204353\tvalid_1's rmse: 495.937\n",
      "[23100]\ttraining's rmse: 0.201483\tvalid_1's rmse: 495.937\n",
      "[23200]\ttraining's rmse: 0.198432\tvalid_1's rmse: 495.936\n",
      "[23300]\ttraining's rmse: 0.194879\tvalid_1's rmse: 495.935\n",
      "[23400]\ttraining's rmse: 0.191775\tvalid_1's rmse: 495.935\n",
      "[23500]\ttraining's rmse: 0.189649\tvalid_1's rmse: 495.934\n",
      "[23600]\ttraining's rmse: 0.187596\tvalid_1's rmse: 495.934\n",
      "[23700]\ttraining's rmse: 0.18501\tvalid_1's rmse: 495.934\n",
      "[23800]\ttraining's rmse: 0.181934\tvalid_1's rmse: 495.933\n",
      "[23900]\ttraining's rmse: 0.179\tvalid_1's rmse: 495.933\n",
      "[24000]\ttraining's rmse: 0.175927\tvalid_1's rmse: 495.932\n",
      "[24100]\ttraining's rmse: 0.173177\tvalid_1's rmse: 495.932\n",
      "[24200]\ttraining's rmse: 0.170901\tvalid_1's rmse: 495.931\n",
      "[24300]\ttraining's rmse: 0.168612\tvalid_1's rmse: 495.931\n",
      "[24400]\ttraining's rmse: 0.166659\tvalid_1's rmse: 495.931\n",
      "[24500]\ttraining's rmse: 0.164346\tvalid_1's rmse: 495.93\n",
      "[24600]\ttraining's rmse: 0.161641\tvalid_1's rmse: 495.93\n",
      "[24700]\ttraining's rmse: 0.159575\tvalid_1's rmse: 495.93\n",
      "[24800]\ttraining's rmse: 0.157108\tvalid_1's rmse: 495.929\n",
      "[24900]\ttraining's rmse: 0.155227\tvalid_1's rmse: 495.929\n",
      "[25000]\ttraining's rmse: 0.153299\tvalid_1's rmse: 495.928\n",
      "[25100]\ttraining's rmse: 0.15052\tvalid_1's rmse: 495.928\n",
      "[25200]\ttraining's rmse: 0.148335\tvalid_1's rmse: 495.927\n",
      "[25300]\ttraining's rmse: 0.146105\tvalid_1's rmse: 495.927\n",
      "[25400]\ttraining's rmse: 0.144331\tvalid_1's rmse: 495.927\n",
      "[25500]\ttraining's rmse: 0.142063\tvalid_1's rmse: 495.926\n",
      "[25600]\ttraining's rmse: 0.140302\tvalid_1's rmse: 495.926\n",
      "[25700]\ttraining's rmse: 0.13891\tvalid_1's rmse: 495.926\n",
      "[25800]\ttraining's rmse: 0.13665\tvalid_1's rmse: 495.926\n",
      "[25900]\ttraining's rmse: 0.134324\tvalid_1's rmse: 495.925\n",
      "[26000]\ttraining's rmse: 0.132461\tvalid_1's rmse: 495.925\n",
      "[26100]\ttraining's rmse: 0.13057\tvalid_1's rmse: 495.924\n",
      "[26200]\ttraining's rmse: 0.128354\tvalid_1's rmse: 495.924\n",
      "[26300]\ttraining's rmse: 0.125975\tvalid_1's rmse: 495.924\n",
      "[26400]\ttraining's rmse: 0.12408\tvalid_1's rmse: 495.924\n",
      "[26500]\ttraining's rmse: 0.122519\tvalid_1's rmse: 495.923\n",
      "[26600]\ttraining's rmse: 0.120871\tvalid_1's rmse: 495.923\n",
      "[26700]\ttraining's rmse: 0.119252\tvalid_1's rmse: 495.923\n",
      "[26800]\ttraining's rmse: 0.117223\tvalid_1's rmse: 495.923\n",
      "[26900]\ttraining's rmse: 0.115576\tvalid_1's rmse: 495.922\n",
      "[27000]\ttraining's rmse: 0.113968\tvalid_1's rmse: 495.922\n",
      "[27100]\ttraining's rmse: 0.112775\tvalid_1's rmse: 495.922\n",
      "[27200]\ttraining's rmse: 0.111336\tvalid_1's rmse: 495.922\n",
      "[27300]\ttraining's rmse: 0.110113\tvalid_1's rmse: 495.922\n",
      "[27400]\ttraining's rmse: 0.108376\tvalid_1's rmse: 495.922\n",
      "[27500]\ttraining's rmse: 0.107088\tvalid_1's rmse: 495.921\n",
      "[27600]\ttraining's rmse: 0.105006\tvalid_1's rmse: 495.921\n",
      "[27700]\ttraining's rmse: 0.103376\tvalid_1's rmse: 495.921\n",
      "[27800]\ttraining's rmse: 0.102514\tvalid_1's rmse: 495.921\n",
      "[27900]\ttraining's rmse: 0.101018\tvalid_1's rmse: 495.921\n",
      "[28000]\ttraining's rmse: 0.100294\tvalid_1's rmse: 495.92\n",
      "[28100]\ttraining's rmse: 0.098714\tvalid_1's rmse: 495.92\n",
      "[28200]\ttraining's rmse: 0.0973457\tvalid_1's rmse: 495.92\n",
      "[28300]\ttraining's rmse: 0.0957913\tvalid_1's rmse: 495.92\n",
      "[28400]\ttraining's rmse: 0.0945831\tvalid_1's rmse: 495.919\n",
      "[28500]\ttraining's rmse: 0.0929842\tvalid_1's rmse: 495.919\n",
      "[28600]\ttraining's rmse: 0.0918074\tvalid_1's rmse: 495.919\n",
      "[28700]\ttraining's rmse: 0.0906784\tvalid_1's rmse: 495.919\n",
      "[28800]\ttraining's rmse: 0.0893165\tvalid_1's rmse: 495.919\n",
      "[28900]\ttraining's rmse: 0.0882474\tvalid_1's rmse: 495.919\n",
      "[29000]\ttraining's rmse: 0.0872532\tvalid_1's rmse: 495.919\n",
      "[29100]\ttraining's rmse: 0.0861083\tvalid_1's rmse: 495.919\n",
      "[29200]\ttraining's rmse: 0.0849684\tvalid_1's rmse: 495.918\n",
      "[29300]\ttraining's rmse: 0.0839298\tvalid_1's rmse: 495.918\n",
      "[29400]\ttraining's rmse: 0.0825299\tvalid_1's rmse: 495.918\n",
      "[29500]\ttraining's rmse: 0.0811207\tvalid_1's rmse: 495.918\n",
      "[29600]\ttraining's rmse: 0.0800357\tvalid_1's rmse: 495.918\n",
      "[29700]\ttraining's rmse: 0.0789305\tvalid_1's rmse: 495.917\n",
      "[29800]\ttraining's rmse: 0.0781847\tvalid_1's rmse: 495.917\n",
      "[29900]\ttraining's rmse: 0.0772145\tvalid_1's rmse: 495.917\n",
      "[30000]\ttraining's rmse: 0.0761412\tvalid_1's rmse: 495.917\n",
      "[30100]\ttraining's rmse: 0.0748702\tvalid_1's rmse: 495.917\n",
      "[30200]\ttraining's rmse: 0.073733\tvalid_1's rmse: 495.916\n",
      "[30300]\ttraining's rmse: 0.0729241\tvalid_1's rmse: 495.916\n",
      "[30400]\ttraining's rmse: 0.0723053\tvalid_1's rmse: 495.916\n",
      "[30500]\ttraining's rmse: 0.0713592\tvalid_1's rmse: 495.916\n",
      "[30600]\ttraining's rmse: 0.0704489\tvalid_1's rmse: 495.916\n",
      "[30700]\ttraining's rmse: 0.0692249\tvalid_1's rmse: 495.916\n",
      "[30800]\ttraining's rmse: 0.068519\tvalid_1's rmse: 495.916\n",
      "[30900]\ttraining's rmse: 0.0675499\tvalid_1's rmse: 495.915\n",
      "[31000]\ttraining's rmse: 0.0666841\tvalid_1's rmse: 495.915\n",
      "[31100]\ttraining's rmse: 0.065982\tvalid_1's rmse: 495.915\n",
      "[31200]\ttraining's rmse: 0.0649031\tvalid_1's rmse: 495.915\n",
      "[31300]\ttraining's rmse: 0.064108\tvalid_1's rmse: 495.915\n",
      "[31400]\ttraining's rmse: 0.0635895\tvalid_1's rmse: 495.915\n",
      "[31500]\ttraining's rmse: 0.0626721\tvalid_1's rmse: 495.915\n",
      "[31600]\ttraining's rmse: 0.0617404\tvalid_1's rmse: 495.915\n",
      "[31700]\ttraining's rmse: 0.0609845\tvalid_1's rmse: 495.914\n",
      "[31800]\ttraining's rmse: 0.0602466\tvalid_1's rmse: 495.914\n",
      "[31900]\ttraining's rmse: 0.0594952\tvalid_1's rmse: 495.914\n",
      "[32000]\ttraining's rmse: 0.0585336\tvalid_1's rmse: 495.914\n",
      "[32100]\ttraining's rmse: 0.0578077\tvalid_1's rmse: 495.914\n",
      "[32200]\ttraining's rmse: 0.056966\tvalid_1's rmse: 495.914\n",
      "[32300]\ttraining's rmse: 0.0561567\tvalid_1's rmse: 495.914\n",
      "[32400]\ttraining's rmse: 0.0553281\tvalid_1's rmse: 495.914\n",
      "[32500]\ttraining's rmse: 0.0545553\tvalid_1's rmse: 495.913\n",
      "[32600]\ttraining's rmse: 0.0538666\tvalid_1's rmse: 495.913\n",
      "[32700]\ttraining's rmse: 0.0531038\tvalid_1's rmse: 495.913\n",
      "[32800]\ttraining's rmse: 0.052435\tvalid_1's rmse: 495.913\n",
      "[32900]\ttraining's rmse: 0.0516706\tvalid_1's rmse: 495.913\n",
      "[33000]\ttraining's rmse: 0.0511098\tvalid_1's rmse: 495.913\n",
      "[33100]\ttraining's rmse: 0.0501611\tvalid_1's rmse: 495.913\n",
      "[33200]\ttraining's rmse: 0.0496262\tvalid_1's rmse: 495.913\n",
      "[33300]\ttraining's rmse: 0.0489225\tvalid_1's rmse: 495.913\n",
      "[33400]\ttraining's rmse: 0.0481352\tvalid_1's rmse: 495.913\n",
      "[33500]\ttraining's rmse: 0.0474262\tvalid_1's rmse: 495.913\n",
      "[33600]\ttraining's rmse: 0.0469438\tvalid_1's rmse: 495.913\n",
      "[33700]\ttraining's rmse: 0.0461823\tvalid_1's rmse: 495.913\n",
      "[33800]\ttraining's rmse: 0.0456208\tvalid_1's rmse: 495.913\n",
      "[33900]\ttraining's rmse: 0.0449388\tvalid_1's rmse: 495.913\n",
      "[34000]\ttraining's rmse: 0.044446\tvalid_1's rmse: 495.913\n",
      "[34100]\ttraining's rmse: 0.043851\tvalid_1's rmse: 495.913\n",
      "[34200]\ttraining's rmse: 0.0434433\tvalid_1's rmse: 495.913\n",
      "[34300]\ttraining's rmse: 0.0428462\tvalid_1's rmse: 495.913\n",
      "[34400]\ttraining's rmse: 0.0422107\tvalid_1's rmse: 495.912\n",
      "[34500]\ttraining's rmse: 0.0416954\tvalid_1's rmse: 495.912\n",
      "[34600]\ttraining's rmse: 0.041103\tvalid_1's rmse: 495.912\n",
      "[34700]\ttraining's rmse: 0.0405313\tvalid_1's rmse: 495.912\n",
      "[34800]\ttraining's rmse: 0.0399989\tvalid_1's rmse: 495.912\n",
      "[34900]\ttraining's rmse: 0.0393171\tvalid_1's rmse: 495.912\n",
      "[35000]\ttraining's rmse: 0.0387335\tvalid_1's rmse: 495.912\n",
      "[35100]\ttraining's rmse: 0.0381891\tvalid_1's rmse: 495.912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35200]\ttraining's rmse: 0.0377035\tvalid_1's rmse: 495.912\n",
      "[35300]\ttraining's rmse: 0.0372037\tvalid_1's rmse: 495.912\n",
      "[35400]\ttraining's rmse: 0.0366386\tvalid_1's rmse: 495.912\n",
      "[35500]\ttraining's rmse: 0.0360988\tvalid_1's rmse: 495.912\n",
      "[35600]\ttraining's rmse: 0.0355105\tvalid_1's rmse: 495.912\n",
      "[35700]\ttraining's rmse: 0.0350209\tvalid_1's rmse: 495.912\n",
      "[35800]\ttraining's rmse: 0.0346249\tvalid_1's rmse: 495.912\n",
      "[35900]\ttraining's rmse: 0.0341538\tvalid_1's rmse: 495.912\n",
      "[36000]\ttraining's rmse: 0.0337258\tvalid_1's rmse: 495.912\n",
      "[36100]\ttraining's rmse: 0.0334276\tvalid_1's rmse: 495.912\n",
      "[36200]\ttraining's rmse: 0.0330868\tvalid_1's rmse: 495.912\n",
      "[36300]\ttraining's rmse: 0.0325539\tvalid_1's rmse: 495.912\n",
      "[36400]\ttraining's rmse: 0.0320964\tvalid_1's rmse: 495.912\n",
      "[36500]\ttraining's rmse: 0.0316972\tvalid_1's rmse: 495.912\n",
      "[36600]\ttraining's rmse: 0.0313059\tvalid_1's rmse: 495.912\n",
      "[36700]\ttraining's rmse: 0.0307503\tvalid_1's rmse: 495.912\n",
      "[36800]\ttraining's rmse: 0.0303447\tvalid_1's rmse: 495.912\n",
      "[36900]\ttraining's rmse: 0.0297908\tvalid_1's rmse: 495.912\n",
      "[37000]\ttraining's rmse: 0.0293593\tvalid_1's rmse: 495.912\n",
      "[37100]\ttraining's rmse: 0.0290106\tvalid_1's rmse: 495.912\n",
      "[37200]\ttraining's rmse: 0.0286312\tvalid_1's rmse: 495.912\n",
      "[37300]\ttraining's rmse: 0.0282996\tvalid_1's rmse: 495.912\n",
      "[37400]\ttraining's rmse: 0.0278849\tvalid_1's rmse: 495.911\n",
      "[37500]\ttraining's rmse: 0.0275426\tvalid_1's rmse: 495.911\n",
      "[37600]\ttraining's rmse: 0.0272207\tvalid_1's rmse: 495.911\n",
      "[37700]\ttraining's rmse: 0.0269421\tvalid_1's rmse: 495.911\n",
      "[37800]\ttraining's rmse: 0.0266607\tvalid_1's rmse: 495.911\n",
      "[37900]\ttraining's rmse: 0.0264254\tvalid_1's rmse: 495.911\n",
      "[38000]\ttraining's rmse: 0.0260332\tvalid_1's rmse: 495.911\n",
      "[38100]\ttraining's rmse: 0.0256805\tvalid_1's rmse: 495.911\n",
      "[38200]\ttraining's rmse: 0.0253964\tvalid_1's rmse: 495.911\n",
      "[38300]\ttraining's rmse: 0.0250594\tvalid_1's rmse: 495.911\n",
      "[38400]\ttraining's rmse: 0.0246055\tvalid_1's rmse: 495.911\n",
      "[38500]\ttraining's rmse: 0.0242934\tvalid_1's rmse: 495.911\n",
      "[38600]\ttraining's rmse: 0.0240068\tvalid_1's rmse: 495.911\n",
      "[38700]\ttraining's rmse: 0.0236776\tvalid_1's rmse: 495.911\n",
      "[38800]\ttraining's rmse: 0.0233681\tvalid_1's rmse: 495.911\n",
      "[38900]\ttraining's rmse: 0.0230468\tvalid_1's rmse: 495.911\n",
      "[39000]\ttraining's rmse: 0.0227299\tvalid_1's rmse: 495.911\n",
      "[39100]\ttraining's rmse: 0.0224568\tvalid_1's rmse: 495.911\n",
      "[39200]\ttraining's rmse: 0.0221468\tvalid_1's rmse: 495.911\n",
      "[39300]\ttraining's rmse: 0.0218321\tvalid_1's rmse: 495.911\n",
      "[39400]\ttraining's rmse: 0.021545\tvalid_1's rmse: 495.911\n",
      "[39500]\ttraining's rmse: 0.0212968\tvalid_1's rmse: 495.911\n",
      "[39600]\ttraining's rmse: 0.0210182\tvalid_1's rmse: 495.911\n",
      "[39700]\ttraining's rmse: 0.0207225\tvalid_1's rmse: 495.911\n",
      "[39800]\ttraining's rmse: 0.0205103\tvalid_1's rmse: 495.911\n",
      "[39900]\ttraining's rmse: 0.020228\tvalid_1's rmse: 495.911\n",
      "[40000]\ttraining's rmse: 0.0199639\tvalid_1's rmse: 495.911\n",
      "[40100]\ttraining's rmse: 0.019671\tvalid_1's rmse: 495.911\n",
      "[40200]\ttraining's rmse: 0.0193578\tvalid_1's rmse: 495.911\n",
      "[40300]\ttraining's rmse: 0.0191387\tvalid_1's rmse: 495.911\n",
      "[40400]\ttraining's rmse: 0.0189419\tvalid_1's rmse: 495.911\n",
      "[40500]\ttraining's rmse: 0.0186745\tvalid_1's rmse: 495.911\n",
      "[40600]\ttraining's rmse: 0.0183878\tvalid_1's rmse: 495.911\n",
      "[40700]\ttraining's rmse: 0.0181863\tvalid_1's rmse: 495.911\n",
      "[40800]\ttraining's rmse: 0.0178908\tvalid_1's rmse: 495.911\n",
      "[40900]\ttraining's rmse: 0.0176421\tvalid_1's rmse: 495.911\n",
      "[41000]\ttraining's rmse: 0.0174546\tvalid_1's rmse: 495.911\n",
      "[41100]\ttraining's rmse: 0.0172619\tvalid_1's rmse: 495.911\n",
      "[41200]\ttraining's rmse: 0.017065\tvalid_1's rmse: 495.911\n",
      "[41300]\ttraining's rmse: 0.0169062\tvalid_1's rmse: 495.911\n",
      "[41400]\ttraining's rmse: 0.0167325\tvalid_1's rmse: 495.911\n",
      "[41500]\ttraining's rmse: 0.0165217\tvalid_1's rmse: 495.911\n",
      "[41600]\ttraining's rmse: 0.0163112\tvalid_1's rmse: 495.911\n",
      "[41700]\ttraining's rmse: 0.0160957\tvalid_1's rmse: 495.911\n",
      "[41800]\ttraining's rmse: 0.0158322\tvalid_1's rmse: 495.91\n",
      "[41900]\ttraining's rmse: 0.0156791\tvalid_1's rmse: 495.91\n",
      "[42000]\ttraining's rmse: 0.0154709\tvalid_1's rmse: 495.91\n",
      "[42100]\ttraining's rmse: 0.0152185\tvalid_1's rmse: 495.91\n",
      "[42200]\ttraining's rmse: 0.0150821\tvalid_1's rmse: 495.91\n",
      "[42300]\ttraining's rmse: 0.0148538\tvalid_1's rmse: 495.91\n",
      "[42400]\ttraining's rmse: 0.0146669\tvalid_1's rmse: 495.91\n",
      "[42500]\ttraining's rmse: 0.0144504\tvalid_1's rmse: 495.91\n",
      "[42600]\ttraining's rmse: 0.014309\tvalid_1's rmse: 495.91\n",
      "[42700]\ttraining's rmse: 0.0141611\tvalid_1's rmse: 495.91\n",
      "[42800]\ttraining's rmse: 0.013947\tvalid_1's rmse: 495.91\n",
      "[42900]\ttraining's rmse: 0.0138321\tvalid_1's rmse: 495.91\n",
      "[43000]\ttraining's rmse: 0.0136602\tvalid_1's rmse: 495.91\n",
      "[43100]\ttraining's rmse: 0.0134887\tvalid_1's rmse: 495.91\n",
      "[43200]\ttraining's rmse: 0.0133104\tvalid_1's rmse: 495.91\n",
      "[43300]\ttraining's rmse: 0.0131053\tvalid_1's rmse: 495.91\n",
      "[43400]\ttraining's rmse: 0.0129142\tvalid_1's rmse: 495.91\n",
      "[43500]\ttraining's rmse: 0.0127546\tvalid_1's rmse: 495.91\n",
      "[43600]\ttraining's rmse: 0.0126036\tvalid_1's rmse: 495.91\n",
      "[43700]\ttraining's rmse: 0.0124784\tvalid_1's rmse: 495.91\n",
      "[43800]\ttraining's rmse: 0.0123521\tvalid_1's rmse: 495.91\n",
      "[43900]\ttraining's rmse: 0.0122002\tvalid_1's rmse: 495.91\n",
      "[44000]\ttraining's rmse: 0.0119874\tvalid_1's rmse: 495.91\n",
      "[44100]\ttraining's rmse: 0.0118276\tvalid_1's rmse: 495.91\n",
      "[44200]\ttraining's rmse: 0.0116902\tvalid_1's rmse: 495.91\n",
      "[44300]\ttraining's rmse: 0.0115198\tvalid_1's rmse: 495.91\n",
      "[44400]\ttraining's rmse: 0.0113887\tvalid_1's rmse: 495.91\n",
      "[44500]\ttraining's rmse: 0.0112581\tvalid_1's rmse: 495.91\n",
      "[44600]\ttraining's rmse: 0.0111265\tvalid_1's rmse: 495.91\n",
      "[44700]\ttraining's rmse: 0.0109969\tvalid_1's rmse: 495.91\n",
      "[44800]\ttraining's rmse: 0.0108272\tvalid_1's rmse: 495.91\n",
      "[44900]\ttraining's rmse: 0.0107006\tvalid_1's rmse: 495.91\n",
      "[45000]\ttraining's rmse: 0.0105744\tvalid_1's rmse: 495.91\n",
      "[45100]\ttraining's rmse: 0.0104407\tvalid_1's rmse: 495.91\n",
      "[45200]\ttraining's rmse: 0.0103023\tvalid_1's rmse: 495.91\n",
      "[45300]\ttraining's rmse: 0.0101714\tvalid_1's rmse: 495.91\n",
      "[45400]\ttraining's rmse: 0.010039\tvalid_1's rmse: 495.91\n",
      "[45500]\ttraining's rmse: 0.00991702\tvalid_1's rmse: 495.91\n",
      "[45600]\ttraining's rmse: 0.00979397\tvalid_1's rmse: 495.91\n",
      "[45700]\ttraining's rmse: 0.00969818\tvalid_1's rmse: 495.91\n",
      "[45800]\ttraining's rmse: 0.0095435\tvalid_1's rmse: 495.91\n",
      "[45900]\ttraining's rmse: 0.00938759\tvalid_1's rmse: 495.91\n",
      "[46000]\ttraining's rmse: 0.00926947\tvalid_1's rmse: 495.91\n",
      "[46100]\ttraining's rmse: 0.00911418\tvalid_1's rmse: 495.91\n",
      "[46200]\ttraining's rmse: 0.00902748\tvalid_1's rmse: 495.91\n",
      "[46300]\ttraining's rmse: 0.00890355\tvalid_1's rmse: 495.91\n",
      "[46400]\ttraining's rmse: 0.00877568\tvalid_1's rmse: 495.91\n",
      "[46500]\ttraining's rmse: 0.00862365\tvalid_1's rmse: 495.91\n",
      "[46600]\ttraining's rmse: 0.00849569\tvalid_1's rmse: 495.91\n",
      "[46700]\ttraining's rmse: 0.00837439\tvalid_1's rmse: 495.91\n",
      "[46800]\ttraining's rmse: 0.00824768\tvalid_1's rmse: 495.91\n",
      "[46900]\ttraining's rmse: 0.00811295\tvalid_1's rmse: 495.91\n",
      "[47000]\ttraining's rmse: 0.00803179\tvalid_1's rmse: 495.91\n",
      "[47100]\ttraining's rmse: 0.00791706\tvalid_1's rmse: 495.91\n",
      "[47200]\ttraining's rmse: 0.00781674\tvalid_1's rmse: 495.91\n",
      "[47300]\ttraining's rmse: 0.00770639\tvalid_1's rmse: 495.91\n",
      "[47400]\ttraining's rmse: 0.00761336\tvalid_1's rmse: 495.91\n",
      "[47500]\ttraining's rmse: 0.0075022\tvalid_1's rmse: 495.91\n",
      "[47600]\ttraining's rmse: 0.00741503\tvalid_1's rmse: 495.91\n",
      "[47700]\ttraining's rmse: 0.00733879\tvalid_1's rmse: 495.91\n",
      "[47800]\ttraining's rmse: 0.00727749\tvalid_1's rmse: 495.91\n",
      "[47900]\ttraining's rmse: 0.00718985\tvalid_1's rmse: 495.91\n",
      "[48000]\ttraining's rmse: 0.00708322\tvalid_1's rmse: 495.91\n",
      "[48100]\ttraining's rmse: 0.00699646\tvalid_1's rmse: 495.91\n",
      "[48200]\ttraining's rmse: 0.00691375\tvalid_1's rmse: 495.91\n",
      "[48300]\ttraining's rmse: 0.00684166\tvalid_1's rmse: 495.91\n",
      "[48400]\ttraining's rmse: 0.00674098\tvalid_1's rmse: 495.91\n",
      "[48500]\ttraining's rmse: 0.00665224\tvalid_1's rmse: 495.91\n",
      "[48600]\ttraining's rmse: 0.00657232\tvalid_1's rmse: 495.91\n",
      "[48700]\ttraining's rmse: 0.00649432\tvalid_1's rmse: 495.91\n",
      "[48800]\ttraining's rmse: 0.0064235\tvalid_1's rmse: 495.91\n",
      "[48900]\ttraining's rmse: 0.00635504\tvalid_1's rmse: 495.91\n",
      "[49000]\ttraining's rmse: 0.00626796\tvalid_1's rmse: 495.91\n",
      "[49100]\ttraining's rmse: 0.00619264\tvalid_1's rmse: 495.91\n",
      "[49200]\ttraining's rmse: 0.00610169\tvalid_1's rmse: 495.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49300]\ttraining's rmse: 0.00602934\tvalid_1's rmse: 495.91\n",
      "[49400]\ttraining's rmse: 0.00594432\tvalid_1's rmse: 495.91\n",
      "[49500]\ttraining's rmse: 0.00585775\tvalid_1's rmse: 495.91\n",
      "[49600]\ttraining's rmse: 0.00577921\tvalid_1's rmse: 495.91\n",
      "[49700]\ttraining's rmse: 0.00572203\tvalid_1's rmse: 495.91\n",
      "[49800]\ttraining's rmse: 0.0056337\tvalid_1's rmse: 495.91\n",
      "[49900]\ttraining's rmse: 0.00557523\tvalid_1's rmse: 495.91\n",
      "[50000]\ttraining's rmse: 0.00549941\tvalid_1's rmse: 495.91\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50000]\ttraining's rmse: 0.00549941\tvalid_1's rmse: 495.91\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\ttraining's rmse: 534.033\tvalid_1's rmse: 785.954\n",
      "[200]\ttraining's rmse: 331.318\tvalid_1's rmse: 626.906\n",
      "[300]\ttraining's rmse: 248.734\tvalid_1's rmse: 579.736\n",
      "[400]\ttraining's rmse: 202.064\tvalid_1's rmse: 557.333\n",
      "[500]\ttraining's rmse: 170.457\tvalid_1's rmse: 547.302\n",
      "[600]\ttraining's rmse: 147.766\tvalid_1's rmse: 540.134\n",
      "[700]\ttraining's rmse: 129.253\tvalid_1's rmse: 534.329\n",
      "[800]\ttraining's rmse: 114.965\tvalid_1's rmse: 530.047\n",
      "[900]\ttraining's rmse: 103.226\tvalid_1's rmse: 527.529\n",
      "[1000]\ttraining's rmse: 93.4357\tvalid_1's rmse: 525.241\n",
      "[1100]\ttraining's rmse: 84.9968\tvalid_1's rmse: 523.915\n",
      "[1200]\ttraining's rmse: 77.5483\tvalid_1's rmse: 522.462\n",
      "[1300]\ttraining's rmse: 71.1322\tvalid_1's rmse: 521.012\n",
      "[1400]\ttraining's rmse: 65.411\tvalid_1's rmse: 520.389\n",
      "[1500]\ttraining's rmse: 60.3829\tvalid_1's rmse: 519.847\n",
      "[1600]\ttraining's rmse: 55.9738\tvalid_1's rmse: 519.266\n",
      "[1700]\ttraining's rmse: 51.6051\tvalid_1's rmse: 518.595\n",
      "[1800]\ttraining's rmse: 47.9622\tvalid_1's rmse: 518.04\n",
      "[1900]\ttraining's rmse: 44.7186\tvalid_1's rmse: 517.538\n",
      "[2000]\ttraining's rmse: 41.6453\tvalid_1's rmse: 517.179\n",
      "[2100]\ttraining's rmse: 38.8967\tvalid_1's rmse: 517.151\n",
      "[2200]\ttraining's rmse: 36.4083\tvalid_1's rmse: 516.887\n",
      "[2300]\ttraining's rmse: 34.0535\tvalid_1's rmse: 516.76\n",
      "[2400]\ttraining's rmse: 31.8997\tvalid_1's rmse: 516.78\n",
      "[2500]\ttraining's rmse: 29.9148\tvalid_1's rmse: 516.529\n",
      "[2600]\ttraining's rmse: 27.9964\tvalid_1's rmse: 516.394\n",
      "[2700]\ttraining's rmse: 26.3487\tvalid_1's rmse: 516.171\n",
      "[2800]\ttraining's rmse: 24.7819\tvalid_1's rmse: 516.111\n",
      "[2900]\ttraining's rmse: 23.3482\tvalid_1's rmse: 515.914\n",
      "[3000]\ttraining's rmse: 22.0084\tvalid_1's rmse: 515.91\n",
      "[3100]\ttraining's rmse: 20.7286\tvalid_1's rmse: 515.753\n",
      "[3200]\ttraining's rmse: 19.5952\tvalid_1's rmse: 515.724\n",
      "[3300]\ttraining's rmse: 18.4809\tvalid_1's rmse: 515.693\n",
      "[3400]\ttraining's rmse: 17.4891\tvalid_1's rmse: 515.679\n",
      "[3500]\ttraining's rmse: 16.5135\tvalid_1's rmse: 515.612\n",
      "[3600]\ttraining's rmse: 15.5828\tvalid_1's rmse: 515.569\n",
      "[3700]\ttraining's rmse: 14.6496\tvalid_1's rmse: 515.452\n",
      "[3800]\ttraining's rmse: 13.8459\tvalid_1's rmse: 515.391\n",
      "[3900]\ttraining's rmse: 13.1195\tvalid_1's rmse: 515.395\n",
      "[4000]\ttraining's rmse: 12.4237\tvalid_1's rmse: 515.39\n",
      "[4100]\ttraining's rmse: 11.7656\tvalid_1's rmse: 515.343\n",
      "[4200]\ttraining's rmse: 11.1612\tvalid_1's rmse: 515.335\n",
      "[4300]\ttraining's rmse: 10.6018\tvalid_1's rmse: 515.308\n",
      "[4400]\ttraining's rmse: 10.0564\tvalid_1's rmse: 515.258\n",
      "[4500]\ttraining's rmse: 9.54103\tvalid_1's rmse: 515.24\n",
      "[4600]\ttraining's rmse: 9.08536\tvalid_1's rmse: 515.224\n",
      "[4700]\ttraining's rmse: 8.61616\tvalid_1's rmse: 515.21\n",
      "[4800]\ttraining's rmse: 8.20052\tvalid_1's rmse: 515.166\n",
      "[4900]\ttraining's rmse: 7.82547\tvalid_1's rmse: 515.157\n",
      "[5000]\ttraining's rmse: 7.44597\tvalid_1's rmse: 515.115\n",
      "[5100]\ttraining's rmse: 7.10069\tvalid_1's rmse: 515.085\n",
      "[5200]\ttraining's rmse: 6.79507\tvalid_1's rmse: 515.072\n",
      "[5300]\ttraining's rmse: 6.48028\tvalid_1's rmse: 515.061\n",
      "[5400]\ttraining's rmse: 6.18373\tvalid_1's rmse: 515.015\n",
      "[5500]\ttraining's rmse: 5.89787\tvalid_1's rmse: 515.021\n",
      "[5600]\ttraining's rmse: 5.63907\tvalid_1's rmse: 515.011\n",
      "[5700]\ttraining's rmse: 5.39272\tvalid_1's rmse: 515.007\n",
      "[5800]\ttraining's rmse: 5.16825\tvalid_1's rmse: 515.014\n",
      "[5900]\ttraining's rmse: 4.94026\tvalid_1's rmse: 515.014\n",
      "[6000]\ttraining's rmse: 4.72777\tvalid_1's rmse: 514.997\n",
      "[6100]\ttraining's rmse: 4.52184\tvalid_1's rmse: 514.989\n",
      "[6200]\ttraining's rmse: 4.3441\tvalid_1's rmse: 514.984\n",
      "[6300]\ttraining's rmse: 4.16516\tvalid_1's rmse: 514.985\n",
      "[6400]\ttraining's rmse: 3.99999\tvalid_1's rmse: 514.982\n",
      "[6500]\ttraining's rmse: 3.83791\tvalid_1's rmse: 514.977\n",
      "[6600]\ttraining's rmse: 3.69105\tvalid_1's rmse: 514.977\n",
      "[6700]\ttraining's rmse: 3.54646\tvalid_1's rmse: 514.972\n",
      "[6800]\ttraining's rmse: 3.4123\tvalid_1's rmse: 514.963\n",
      "[6900]\ttraining's rmse: 3.28666\tvalid_1's rmse: 514.96\n",
      "[7000]\ttraining's rmse: 3.1706\tvalid_1's rmse: 514.945\n",
      "[7100]\ttraining's rmse: 3.06331\tvalid_1's rmse: 514.944\n",
      "[7200]\ttraining's rmse: 2.95348\tvalid_1's rmse: 514.943\n",
      "[7300]\ttraining's rmse: 2.8519\tvalid_1's rmse: 514.947\n",
      "[7400]\ttraining's rmse: 2.75627\tvalid_1's rmse: 514.94\n",
      "[7500]\ttraining's rmse: 2.65928\tvalid_1's rmse: 514.948\n",
      "[7600]\ttraining's rmse: 2.57913\tvalid_1's rmse: 514.948\n",
      "[7700]\ttraining's rmse: 2.49326\tvalid_1's rmse: 514.95\n",
      "[7800]\ttraining's rmse: 2.4141\tvalid_1's rmse: 514.945\n",
      "Early stopping, best iteration is:\n",
      "[7370]\ttraining's rmse: 2.78383\tvalid_1's rmse: 514.939\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\ttraining's rmse: 519.057\tvalid_1's rmse: 829.076\n",
      "[200]\ttraining's rmse: 324\tvalid_1's rmse: 672.523\n",
      "[300]\ttraining's rmse: 242.202\tvalid_1's rmse: 620.527\n",
      "[400]\ttraining's rmse: 194.115\tvalid_1's rmse: 597.176\n",
      "[500]\ttraining's rmse: 163.114\tvalid_1's rmse: 585.025\n",
      "[600]\ttraining's rmse: 140.402\tvalid_1's rmse: 577.797\n",
      "[700]\ttraining's rmse: 123.442\tvalid_1's rmse: 571.669\n",
      "[800]\ttraining's rmse: 109.821\tvalid_1's rmse: 568.349\n",
      "[900]\ttraining's rmse: 98.2313\tvalid_1's rmse: 565.103\n",
      "[1000]\ttraining's rmse: 88.6477\tvalid_1's rmse: 563.502\n",
      "[1100]\ttraining's rmse: 80.6664\tvalid_1's rmse: 561.954\n",
      "[1200]\ttraining's rmse: 73.5087\tvalid_1's rmse: 560.664\n",
      "[1300]\ttraining's rmse: 67.269\tvalid_1's rmse: 559.577\n",
      "[1400]\ttraining's rmse: 62.0813\tvalid_1's rmse: 558.887\n",
      "[1500]\ttraining's rmse: 57.309\tvalid_1's rmse: 557.888\n",
      "[1600]\ttraining's rmse: 52.9925\tvalid_1's rmse: 557.15\n",
      "[1700]\ttraining's rmse: 49.1145\tvalid_1's rmse: 556.857\n",
      "[1800]\ttraining's rmse: 45.7854\tvalid_1's rmse: 556.368\n",
      "[1900]\ttraining's rmse: 42.7182\tvalid_1's rmse: 555.914\n",
      "[2000]\ttraining's rmse: 39.9582\tvalid_1's rmse: 555.529\n",
      "[2100]\ttraining's rmse: 37.4051\tvalid_1's rmse: 555.439\n",
      "[2200]\ttraining's rmse: 34.963\tvalid_1's rmse: 555.338\n",
      "[2300]\ttraining's rmse: 32.7442\tvalid_1's rmse: 555.25\n",
      "[2400]\ttraining's rmse: 30.6401\tvalid_1's rmse: 555.058\n",
      "[2500]\ttraining's rmse: 28.6923\tvalid_1's rmse: 554.998\n",
      "[2600]\ttraining's rmse: 26.962\tvalid_1's rmse: 554.962\n",
      "[2700]\ttraining's rmse: 25.3155\tvalid_1's rmse: 554.882\n",
      "[2800]\ttraining's rmse: 23.8134\tvalid_1's rmse: 554.807\n",
      "[2900]\ttraining's rmse: 22.4205\tvalid_1's rmse: 554.799\n",
      "[3000]\ttraining's rmse: 21.1435\tvalid_1's rmse: 554.68\n",
      "[3100]\ttraining's rmse: 19.9097\tvalid_1's rmse: 554.619\n",
      "[3200]\ttraining's rmse: 18.8287\tvalid_1's rmse: 554.584\n",
      "[3300]\ttraining's rmse: 17.7727\tvalid_1's rmse: 554.455\n",
      "[3400]\ttraining's rmse: 16.7982\tvalid_1's rmse: 554.445\n",
      "[3500]\ttraining's rmse: 15.8979\tvalid_1's rmse: 554.326\n",
      "[3600]\ttraining's rmse: 15.0258\tvalid_1's rmse: 554.281\n",
      "[3700]\ttraining's rmse: 14.218\tvalid_1's rmse: 554.275\n",
      "[3800]\ttraining's rmse: 13.4906\tvalid_1's rmse: 554.228\n",
      "[3900]\ttraining's rmse: 12.7883\tvalid_1's rmse: 554.214\n",
      "[4000]\ttraining's rmse: 12.1219\tvalid_1's rmse: 554.18\n",
      "[4100]\ttraining's rmse: 11.5244\tvalid_1's rmse: 554.17\n",
      "[4200]\ttraining's rmse: 10.9492\tvalid_1's rmse: 554.157\n",
      "[4300]\ttraining's rmse: 10.4348\tvalid_1's rmse: 554.121\n",
      "[4400]\ttraining's rmse: 9.91786\tvalid_1's rmse: 554.125\n",
      "[4500]\ttraining's rmse: 9.44789\tvalid_1's rmse: 554.092\n",
      "[4600]\ttraining's rmse: 9.01084\tvalid_1's rmse: 554.088\n",
      "[4700]\ttraining's rmse: 8.60101\tvalid_1's rmse: 554.038\n",
      "[4800]\ttraining's rmse: 8.19959\tvalid_1's rmse: 554.041\n",
      "[4900]\ttraining's rmse: 7.80792\tvalid_1's rmse: 554.038\n",
      "[5000]\ttraining's rmse: 7.4331\tvalid_1's rmse: 553.992\n",
      "[5100]\ttraining's rmse: 7.08936\tvalid_1's rmse: 553.973\n",
      "[5200]\ttraining's rmse: 6.77142\tvalid_1's rmse: 553.987\n",
      "[5300]\ttraining's rmse: 6.45434\tvalid_1's rmse: 553.963\n",
      "[5400]\ttraining's rmse: 6.16708\tvalid_1's rmse: 553.94\n",
      "[5500]\ttraining's rmse: 5.89568\tvalid_1's rmse: 553.952\n",
      "[5600]\ttraining's rmse: 5.64279\tvalid_1's rmse: 553.943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5700]\ttraining's rmse: 5.40626\tvalid_1's rmse: 553.948\n",
      "[5800]\ttraining's rmse: 5.15594\tvalid_1's rmse: 553.936\n",
      "[5900]\ttraining's rmse: 4.92402\tvalid_1's rmse: 553.931\n",
      "[6000]\ttraining's rmse: 4.7205\tvalid_1's rmse: 553.922\n",
      "[6100]\ttraining's rmse: 4.52936\tvalid_1's rmse: 553.914\n",
      "[6200]\ttraining's rmse: 4.33672\tvalid_1's rmse: 553.908\n",
      "[6300]\ttraining's rmse: 4.1633\tvalid_1's rmse: 553.907\n",
      "[6400]\ttraining's rmse: 3.99409\tvalid_1's rmse: 553.892\n",
      "[6500]\ttraining's rmse: 3.82903\tvalid_1's rmse: 553.888\n",
      "[6600]\ttraining's rmse: 3.68006\tvalid_1's rmse: 553.874\n",
      "[6700]\ttraining's rmse: 3.54307\tvalid_1's rmse: 553.87\n",
      "[6800]\ttraining's rmse: 3.40411\tvalid_1's rmse: 553.877\n",
      "[6900]\ttraining's rmse: 3.27365\tvalid_1's rmse: 553.873\n",
      "[7000]\ttraining's rmse: 3.15057\tvalid_1's rmse: 553.862\n",
      "[7100]\ttraining's rmse: 3.03351\tvalid_1's rmse: 553.86\n",
      "[7200]\ttraining's rmse: 2.92868\tvalid_1's rmse: 553.858\n",
      "[7300]\ttraining's rmse: 2.82927\tvalid_1's rmse: 553.854\n",
      "[7400]\ttraining's rmse: 2.72434\tvalid_1's rmse: 553.851\n",
      "[7500]\ttraining's rmse: 2.63104\tvalid_1's rmse: 553.848\n",
      "[7600]\ttraining's rmse: 2.54681\tvalid_1's rmse: 553.84\n",
      "[7700]\ttraining's rmse: 2.46104\tvalid_1's rmse: 553.843\n",
      "[7800]\ttraining's rmse: 2.37831\tvalid_1's rmse: 553.838\n",
      "[7900]\ttraining's rmse: 2.29739\tvalid_1's rmse: 553.831\n",
      "[8000]\ttraining's rmse: 2.22561\tvalid_1's rmse: 553.827\n",
      "[8100]\ttraining's rmse: 2.15128\tvalid_1's rmse: 553.829\n",
      "[8200]\ttraining's rmse: 2.08624\tvalid_1's rmse: 553.822\n",
      "[8300]\ttraining's rmse: 2.02365\tvalid_1's rmse: 553.815\n",
      "[8400]\ttraining's rmse: 1.96299\tvalid_1's rmse: 553.813\n",
      "[8500]\ttraining's rmse: 1.90569\tvalid_1's rmse: 553.807\n",
      "[8600]\ttraining's rmse: 1.8455\tvalid_1's rmse: 553.801\n",
      "[8700]\ttraining's rmse: 1.79239\tvalid_1's rmse: 553.8\n",
      "[8800]\ttraining's rmse: 1.74201\tvalid_1's rmse: 553.801\n",
      "[8900]\ttraining's rmse: 1.69563\tvalid_1's rmse: 553.8\n",
      "[9000]\ttraining's rmse: 1.64914\tvalid_1's rmse: 553.799\n",
      "[9100]\ttraining's rmse: 1.60137\tvalid_1's rmse: 553.8\n",
      "[9200]\ttraining's rmse: 1.55913\tvalid_1's rmse: 553.802\n",
      "[9300]\ttraining's rmse: 1.51918\tvalid_1's rmse: 553.8\n",
      "[9400]\ttraining's rmse: 1.48047\tvalid_1's rmse: 553.796\n",
      "[9500]\ttraining's rmse: 1.44286\tvalid_1's rmse: 553.796\n",
      "[9600]\ttraining's rmse: 1.40628\tvalid_1's rmse: 553.793\n",
      "[9700]\ttraining's rmse: 1.37032\tvalid_1's rmse: 553.79\n",
      "[9800]\ttraining's rmse: 1.3345\tvalid_1's rmse: 553.784\n",
      "[9900]\ttraining's rmse: 1.30113\tvalid_1's rmse: 553.783\n",
      "[10000]\ttraining's rmse: 1.27074\tvalid_1's rmse: 553.779\n",
      "[10100]\ttraining's rmse: 1.23911\tvalid_1's rmse: 553.777\n",
      "[10200]\ttraining's rmse: 1.21019\tvalid_1's rmse: 553.776\n",
      "[10300]\ttraining's rmse: 1.18442\tvalid_1's rmse: 553.778\n",
      "[10400]\ttraining's rmse: 1.15498\tvalid_1's rmse: 553.776\n",
      "[10500]\ttraining's rmse: 1.13168\tvalid_1's rmse: 553.775\n",
      "[10600]\ttraining's rmse: 1.10664\tvalid_1's rmse: 553.775\n",
      "[10700]\ttraining's rmse: 1.08191\tvalid_1's rmse: 553.773\n",
      "[10800]\ttraining's rmse: 1.05806\tvalid_1's rmse: 553.771\n",
      "[10900]\ttraining's rmse: 1.03578\tvalid_1's rmse: 553.77\n",
      "[11000]\ttraining's rmse: 1.01511\tvalid_1's rmse: 553.77\n",
      "[11100]\ttraining's rmse: 0.991547\tvalid_1's rmse: 553.769\n",
      "[11200]\ttraining's rmse: 0.973093\tvalid_1's rmse: 553.767\n",
      "[11300]\ttraining's rmse: 0.951652\tvalid_1's rmse: 553.769\n",
      "[11400]\ttraining's rmse: 0.929842\tvalid_1's rmse: 553.767\n",
      "[11500]\ttraining's rmse: 0.909759\tvalid_1's rmse: 553.767\n",
      "[11600]\ttraining's rmse: 0.89121\tvalid_1's rmse: 553.765\n",
      "[11700]\ttraining's rmse: 0.872965\tvalid_1's rmse: 553.766\n",
      "[11800]\ttraining's rmse: 0.857805\tvalid_1's rmse: 553.764\n",
      "[11900]\ttraining's rmse: 0.8441\tvalid_1's rmse: 553.762\n",
      "[12000]\ttraining's rmse: 0.826555\tvalid_1's rmse: 553.761\n",
      "[12100]\ttraining's rmse: 0.812967\tvalid_1's rmse: 553.761\n",
      "[12200]\ttraining's rmse: 0.798313\tvalid_1's rmse: 553.763\n",
      "[12300]\ttraining's rmse: 0.782992\tvalid_1's rmse: 553.762\n",
      "[12400]\ttraining's rmse: 0.769561\tvalid_1's rmse: 553.76\n",
      "[12500]\ttraining's rmse: 0.756001\tvalid_1's rmse: 553.759\n",
      "[12600]\ttraining's rmse: 0.739046\tvalid_1's rmse: 553.759\n",
      "[12700]\ttraining's rmse: 0.725429\tvalid_1's rmse: 553.759\n",
      "[12800]\ttraining's rmse: 0.713562\tvalid_1's rmse: 553.759\n",
      "[12900]\ttraining's rmse: 0.701296\tvalid_1's rmse: 553.758\n",
      "[13000]\ttraining's rmse: 0.686766\tvalid_1's rmse: 553.756\n",
      "[13100]\ttraining's rmse: 0.6728\tvalid_1's rmse: 553.756\n",
      "[13200]\ttraining's rmse: 0.660957\tvalid_1's rmse: 553.755\n",
      "[13300]\ttraining's rmse: 0.646988\tvalid_1's rmse: 553.756\n",
      "[13400]\ttraining's rmse: 0.637578\tvalid_1's rmse: 553.755\n",
      "[13500]\ttraining's rmse: 0.627094\tvalid_1's rmse: 553.756\n",
      "[13600]\ttraining's rmse: 0.616207\tvalid_1's rmse: 553.755\n",
      "[13700]\ttraining's rmse: 0.606433\tvalid_1's rmse: 553.754\n",
      "[13800]\ttraining's rmse: 0.595355\tvalid_1's rmse: 553.755\n",
      "[13900]\ttraining's rmse: 0.585676\tvalid_1's rmse: 553.755\n",
      "[14000]\ttraining's rmse: 0.575336\tvalid_1's rmse: 553.756\n",
      "[14100]\ttraining's rmse: 0.564561\tvalid_1's rmse: 553.755\n",
      "[14200]\ttraining's rmse: 0.556831\tvalid_1's rmse: 553.757\n",
      "[14300]\ttraining's rmse: 0.543722\tvalid_1's rmse: 553.756\n",
      "Early stopping, best iteration is:\n",
      "[13852]\ttraining's rmse: 0.589832\tvalid_1's rmse: 553.754\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\ttraining's rmse: 535.43\tvalid_1's rmse: 693.151\n",
      "[200]\ttraining's rmse: 330.677\tvalid_1's rmse: 535.514\n",
      "[300]\ttraining's rmse: 246.612\tvalid_1's rmse: 486.809\n",
      "[400]\ttraining's rmse: 198.075\tvalid_1's rmse: 468.053\n",
      "[500]\ttraining's rmse: 166.441\tvalid_1's rmse: 457.337\n",
      "[600]\ttraining's rmse: 143.735\tvalid_1's rmse: 452.164\n",
      "[700]\ttraining's rmse: 126.13\tvalid_1's rmse: 446.598\n",
      "[800]\ttraining's rmse: 111.942\tvalid_1's rmse: 443.491\n",
      "[900]\ttraining's rmse: 100.581\tvalid_1's rmse: 440.956\n",
      "[1000]\ttraining's rmse: 90.9497\tvalid_1's rmse: 439.064\n",
      "[1100]\ttraining's rmse: 82.8338\tvalid_1's rmse: 438.198\n",
      "[1200]\ttraining's rmse: 75.7029\tvalid_1's rmse: 437.317\n",
      "[1300]\ttraining's rmse: 69.6079\tvalid_1's rmse: 436.789\n",
      "[1400]\ttraining's rmse: 64.3061\tvalid_1's rmse: 435.919\n",
      "[1500]\ttraining's rmse: 59.5575\tvalid_1's rmse: 435.489\n",
      "[1600]\ttraining's rmse: 55.161\tvalid_1's rmse: 434.7\n",
      "[1700]\ttraining's rmse: 51.1259\tvalid_1's rmse: 434.175\n",
      "[1800]\ttraining's rmse: 47.6287\tvalid_1's rmse: 433.801\n",
      "[1900]\ttraining's rmse: 44.3995\tvalid_1's rmse: 433.394\n",
      "[2000]\ttraining's rmse: 41.4864\tvalid_1's rmse: 433.166\n",
      "[2100]\ttraining's rmse: 38.7711\tvalid_1's rmse: 432.842\n",
      "[2200]\ttraining's rmse: 36.3271\tvalid_1's rmse: 432.788\n",
      "[2300]\ttraining's rmse: 34.0335\tvalid_1's rmse: 432.636\n",
      "[2400]\ttraining's rmse: 31.8925\tvalid_1's rmse: 432.435\n",
      "[2500]\ttraining's rmse: 29.996\tvalid_1's rmse: 432.364\n",
      "[2600]\ttraining's rmse: 28.3461\tvalid_1's rmse: 432.352\n",
      "[2700]\ttraining's rmse: 26.6922\tvalid_1's rmse: 432.236\n",
      "[2800]\ttraining's rmse: 25.1763\tvalid_1's rmse: 432.185\n",
      "[2900]\ttraining's rmse: 23.7904\tvalid_1's rmse: 432.007\n",
      "[3000]\ttraining's rmse: 22.5334\tvalid_1's rmse: 431.921\n",
      "[3100]\ttraining's rmse: 21.3576\tvalid_1's rmse: 431.751\n",
      "[3200]\ttraining's rmse: 20.2361\tvalid_1's rmse: 431.604\n",
      "[3300]\ttraining's rmse: 19.1733\tvalid_1's rmse: 431.545\n",
      "[3400]\ttraining's rmse: 18.1142\tvalid_1's rmse: 431.478\n",
      "[3500]\ttraining's rmse: 17.2186\tvalid_1's rmse: 431.372\n",
      "[3600]\ttraining's rmse: 16.3627\tvalid_1's rmse: 431.328\n",
      "[3700]\ttraining's rmse: 15.5521\tvalid_1's rmse: 431.3\n",
      "[3800]\ttraining's rmse: 14.8136\tvalid_1's rmse: 431.245\n",
      "[3900]\ttraining's rmse: 14.1122\tvalid_1's rmse: 431.16\n",
      "[4000]\ttraining's rmse: 13.4742\tvalid_1's rmse: 431.159\n",
      "[4100]\ttraining's rmse: 12.8657\tvalid_1's rmse: 431.103\n",
      "[4200]\ttraining's rmse: 12.3051\tvalid_1's rmse: 431.108\n",
      "[4300]\ttraining's rmse: 11.7254\tvalid_1's rmse: 431.089\n",
      "[4400]\ttraining's rmse: 11.174\tvalid_1's rmse: 431.081\n",
      "[4500]\ttraining's rmse: 10.7107\tvalid_1's rmse: 431.024\n",
      "[4600]\ttraining's rmse: 10.2835\tvalid_1's rmse: 431.017\n",
      "[4700]\ttraining's rmse: 9.84676\tvalid_1's rmse: 431.014\n",
      "[4800]\ttraining's rmse: 9.46143\tvalid_1's rmse: 430.987\n",
      "[4900]\ttraining's rmse: 9.06613\tvalid_1's rmse: 430.977\n",
      "[5000]\ttraining's rmse: 8.71136\tvalid_1's rmse: 430.971\n",
      "[5100]\ttraining's rmse: 8.39004\tvalid_1's rmse: 430.994\n",
      "[5200]\ttraining's rmse: 8.08833\tvalid_1's rmse: 430.973\n",
      "[5300]\ttraining's rmse: 7.7978\tvalid_1's rmse: 430.961\n",
      "[5400]\ttraining's rmse: 7.5115\tvalid_1's rmse: 430.968\n",
      "[5500]\ttraining's rmse: 7.24916\tvalid_1's rmse: 430.963\n",
      "[5600]\ttraining's rmse: 7.01637\tvalid_1's rmse: 430.947\n",
      "[5700]\ttraining's rmse: 6.7858\tvalid_1's rmse: 430.948\n",
      "[5800]\ttraining's rmse: 6.57107\tvalid_1's rmse: 430.941\n",
      "[5900]\ttraining's rmse: 6.36412\tvalid_1's rmse: 430.94\n",
      "[6000]\ttraining's rmse: 6.17102\tvalid_1's rmse: 430.927\n",
      "[6100]\ttraining's rmse: 5.99975\tvalid_1's rmse: 430.921\n",
      "[6200]\ttraining's rmse: 5.83267\tvalid_1's rmse: 430.916\n",
      "[6300]\ttraining's rmse: 5.67923\tvalid_1's rmse: 430.906\n",
      "[6400]\ttraining's rmse: 5.53001\tvalid_1's rmse: 430.903\n",
      "[6500]\ttraining's rmse: 5.37764\tvalid_1's rmse: 430.892\n",
      "[6600]\ttraining's rmse: 5.23221\tvalid_1's rmse: 430.876\n",
      "[6700]\ttraining's rmse: 5.10681\tvalid_1's rmse: 430.86\n",
      "[6800]\ttraining's rmse: 4.97679\tvalid_1's rmse: 430.854\n",
      "[6900]\ttraining's rmse: 4.85338\tvalid_1's rmse: 430.856\n",
      "[7000]\ttraining's rmse: 4.73448\tvalid_1's rmse: 430.842\n",
      "[7100]\ttraining's rmse: 4.62003\tvalid_1's rmse: 430.847\n",
      "[7200]\ttraining's rmse: 4.51099\tvalid_1's rmse: 430.839\n",
      "[7300]\ttraining's rmse: 4.40535\tvalid_1's rmse: 430.835\n",
      "[7400]\ttraining's rmse: 4.30615\tvalid_1's rmse: 430.834\n",
      "[7500]\ttraining's rmse: 4.21844\tvalid_1's rmse: 430.818\n",
      "[7600]\ttraining's rmse: 4.14366\tvalid_1's rmse: 430.816\n",
      "[7700]\ttraining's rmse: 4.05883\tvalid_1's rmse: 430.812\n",
      "[7800]\ttraining's rmse: 3.98229\tvalid_1's rmse: 430.812\n",
      "[7900]\ttraining's rmse: 3.90555\tvalid_1's rmse: 430.798\n",
      "[8000]\ttraining's rmse: 3.82792\tvalid_1's rmse: 430.795\n",
      "[8100]\ttraining's rmse: 3.75261\tvalid_1's rmse: 430.793\n",
      "[8200]\ttraining's rmse: 3.68055\tvalid_1's rmse: 430.79\n",
      "[8300]\ttraining's rmse: 3.6167\tvalid_1's rmse: 430.786\n",
      "[8400]\ttraining's rmse: 3.55834\tvalid_1's rmse: 430.783\n",
      "[8500]\ttraining's rmse: 3.49284\tvalid_1's rmse: 430.783\n",
      "[8600]\ttraining's rmse: 3.42574\tvalid_1's rmse: 430.778\n",
      "[8700]\ttraining's rmse: 3.36975\tvalid_1's rmse: 430.77\n",
      "[8800]\ttraining's rmse: 3.30934\tvalid_1's rmse: 430.777\n",
      "[8900]\ttraining's rmse: 3.26051\tvalid_1's rmse: 430.774\n",
      "[9000]\ttraining's rmse: 3.20798\tvalid_1's rmse: 430.769\n",
      "[9100]\ttraining's rmse: 3.14522\tvalid_1's rmse: 430.769\n",
      "[9200]\ttraining's rmse: 3.09465\tvalid_1's rmse: 430.764\n",
      "[9300]\ttraining's rmse: 3.04847\tvalid_1's rmse: 430.763\n",
      "[9400]\ttraining's rmse: 3.00801\tvalid_1's rmse: 430.761\n",
      "[9500]\ttraining's rmse: 2.9605\tvalid_1's rmse: 430.76\n",
      "[9600]\ttraining's rmse: 2.90851\tvalid_1's rmse: 430.764\n",
      "[9700]\ttraining's rmse: 2.86355\tvalid_1's rmse: 430.765\n",
      "[9800]\ttraining's rmse: 2.81781\tvalid_1's rmse: 430.761\n",
      "[9900]\ttraining's rmse: 2.77037\tvalid_1's rmse: 430.765\n",
      "[10000]\ttraining's rmse: 2.73263\tvalid_1's rmse: 430.766\n",
      "[10100]\ttraining's rmse: 2.69018\tvalid_1's rmse: 430.767\n",
      "[10200]\ttraining's rmse: 2.65291\tvalid_1's rmse: 430.772\n",
      "[10300]\ttraining's rmse: 2.61934\tvalid_1's rmse: 430.767\n",
      "Early stopping, best iteration is:\n",
      "[9820]\ttraining's rmse: 2.8094\tvalid_1's rmse: 430.759\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\ttraining's rmse: 526.397\tvalid_1's rmse: 858.454\n",
      "[200]\ttraining's rmse: 331.067\tvalid_1's rmse: 702.299\n",
      "[300]\ttraining's rmse: 249.397\tvalid_1's rmse: 653.189\n",
      "[400]\ttraining's rmse: 202.079\tvalid_1's rmse: 635.546\n",
      "[500]\ttraining's rmse: 171.219\tvalid_1's rmse: 625.231\n",
      "[600]\ttraining's rmse: 147.856\tvalid_1's rmse: 618.595\n",
      "[700]\ttraining's rmse: 130.034\tvalid_1's rmse: 613.56\n",
      "[800]\ttraining's rmse: 115.844\tvalid_1's rmse: 611.553\n",
      "[900]\ttraining's rmse: 104.189\tvalid_1's rmse: 609.21\n",
      "[1000]\ttraining's rmse: 94.3214\tvalid_1's rmse: 608.296\n",
      "[1100]\ttraining's rmse: 86.036\tvalid_1's rmse: 606.614\n",
      "[1200]\ttraining's rmse: 78.7438\tvalid_1's rmse: 605.455\n",
      "[1300]\ttraining's rmse: 72.3574\tvalid_1's rmse: 604.177\n",
      "[1400]\ttraining's rmse: 66.8126\tvalid_1's rmse: 603.742\n",
      "[1500]\ttraining's rmse: 61.9889\tvalid_1's rmse: 603.276\n",
      "[1600]\ttraining's rmse: 57.8253\tvalid_1's rmse: 602.988\n",
      "[1700]\ttraining's rmse: 53.6617\tvalid_1's rmse: 602.401\n",
      "[1800]\ttraining's rmse: 49.8736\tvalid_1's rmse: 602.129\n",
      "[1900]\ttraining's rmse: 46.4626\tvalid_1's rmse: 601.919\n",
      "[2000]\ttraining's rmse: 43.417\tvalid_1's rmse: 601.604\n",
      "[2100]\ttraining's rmse: 40.7336\tvalid_1's rmse: 601.54\n",
      "[2200]\ttraining's rmse: 38.2645\tvalid_1's rmse: 601.397\n",
      "[2300]\ttraining's rmse: 35.962\tvalid_1's rmse: 601.328\n",
      "[2400]\ttraining's rmse: 33.82\tvalid_1's rmse: 601.182\n",
      "[2500]\ttraining's rmse: 31.8167\tvalid_1's rmse: 601.057\n",
      "[2600]\ttraining's rmse: 29.9625\tvalid_1's rmse: 601.009\n",
      "[2700]\ttraining's rmse: 28.2411\tvalid_1's rmse: 600.856\n",
      "[2800]\ttraining's rmse: 26.6277\tvalid_1's rmse: 600.853\n",
      "[2900]\ttraining's rmse: 25.1316\tvalid_1's rmse: 600.765\n",
      "[3000]\ttraining's rmse: 23.8005\tvalid_1's rmse: 600.701\n",
      "[3100]\ttraining's rmse: 22.5114\tvalid_1's rmse: 600.646\n",
      "[3200]\ttraining's rmse: 21.2388\tvalid_1's rmse: 600.52\n",
      "[3300]\ttraining's rmse: 20.124\tvalid_1's rmse: 600.445\n",
      "[3400]\ttraining's rmse: 19.0602\tvalid_1's rmse: 600.367\n",
      "[3500]\ttraining's rmse: 18.0127\tvalid_1's rmse: 600.311\n",
      "[3600]\ttraining's rmse: 17.0521\tvalid_1's rmse: 600.277\n",
      "[3700]\ttraining's rmse: 16.1464\tvalid_1's rmse: 600.189\n",
      "[3800]\ttraining's rmse: 15.3217\tvalid_1's rmse: 600.197\n",
      "[3900]\ttraining's rmse: 14.5605\tvalid_1's rmse: 600.174\n",
      "[4000]\ttraining's rmse: 13.8443\tvalid_1's rmse: 600.178\n",
      "[4100]\ttraining's rmse: 13.1552\tvalid_1's rmse: 600.135\n",
      "[4200]\ttraining's rmse: 12.4965\tvalid_1's rmse: 600.116\n",
      "[4300]\ttraining's rmse: 11.8888\tvalid_1's rmse: 600.079\n",
      "[4400]\ttraining's rmse: 11.3129\tvalid_1's rmse: 600.098\n",
      "[4500]\ttraining's rmse: 10.7367\tvalid_1's rmse: 600.08\n",
      "[4600]\ttraining's rmse: 10.2071\tvalid_1's rmse: 600.053\n",
      "[4700]\ttraining's rmse: 9.71975\tvalid_1's rmse: 600.042\n",
      "[4800]\ttraining's rmse: 9.27718\tvalid_1's rmse: 599.999\n",
      "[4900]\ttraining's rmse: 8.85831\tvalid_1's rmse: 600.018\n",
      "[5000]\ttraining's rmse: 8.46074\tvalid_1's rmse: 600.003\n",
      "[5100]\ttraining's rmse: 8.08061\tvalid_1's rmse: 600.011\n",
      "[5200]\ttraining's rmse: 7.70815\tvalid_1's rmse: 600.069\n",
      "[5300]\ttraining's rmse: 7.36146\tvalid_1's rmse: 600.067\n",
      "Early stopping, best iteration is:\n",
      "[4825]\ttraining's rmse: 9.17588\tvalid_1's rmse: 599.997\n",
      "fold n°6\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\ttraining's rmse: 529.661\tvalid_1's rmse: 722.004\n",
      "[200]\ttraining's rmse: 328.31\tvalid_1's rmse: 578.305\n",
      "[300]\ttraining's rmse: 246.123\tvalid_1's rmse: 532.325\n",
      "[400]\ttraining's rmse: 198.46\tvalid_1's rmse: 510.999\n",
      "[500]\ttraining's rmse: 166.929\tvalid_1's rmse: 498.593\n",
      "[600]\ttraining's rmse: 144.653\tvalid_1's rmse: 490.88\n",
      "[700]\ttraining's rmse: 126.831\tvalid_1's rmse: 485.294\n",
      "[800]\ttraining's rmse: 113.264\tvalid_1's rmse: 482.423\n",
      "[900]\ttraining's rmse: 101.466\tvalid_1's rmse: 479.683\n",
      "[1000]\ttraining's rmse: 91.7045\tvalid_1's rmse: 477.902\n",
      "[1100]\ttraining's rmse: 83.6233\tvalid_1's rmse: 477.003\n",
      "[1200]\ttraining's rmse: 76.5837\tvalid_1's rmse: 475.615\n",
      "[1300]\ttraining's rmse: 70.3658\tvalid_1's rmse: 474.752\n",
      "[1400]\ttraining's rmse: 64.8512\tvalid_1's rmse: 474.465\n",
      "[1500]\ttraining's rmse: 59.9103\tvalid_1's rmse: 473.7\n",
      "[1600]\ttraining's rmse: 55.6722\tvalid_1's rmse: 472.929\n",
      "[1700]\ttraining's rmse: 51.7492\tvalid_1's rmse: 472.527\n",
      "[1800]\ttraining's rmse: 48.0828\tvalid_1's rmse: 472.514\n",
      "[1900]\ttraining's rmse: 44.9569\tvalid_1's rmse: 472.23\n",
      "[2000]\ttraining's rmse: 41.9255\tvalid_1's rmse: 471.95\n",
      "[2100]\ttraining's rmse: 39.1686\tvalid_1's rmse: 471.619\n",
      "[2200]\ttraining's rmse: 36.4925\tvalid_1's rmse: 471.568\n",
      "[2300]\ttraining's rmse: 34.2535\tvalid_1's rmse: 471.2\n",
      "[2400]\ttraining's rmse: 32.2086\tvalid_1's rmse: 471\n",
      "[2500]\ttraining's rmse: 30.1503\tvalid_1's rmse: 470.904\n",
      "[2600]\ttraining's rmse: 28.2473\tvalid_1's rmse: 470.742\n",
      "[2700]\ttraining's rmse: 26.5616\tvalid_1's rmse: 470.751\n",
      "[2800]\ttraining's rmse: 24.9504\tvalid_1's rmse: 470.563\n",
      "[2900]\ttraining's rmse: 23.5056\tvalid_1's rmse: 470.596\n",
      "[3000]\ttraining's rmse: 22.1926\tvalid_1's rmse: 470.506\n",
      "[3100]\ttraining's rmse: 20.9476\tvalid_1's rmse: 470.42\n",
      "[3200]\ttraining's rmse: 19.7121\tvalid_1's rmse: 470.356\n",
      "[3300]\ttraining's rmse: 18.5948\tvalid_1's rmse: 470.357\n",
      "[3400]\ttraining's rmse: 17.5872\tvalid_1's rmse: 470.274\n",
      "[3500]\ttraining's rmse: 16.6041\tvalid_1's rmse: 470.314\n",
      "[3600]\ttraining's rmse: 15.7309\tvalid_1's rmse: 470.265\n",
      "[3700]\ttraining's rmse: 14.9123\tvalid_1's rmse: 470.319\n",
      "[3800]\ttraining's rmse: 14.1024\tvalid_1's rmse: 470.27\n",
      "[3900]\ttraining's rmse: 13.2978\tvalid_1's rmse: 470.246\n",
      "[4000]\ttraining's rmse: 12.6082\tvalid_1's rmse: 470.236\n",
      "[4100]\ttraining's rmse: 11.9087\tvalid_1's rmse: 470.242\n",
      "[4200]\ttraining's rmse: 11.3078\tvalid_1's rmse: 470.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4300]\ttraining's rmse: 10.7644\tvalid_1's rmse: 470.238\n",
      "[4400]\ttraining's rmse: 10.2297\tvalid_1's rmse: 470.227\n",
      "[4500]\ttraining's rmse: 9.6878\tvalid_1's rmse: 470.194\n",
      "[4600]\ttraining's rmse: 9.21536\tvalid_1's rmse: 470.204\n",
      "[4700]\ttraining's rmse: 8.72215\tvalid_1's rmse: 470.198\n",
      "[4800]\ttraining's rmse: 8.29537\tvalid_1's rmse: 470.175\n",
      "[4900]\ttraining's rmse: 7.89419\tvalid_1's rmse: 470.176\n",
      "[5000]\ttraining's rmse: 7.50823\tvalid_1's rmse: 470.157\n",
      "[5100]\ttraining's rmse: 7.14957\tvalid_1's rmse: 470.114\n",
      "[5200]\ttraining's rmse: 6.83679\tvalid_1's rmse: 470.127\n",
      "[5300]\ttraining's rmse: 6.52518\tvalid_1's rmse: 470.122\n",
      "[5400]\ttraining's rmse: 6.22718\tvalid_1's rmse: 470.123\n",
      "[5500]\ttraining's rmse: 5.95389\tvalid_1's rmse: 470.097\n",
      "[5600]\ttraining's rmse: 5.68618\tvalid_1's rmse: 470.091\n",
      "[5700]\ttraining's rmse: 5.4141\tvalid_1's rmse: 470.091\n",
      "[5800]\ttraining's rmse: 5.18046\tvalid_1's rmse: 470.078\n",
      "[5900]\ttraining's rmse: 4.96419\tvalid_1's rmse: 470.081\n",
      "[6000]\ttraining's rmse: 4.75462\tvalid_1's rmse: 470.082\n",
      "[6100]\ttraining's rmse: 4.55482\tvalid_1's rmse: 470.079\n",
      "[6200]\ttraining's rmse: 4.36798\tvalid_1's rmse: 470.081\n",
      "[6300]\ttraining's rmse: 4.18015\tvalid_1's rmse: 470.086\n",
      "[6400]\ttraining's rmse: 4.01538\tvalid_1's rmse: 470.084\n",
      "[6500]\ttraining's rmse: 3.84442\tvalid_1's rmse: 470.097\n",
      "Early stopping, best iteration is:\n",
      "[6040]\ttraining's rmse: 4.6706\tvalid_1's rmse: 470.074\n",
      "fold n°7\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\ttraining's rmse: 527.014\tvalid_1's rmse: 686.778\n",
      "[200]\ttraining's rmse: 326.168\tvalid_1's rmse: 552.926\n",
      "[300]\ttraining's rmse: 246.259\tvalid_1's rmse: 512.512\n",
      "[400]\ttraining's rmse: 199.174\tvalid_1's rmse: 491.712\n",
      "[500]\ttraining's rmse: 167.519\tvalid_1's rmse: 483.661\n",
      "[600]\ttraining's rmse: 144.89\tvalid_1's rmse: 478.29\n",
      "[700]\ttraining's rmse: 127.007\tvalid_1's rmse: 473.648\n",
      "[800]\ttraining's rmse: 112.599\tvalid_1's rmse: 470.138\n",
      "[900]\ttraining's rmse: 100.747\tvalid_1's rmse: 467.698\n",
      "[1000]\ttraining's rmse: 91.0264\tvalid_1's rmse: 466.165\n",
      "[1100]\ttraining's rmse: 82.8547\tvalid_1's rmse: 464.924\n",
      "[1200]\ttraining's rmse: 75.5455\tvalid_1's rmse: 463.965\n",
      "[1300]\ttraining's rmse: 69.3473\tvalid_1's rmse: 463.299\n",
      "[1400]\ttraining's rmse: 63.856\tvalid_1's rmse: 462.59\n",
      "[1500]\ttraining's rmse: 58.8264\tvalid_1's rmse: 462.098\n",
      "[1600]\ttraining's rmse: 54.6529\tvalid_1's rmse: 461.765\n",
      "[1700]\ttraining's rmse: 50.6333\tvalid_1's rmse: 461.162\n",
      "[1800]\ttraining's rmse: 46.9996\tvalid_1's rmse: 461.267\n",
      "[1900]\ttraining's rmse: 43.7426\tvalid_1's rmse: 460.98\n",
      "[2000]\ttraining's rmse: 40.8724\tvalid_1's rmse: 460.681\n",
      "[2100]\ttraining's rmse: 38.1176\tvalid_1's rmse: 460.595\n",
      "[2200]\ttraining's rmse: 35.7735\tvalid_1's rmse: 460.371\n",
      "[2300]\ttraining's rmse: 33.529\tvalid_1's rmse: 460.067\n",
      "[2400]\ttraining's rmse: 31.4951\tvalid_1's rmse: 459.88\n",
      "[2500]\ttraining's rmse: 29.5601\tvalid_1's rmse: 459.731\n",
      "[2600]\ttraining's rmse: 27.7812\tvalid_1's rmse: 459.597\n",
      "[2700]\ttraining's rmse: 26.1458\tvalid_1's rmse: 459.55\n",
      "[2800]\ttraining's rmse: 24.571\tvalid_1's rmse: 459.471\n",
      "[2900]\ttraining's rmse: 23.0622\tvalid_1's rmse: 459.388\n",
      "[3000]\ttraining's rmse: 21.7554\tvalid_1's rmse: 459.385\n",
      "[3100]\ttraining's rmse: 20.5744\tvalid_1's rmse: 459.321\n",
      "[3200]\ttraining's rmse: 19.5349\tvalid_1's rmse: 459.228\n",
      "[3300]\ttraining's rmse: 18.4718\tvalid_1's rmse: 459.189\n",
      "[3400]\ttraining's rmse: 17.436\tvalid_1's rmse: 459.225\n",
      "[3500]\ttraining's rmse: 16.4874\tvalid_1's rmse: 459.175\n",
      "[3600]\ttraining's rmse: 15.616\tvalid_1's rmse: 459.079\n",
      "[3700]\ttraining's rmse: 14.7916\tvalid_1's rmse: 459.069\n",
      "[3800]\ttraining's rmse: 14.0067\tvalid_1's rmse: 459.041\n",
      "[3900]\ttraining's rmse: 13.2915\tvalid_1's rmse: 458.981\n",
      "[4000]\ttraining's rmse: 12.5737\tvalid_1's rmse: 458.947\n",
      "[4100]\ttraining's rmse: 11.9172\tvalid_1's rmse: 458.912\n",
      "[4200]\ttraining's rmse: 11.333\tvalid_1's rmse: 458.878\n",
      "[4300]\ttraining's rmse: 10.7539\tvalid_1's rmse: 458.859\n",
      "[4400]\ttraining's rmse: 10.2436\tvalid_1's rmse: 458.845\n",
      "[4500]\ttraining's rmse: 9.73631\tvalid_1's rmse: 458.827\n",
      "[4600]\ttraining's rmse: 9.24537\tvalid_1's rmse: 458.811\n",
      "[4700]\ttraining's rmse: 8.80321\tvalid_1's rmse: 458.804\n",
      "[4800]\ttraining's rmse: 8.39189\tvalid_1's rmse: 458.777\n",
      "[4900]\ttraining's rmse: 7.97731\tvalid_1's rmse: 458.79\n",
      "[5000]\ttraining's rmse: 7.58956\tvalid_1's rmse: 458.787\n",
      "[5100]\ttraining's rmse: 7.23404\tvalid_1's rmse: 458.785\n",
      "[5200]\ttraining's rmse: 6.89783\tvalid_1's rmse: 458.772\n",
      "[5300]\ttraining's rmse: 6.59174\tvalid_1's rmse: 458.758\n",
      "[5400]\ttraining's rmse: 6.29489\tvalid_1's rmse: 458.757\n",
      "[5500]\ttraining's rmse: 5.9816\tvalid_1's rmse: 458.725\n",
      "[5600]\ttraining's rmse: 5.70246\tvalid_1's rmse: 458.712\n",
      "[5700]\ttraining's rmse: 5.43985\tvalid_1's rmse: 458.695\n",
      "[5800]\ttraining's rmse: 5.19097\tvalid_1's rmse: 458.691\n",
      "[5900]\ttraining's rmse: 4.96776\tvalid_1's rmse: 458.674\n",
      "[6000]\ttraining's rmse: 4.74962\tvalid_1's rmse: 458.661\n",
      "[6100]\ttraining's rmse: 4.53923\tvalid_1's rmse: 458.649\n",
      "[6200]\ttraining's rmse: 4.35087\tvalid_1's rmse: 458.636\n",
      "[6300]\ttraining's rmse: 4.16451\tvalid_1's rmse: 458.635\n",
      "[6400]\ttraining's rmse: 3.99796\tvalid_1's rmse: 458.635\n",
      "[6500]\ttraining's rmse: 3.82616\tvalid_1's rmse: 458.632\n",
      "[6600]\ttraining's rmse: 3.6623\tvalid_1's rmse: 458.623\n",
      "[6700]\ttraining's rmse: 3.51189\tvalid_1's rmse: 458.622\n",
      "[6800]\ttraining's rmse: 3.36283\tvalid_1's rmse: 458.618\n",
      "[6900]\ttraining's rmse: 3.22703\tvalid_1's rmse: 458.606\n",
      "[7000]\ttraining's rmse: 3.10207\tvalid_1's rmse: 458.607\n",
      "[7100]\ttraining's rmse: 2.97271\tvalid_1's rmse: 458.601\n",
      "[7200]\ttraining's rmse: 2.85865\tvalid_1's rmse: 458.606\n",
      "[7300]\ttraining's rmse: 2.74723\tvalid_1's rmse: 458.605\n",
      "[7400]\ttraining's rmse: 2.63812\tvalid_1's rmse: 458.605\n",
      "[7500]\ttraining's rmse: 2.53213\tvalid_1's rmse: 458.609\n",
      "Early stopping, best iteration is:\n",
      "[7030]\ttraining's rmse: 3.06454\tvalid_1's rmse: 458.598\n",
      "fold n°8\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\ttraining's rmse: 521.931\tvalid_1's rmse: 725.844\n",
      "[200]\ttraining's rmse: 325.449\tvalid_1's rmse: 591.013\n",
      "[300]\ttraining's rmse: 244.74\tvalid_1's rmse: 549.104\n",
      "[400]\ttraining's rmse: 197.824\tvalid_1's rmse: 533.628\n",
      "[500]\ttraining's rmse: 166.807\tvalid_1's rmse: 522.855\n",
      "[600]\ttraining's rmse: 143.722\tvalid_1's rmse: 516.501\n",
      "[700]\ttraining's rmse: 126.366\tvalid_1's rmse: 511.965\n",
      "[800]\ttraining's rmse: 112.726\tvalid_1's rmse: 508.171\n",
      "[900]\ttraining's rmse: 100.933\tvalid_1's rmse: 505.919\n",
      "[1000]\ttraining's rmse: 91.3367\tvalid_1's rmse: 503.488\n",
      "[1100]\ttraining's rmse: 83.2765\tvalid_1's rmse: 501.625\n",
      "[1200]\ttraining's rmse: 76.2059\tvalid_1's rmse: 500.142\n",
      "[1300]\ttraining's rmse: 70.1419\tvalid_1's rmse: 499.26\n",
      "[1400]\ttraining's rmse: 64.9123\tvalid_1's rmse: 498.801\n",
      "[1500]\ttraining's rmse: 60.154\tvalid_1's rmse: 498.475\n",
      "[1600]\ttraining's rmse: 55.9273\tvalid_1's rmse: 498.04\n",
      "[1700]\ttraining's rmse: 51.7789\tvalid_1's rmse: 497.655\n",
      "[1800]\ttraining's rmse: 48.1614\tvalid_1's rmse: 497.723\n",
      "[1900]\ttraining's rmse: 44.8283\tvalid_1's rmse: 497.358\n",
      "[2000]\ttraining's rmse: 42.0072\tvalid_1's rmse: 496.984\n",
      "[2100]\ttraining's rmse: 39.1263\tvalid_1's rmse: 496.817\n",
      "[2200]\ttraining's rmse: 36.6141\tvalid_1's rmse: 496.831\n",
      "[2300]\ttraining's rmse: 34.446\tvalid_1's rmse: 496.596\n",
      "[2400]\ttraining's rmse: 32.3335\tvalid_1's rmse: 496.47\n",
      "[2500]\ttraining's rmse: 30.3867\tvalid_1's rmse: 496.31\n",
      "[2600]\ttraining's rmse: 28.5767\tvalid_1's rmse: 496.276\n",
      "[2700]\ttraining's rmse: 26.9628\tvalid_1's rmse: 496.209\n",
      "[2800]\ttraining's rmse: 25.4191\tvalid_1's rmse: 496.063\n",
      "[2900]\ttraining's rmse: 23.9946\tvalid_1's rmse: 495.952\n",
      "[3000]\ttraining's rmse: 22.652\tvalid_1's rmse: 495.934\n",
      "[3100]\ttraining's rmse: 21.3545\tvalid_1's rmse: 495.799\n",
      "[3200]\ttraining's rmse: 20.1491\tvalid_1's rmse: 495.806\n",
      "[3300]\ttraining's rmse: 19.0671\tvalid_1's rmse: 495.725\n",
      "[3400]\ttraining's rmse: 18.0582\tvalid_1's rmse: 495.633\n",
      "[3500]\ttraining's rmse: 17.0906\tvalid_1's rmse: 495.53\n",
      "[3600]\ttraining's rmse: 16.232\tvalid_1's rmse: 495.453\n",
      "[3700]\ttraining's rmse: 15.3028\tvalid_1's rmse: 495.44\n",
      "[3800]\ttraining's rmse: 14.4931\tvalid_1's rmse: 495.394\n",
      "[3900]\ttraining's rmse: 13.7334\tvalid_1's rmse: 495.378\n",
      "[4000]\ttraining's rmse: 13.0264\tvalid_1's rmse: 495.385\n",
      "[4100]\ttraining's rmse: 12.3514\tvalid_1's rmse: 495.413\n",
      "[4200]\ttraining's rmse: 11.7323\tvalid_1's rmse: 495.387\n",
      "[4300]\ttraining's rmse: 11.1729\tvalid_1's rmse: 495.334\n",
      "[4400]\ttraining's rmse: 10.6308\tvalid_1's rmse: 495.323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4500]\ttraining's rmse: 10.1321\tvalid_1's rmse: 495.347\n",
      "[4600]\ttraining's rmse: 9.64902\tvalid_1's rmse: 495.278\n",
      "[4700]\ttraining's rmse: 9.2005\tvalid_1's rmse: 495.261\n",
      "[4800]\ttraining's rmse: 8.76357\tvalid_1's rmse: 495.238\n",
      "[4900]\ttraining's rmse: 8.38109\tvalid_1's rmse: 495.214\n",
      "[5000]\ttraining's rmse: 8.00507\tvalid_1's rmse: 495.19\n",
      "[5100]\ttraining's rmse: 7.65179\tvalid_1's rmse: 495.162\n",
      "[5200]\ttraining's rmse: 7.30304\tvalid_1's rmse: 495.147\n",
      "[5300]\ttraining's rmse: 6.96662\tvalid_1's rmse: 495.124\n",
      "[5400]\ttraining's rmse: 6.67669\tvalid_1's rmse: 495.112\n",
      "[5500]\ttraining's rmse: 6.38418\tvalid_1's rmse: 495.103\n",
      "[5600]\ttraining's rmse: 6.1294\tvalid_1's rmse: 495.097\n",
      "[5700]\ttraining's rmse: 5.86654\tvalid_1's rmse: 495.088\n",
      "[5800]\ttraining's rmse: 5.62772\tvalid_1's rmse: 495.079\n",
      "[5900]\ttraining's rmse: 5.39393\tvalid_1's rmse: 495.083\n",
      "[6000]\ttraining's rmse: 5.17517\tvalid_1's rmse: 495.064\n",
      "[6100]\ttraining's rmse: 4.96464\tvalid_1's rmse: 495.06\n",
      "[6200]\ttraining's rmse: 4.77431\tvalid_1's rmse: 495.037\n",
      "[6300]\ttraining's rmse: 4.59063\tvalid_1's rmse: 495.033\n",
      "[6400]\ttraining's rmse: 4.4195\tvalid_1's rmse: 495.036\n",
      "[6500]\ttraining's rmse: 4.24971\tvalid_1's rmse: 495.036\n",
      "[6600]\ttraining's rmse: 4.08736\tvalid_1's rmse: 495.031\n",
      "[6700]\ttraining's rmse: 3.94244\tvalid_1's rmse: 495.026\n",
      "[6800]\ttraining's rmse: 3.7899\tvalid_1's rmse: 495.015\n",
      "[6900]\ttraining's rmse: 3.66113\tvalid_1's rmse: 495.011\n",
      "[7000]\ttraining's rmse: 3.53603\tvalid_1's rmse: 495.007\n",
      "[7100]\ttraining's rmse: 3.42023\tvalid_1's rmse: 495.012\n",
      "[7200]\ttraining's rmse: 3.30764\tvalid_1's rmse: 495.007\n",
      "[7300]\ttraining's rmse: 3.20209\tvalid_1's rmse: 495.003\n",
      "[7400]\ttraining's rmse: 3.09832\tvalid_1's rmse: 495.009\n",
      "[7500]\ttraining's rmse: 3.00537\tvalid_1's rmse: 494.999\n",
      "[7600]\ttraining's rmse: 2.91187\tvalid_1's rmse: 494.999\n",
      "[7700]\ttraining's rmse: 2.82516\tvalid_1's rmse: 494.994\n",
      "[7800]\ttraining's rmse: 2.74464\tvalid_1's rmse: 494.99\n",
      "[7900]\ttraining's rmse: 2.66056\tvalid_1's rmse: 494.986\n",
      "[8000]\ttraining's rmse: 2.58669\tvalid_1's rmse: 494.98\n",
      "[8100]\ttraining's rmse: 2.51022\tvalid_1's rmse: 494.979\n",
      "[8200]\ttraining's rmse: 2.4412\tvalid_1's rmse: 494.982\n",
      "[8300]\ttraining's rmse: 2.37398\tvalid_1's rmse: 494.977\n",
      "[8400]\ttraining's rmse: 2.31385\tvalid_1's rmse: 494.978\n",
      "[8500]\ttraining's rmse: 2.25442\tvalid_1's rmse: 494.974\n",
      "[8600]\ttraining's rmse: 2.19413\tvalid_1's rmse: 494.974\n",
      "[8700]\ttraining's rmse: 2.13894\tvalid_1's rmse: 494.975\n",
      "[8800]\ttraining's rmse: 2.08198\tvalid_1's rmse: 494.969\n",
      "[8900]\ttraining's rmse: 2.0325\tvalid_1's rmse: 494.97\n",
      "[9000]\ttraining's rmse: 1.98407\tvalid_1's rmse: 494.969\n",
      "[9100]\ttraining's rmse: 1.93046\tvalid_1's rmse: 494.972\n",
      "[9200]\ttraining's rmse: 1.87977\tvalid_1's rmse: 494.967\n",
      "[9300]\ttraining's rmse: 1.83488\tvalid_1's rmse: 494.966\n",
      "[9400]\ttraining's rmse: 1.79455\tvalid_1's rmse: 494.963\n",
      "[9500]\ttraining's rmse: 1.75421\tvalid_1's rmse: 494.962\n",
      "[9600]\ttraining's rmse: 1.71396\tvalid_1's rmse: 494.959\n",
      "[9700]\ttraining's rmse: 1.67561\tvalid_1's rmse: 494.96\n",
      "[9800]\ttraining's rmse: 1.63764\tvalid_1's rmse: 494.959\n",
      "[9900]\ttraining's rmse: 1.5999\tvalid_1's rmse: 494.959\n",
      "[10000]\ttraining's rmse: 1.56737\tvalid_1's rmse: 494.959\n",
      "[10100]\ttraining's rmse: 1.53169\tvalid_1's rmse: 494.959\n",
      "[10200]\ttraining's rmse: 1.49931\tvalid_1's rmse: 494.958\n",
      "[10300]\ttraining's rmse: 1.46946\tvalid_1's rmse: 494.956\n",
      "[10400]\ttraining's rmse: 1.43682\tvalid_1's rmse: 494.954\n",
      "[10500]\ttraining's rmse: 1.4111\tvalid_1's rmse: 494.956\n",
      "[10600]\ttraining's rmse: 1.38178\tvalid_1's rmse: 494.956\n",
      "[10700]\ttraining's rmse: 1.35223\tvalid_1's rmse: 494.953\n",
      "[10800]\ttraining's rmse: 1.32597\tvalid_1's rmse: 494.949\n",
      "[10900]\ttraining's rmse: 1.30148\tvalid_1's rmse: 494.95\n",
      "[11000]\ttraining's rmse: 1.27767\tvalid_1's rmse: 494.951\n",
      "[11100]\ttraining's rmse: 1.25033\tvalid_1's rmse: 494.951\n",
      "[11200]\ttraining's rmse: 1.22774\tvalid_1's rmse: 494.952\n",
      "[11300]\ttraining's rmse: 1.20359\tvalid_1's rmse: 494.953\n",
      "Early stopping, best iteration is:\n",
      "[10802]\ttraining's rmse: 1.32556\tvalid_1's rmse: 494.948\n",
      "fold n°9\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\ttraining's rmse: 523.781\tvalid_1's rmse: 718.454\n",
      "[200]\ttraining's rmse: 326.17\tvalid_1's rmse: 572.869\n",
      "[300]\ttraining's rmse: 245.712\tvalid_1's rmse: 528.365\n",
      "[400]\ttraining's rmse: 198.79\tvalid_1's rmse: 508.345\n",
      "[500]\ttraining's rmse: 167.223\tvalid_1's rmse: 499.104\n",
      "[600]\ttraining's rmse: 144.594\tvalid_1's rmse: 493.96\n",
      "[700]\ttraining's rmse: 126.899\tvalid_1's rmse: 488.519\n",
      "[800]\ttraining's rmse: 112.503\tvalid_1's rmse: 485.283\n",
      "[900]\ttraining's rmse: 101.303\tvalid_1's rmse: 482.55\n",
      "[1000]\ttraining's rmse: 91.3388\tvalid_1's rmse: 480.468\n",
      "[1100]\ttraining's rmse: 83.0436\tvalid_1's rmse: 479.645\n",
      "[1200]\ttraining's rmse: 76.1213\tvalid_1's rmse: 478.814\n",
      "[1300]\ttraining's rmse: 70.0195\tvalid_1's rmse: 477.927\n",
      "[1400]\ttraining's rmse: 64.475\tvalid_1's rmse: 477.139\n",
      "[1500]\ttraining's rmse: 59.3996\tvalid_1's rmse: 476.457\n",
      "[1600]\ttraining's rmse: 55.1632\tvalid_1's rmse: 476.15\n",
      "[1700]\ttraining's rmse: 51.1911\tvalid_1's rmse: 475.801\n",
      "[1800]\ttraining's rmse: 47.639\tvalid_1's rmse: 475.271\n",
      "[1900]\ttraining's rmse: 44.3532\tvalid_1's rmse: 475.007\n",
      "[2000]\ttraining's rmse: 41.4393\tvalid_1's rmse: 474.755\n",
      "[2100]\ttraining's rmse: 38.7067\tvalid_1's rmse: 474.64\n",
      "[2200]\ttraining's rmse: 36.3036\tvalid_1's rmse: 474.495\n",
      "[2300]\ttraining's rmse: 34.0784\tvalid_1's rmse: 474.31\n",
      "[2400]\ttraining's rmse: 32.0572\tvalid_1's rmse: 474.145\n",
      "[2500]\ttraining's rmse: 30.1776\tvalid_1's rmse: 474.167\n",
      "[2600]\ttraining's rmse: 28.3118\tvalid_1's rmse: 474.154\n",
      "[2700]\ttraining's rmse: 26.6454\tvalid_1's rmse: 474.106\n",
      "[2800]\ttraining's rmse: 25.0472\tvalid_1's rmse: 473.974\n",
      "[2900]\ttraining's rmse: 23.6212\tvalid_1's rmse: 473.956\n",
      "[3000]\ttraining's rmse: 22.2723\tvalid_1's rmse: 473.958\n",
      "[3100]\ttraining's rmse: 20.9485\tvalid_1's rmse: 473.897\n",
      "[3200]\ttraining's rmse: 19.8175\tvalid_1's rmse: 473.885\n",
      "[3300]\ttraining's rmse: 18.6665\tvalid_1's rmse: 473.793\n",
      "[3400]\ttraining's rmse: 17.6487\tvalid_1's rmse: 473.705\n",
      "[3500]\ttraining's rmse: 16.7721\tvalid_1's rmse: 473.683\n",
      "[3600]\ttraining's rmse: 15.9152\tvalid_1's rmse: 473.648\n",
      "[3700]\ttraining's rmse: 15.1026\tvalid_1's rmse: 473.674\n",
      "[3800]\ttraining's rmse: 14.3636\tvalid_1's rmse: 473.688\n",
      "[3900]\ttraining's rmse: 13.6183\tvalid_1's rmse: 473.677\n",
      "[4000]\ttraining's rmse: 12.8998\tvalid_1's rmse: 473.675\n",
      "Early stopping, best iteration is:\n",
      "[3593]\ttraining's rmse: 15.9619\tvalid_1's rmse: 473.636\n",
      "CV score: 504.60666\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import time\n",
    "\n",
    "features = [c for c in train_df.columns if c not in ['close']]\n",
    "target = train_df['close']\n",
    "\n",
    "folds = KFold(n_splits=10, shuffle=True, random_state=15)\n",
    "oof_lgb = np.zeros(len(train_df))\n",
    "predictions_lgb = np.zeros(len(test_df))\n",
    "start = time.time()\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "\n",
    "    num_round = 50000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 500)\n",
    "    oof_lgb[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    predictions_lgb += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "oof_lgb[oof_lgb < 0] = 0\n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof_lgb, target)**0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Osuntoki\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "sub= ttest[[\"id\"]]\n",
    "sub['Target'] = predictions_lgb\n",
    "sub.to_csv('postchallengeLt.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip uninstall matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib==3.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data.profile_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SampleSubmission.csv')\n",
    "df['Target'] = np.mean(test_pred, axis = 0)\n",
    "df.to_csv('CatC.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_323Sn2</td>\n",
       "      <td>8.668695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_325SNW</td>\n",
       "      <td>8.668695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_325uzE</td>\n",
       "      <td>8.668695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_328qCx</td>\n",
       "      <td>8.668695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_3293uJ</td>\n",
       "      <td>8.668695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>ID_zufSPk</td>\n",
       "      <td>8.668695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218</th>\n",
       "      <td>ID_zuz9yf</td>\n",
       "      <td>8.668695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>ID_zvrMSX</td>\n",
       "      <td>8.668695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>ID_zy9Cfv</td>\n",
       "      <td>8.668695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <td>ID_zyAFd7</td>\n",
       "      <td>8.668695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6222 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id    Target\n",
       "0     ID_323Sn2  8.668695\n",
       "1     ID_325SNW  8.668695\n",
       "2     ID_325uzE  8.668695\n",
       "3     ID_328qCx  8.668695\n",
       "4     ID_3293uJ  8.668695\n",
       "...         ...       ...\n",
       "6217  ID_zufSPk  8.668695\n",
       "6218  ID_zuz9yf  8.668695\n",
       "6219  ID_zvrMSX  8.668695\n",
       "6220  ID_zy9Cfv  8.668695\n",
       "6221  ID_zyAFd7  8.668695\n",
       "\n",
       "[6222 rows x 2 columns]"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "model = CatBoostRegressor(random_state=44,\n",
    "                                 thread_count=4,\n",
    "                                 verbose=False,\n",
    "                                 loss_function='RMSE',\n",
    "                                 eval_metric='RMSE',\n",
    "                                 od_type=\"Iter\",\n",
    "                                 early_stopping_rounds=500,\n",
    "                                 iterations=10000,\n",
    "                                 task_type=\"CPU\")\n",
    "model.fit(X,y, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
