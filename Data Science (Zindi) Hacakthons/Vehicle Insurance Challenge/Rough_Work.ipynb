{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import datetime as dt\n",
    "import sklearn.linear_model as linear_model\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import skew,norm  # for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import  GradientBoostingClassifier,RandomForestClassifier\n",
    "\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.linear_model import  LinearRegression, Ridge\n",
    "import os, gc, warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrain = pd.read_csv('Train.csv')\n",
    "ttest = pd.read_csv('Test.csv')\n",
    "submission = pd.read_csv(\"SampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data = pd.concat([ttrain,ttest]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data.drop(['ID','LGA_Name'], axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "for i in fin_data.columns:\n",
    "    kd = fin_data[i].isna().sum()\n",
    "    ml = len(fin_data[i])\n",
    "    jd = kd/ml * 100\n",
    "    \n",
    "    \n",
    "    if jd > 70:\n",
    "        fin_data.drop(i, axis = 1, inplace = True)\n",
    "        list.append(i)\n",
    "        \n",
    "        \n",
    "        \"\"\" Dropping fetaures with missing values greater than 70% \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      8356\n",
       "Female    3679\n",
       "Other      546\n",
       "Entity     300\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 854,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper = {'Joint Gender':'Other', 'NOT STATED':'Other', 'NO GENDER': 'Other', 'SEX':\"Other\"}\n",
    "fin_data.Gender = fin_data.Gender.replace(mapper)\n",
    "\n",
    "# Confirm mappings\n",
    "fin_data.Gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Geo1    4377\n",
       "Geo4    1083\n",
       "Geo3     451\n",
       "Geo2     164\n",
       "Geo5      57\n",
       "Geo6       4\n",
       "None       1\n",
       "Name: State, dtype: int64"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Mapping  by geopolitical zones\n",
    "\n",
    "mapper = {'Ibeju-Lekki':'Geo1','Oshodi-Isolo':'Geo1','ABULE-EGBA':'Geo1','AJAO-ESTATE':'Geo1','Orile-Iganmu':'Geo1',\n",
    "          'Ajeromi-Ifelodun':'Geo1','Ifako-Ijaye':'Geo1','Amuwo-Odofin':'Geo1','Eti-Osa':'Geo1','Ajegunle-State':'Geo1',\n",
    "          'Ibadan-East':'Geo1','Ibadan-West':'Geo1', 'Ibadan-North':'Geo1','Oyo-East':'Geo1','Oyo':'Geo1',\n",
    "          'Ogbmosho-South':'Geo1','Oyo-West':'Geo1', 'Lagelu-North':'Geo1','Ibarapa-Central':'Geo1','Lagos':'Geo1',\n",
    "          'Ife-Central':'Geo1', 'Ife-North':'Geo1','Ilesha-West':'Geo1','Ilesha-East':'Geo1','Osun':'Geo1',\n",
    "          'Ile-Oluji':'Geo1','Ondo_West':'Geo1','Ondo':'Geo1',\n",
    "          'Obafemi-Owode':'Geo1','Ogun-Waterside':'Geo1','Ogun-Waterside':'Geo1','Ijebu-North':'Geo1','Ijebu-Ode':'Geo1',\n",
    "          'Ijebu-East':'Geo1', 'Ado-Ota':'Geo1', 'Ogun':'Geo1',\n",
    "          'Ado-Ekiti':'Geo1', 'Ekiti-East':'Geo1','Akoko-West':'Geo1','Ondo-West':'Geo1','Ekiti-West':'Geo1',\n",
    "          \n",
    "          \n",
    "          'Onitsha-North':'Geo2', 'Onitsha-South':'Geo2','Anambra-East':'Geo2','Awka-North':'Geo2',\n",
    "          'Awka-South':'Geo2','Idemili-south':'Geo2','Nnewi-South':'Geo2','Idemili-North':'Geo2','Anambra':'Geo2',\n",
    "          'Ngor-Okpala':'Geo2','Owerri-North':'Geo2','Owerri-West':'Geo2','Owerri-Municipal':'Geo2',\n",
    "          'Owerri-West':'Geo2','Imo':'Geo2','Aboh-Mbaise':'Geo2',\n",
    "          'Umuahia-South':'Geo2', 'Aba-North':'Geo2','Aba-South':'Geo2','Abia':'Geo2','Udi-Agwu':'Geo2',\n",
    "          'Enugu-North':'Geo2','ENUGU-EAST':'Geo2','ENUGU-SOUTH':'Geo2','Nnewi-North':'Geo2','Ebonyi':'Geo2',\n",
    "          \n",
    "          \n",
    "          'Essien-Udim':'Geo3','Nsit-Ubium':'Geo3','Akwa-Ibom':'Geo3',\n",
    "          'Obia-Akpor':'Geo3','Port-Harcourt':'Geo3','Asari-Toru':'Geo3','Calabar-Municipality':'Geo3',\n",
    "          'Rivers':'Geo3','Cross-River':'Geo3', 'Ovia-SouthWest':'Geo3','Ogba-Ndoni':'Geo3',\n",
    "          'Warri':'Geo3','Warri-Central':'Geo3','Warri-South':'Geo3','Oshimili-North':'Geo3',\n",
    "          'Ethiope-East':'Geo3','Ughelli-North':'Geo3', 'Ndokwa-East':'Geo3','Isoko-south':'Geo3',\n",
    "          'Isoko-North':'Geo3','Warri-North':'Geo3','Delta':'Geo3','Esan-Central':'Geo3','Aniocha-South':'Geo3',\n",
    "          'Bayelsa':'Geo3','Esan-West':'Geo3','Edo':'Geo3','Etsako-West':'Geo3',\n",
    "          \n",
    "          \n",
    "          'Abuja-Municipal':'Geo4','Central-Abuja':'Geo4','Abuja':'Geo4','QuaAn-Pan':'Geo4',\n",
    "          'Ilorin-West':'Geo4','Ilorin-East':'Geo4','Kwara':'Geo4','Benue':'Geo4','Nasarawa':'Geo4','Kogi':'Geo4',\n",
    "          'Niger':'Geo4','Jos-North':'Geo4','Jos-South':'Geo4','Niger-State':'Geo4',\n",
    "          \n",
    "          \n",
    "          'Kaduna-South':'Geo5','Kaduna':'Geo5','Kano':'Geo5','Kaduna-North':'Geo5','Kano-Municipal':'Geo5','Kebbi':'Geo5',\n",
    "          \n",
    "          \n",
    "          'Bauchi':'Geo6','Gombe':'Geo6',\n",
    "          \n",
    "          \n",
    "          'N-A':'None'}\n",
    "\n",
    "fin_data.State = fin_data.State.replace(mapper)\n",
    "\n",
    "# Confirm mappings\n",
    "fin_data.State.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill(col):\n",
    "    for i in col:\n",
    "        #fin_data[i].fillna(fin_data[i].mode()[0], inplace = True)\n",
    "        #fin_data[i].astype(str)\n",
    "        fin_data[i].fillna('None', inplace = True)\n",
    "        \n",
    "        \"\"\" Filling up the remaining features with a very large number \"\"\"\n",
    "        \n",
    "        #fin_data[i].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill(fin_data.drop([\"target\",\"State\",'Car_Category'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data[\"State\"].fillna('None', inplace = True)\n",
    "fin_data[\"Car_Category\"].fillna('None', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcol = [col for col in fin_data.columns if 'Date' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in dcol:\n",
    "    fin_data[col] = pd.to_datetime(fin_data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Policy Start Date</th>\n",
       "      <th>Policy End Date</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>First Transaction Date</th>\n",
       "      <th>No_Pol</th>\n",
       "      <th>Car_Category</th>\n",
       "      <th>Subject_Car_Colour</th>\n",
       "      <th>Subject_Car_Make</th>\n",
       "      <th>State</th>\n",
       "      <th>...</th>\n",
       "      <th>target</th>\n",
       "      <th>Policy Start Dateyear</th>\n",
       "      <th>Policy Start Datemonth</th>\n",
       "      <th>Policy Start Dateday</th>\n",
       "      <th>Policy End Dateyear</th>\n",
       "      <th>Policy End Datemonth</th>\n",
       "      <th>Policy End Dateday</th>\n",
       "      <th>First Transaction Dateyear</th>\n",
       "      <th>First Transaction Datemonth</th>\n",
       "      <th>First Transaction Dateday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-05-14</td>\n",
       "      <td>2011-05-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>30</td>\n",
       "      <td>2010-05-14</td>\n",
       "      <td>1</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>Black</td>\n",
       "      <td>TOYOTA</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-11-29</td>\n",
       "      <td>2011-11-28</td>\n",
       "      <td>Female</td>\n",
       "      <td>79</td>\n",
       "      <td>2010-11-29</td>\n",
       "      <td>1</td>\n",
       "      <td>JEEP</td>\n",
       "      <td>Grey</td>\n",
       "      <td>TOYOTA</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-03-21</td>\n",
       "      <td>2011-03-20</td>\n",
       "      <td>Male</td>\n",
       "      <td>43</td>\n",
       "      <td>2010-03-21</td>\n",
       "      <td>1</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>Red</td>\n",
       "      <td>TOYOTA</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-08-21</td>\n",
       "      <td>2011-08-20</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-08-21</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-08-29</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>Entity</td>\n",
       "      <td>20</td>\n",
       "      <td>2010-08-29</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Geo1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Policy Start Date Policy End Date  Gender  Age First Transaction Date  \\\n",
       "0        2010-05-14      2011-05-13    Male   30             2010-05-14   \n",
       "1        2010-11-29      2011-11-28  Female   79             2010-11-29   \n",
       "2        2010-03-21      2011-03-20    Male   43             2010-03-21   \n",
       "3        2010-08-21      2011-08-20    Male    2             2010-08-21   \n",
       "4        2010-08-29      2010-12-31  Entity   20             2010-08-29   \n",
       "\n",
       "   No_Pol Car_Category Subject_Car_Colour Subject_Car_Make State  ... target  \\\n",
       "0       1       Saloon              Black           TOYOTA  None  ...    0.0   \n",
       "1       1         JEEP               Grey           TOYOTA  None  ...    1.0   \n",
       "2       1       Saloon                Red           TOYOTA  None  ...    0.0   \n",
       "3       1         None               None             None  None  ...    0.0   \n",
       "4       3         None               None             None  Geo1  ...    1.0   \n",
       "\n",
       "   Policy Start Dateyear  Policy Start Datemonth  Policy Start Dateday  \\\n",
       "0                   2010                       5                    14   \n",
       "1                   2010                      11                    29   \n",
       "2                   2010                       3                    21   \n",
       "3                   2010                       8                    21   \n",
       "4                   2010                       8                    29   \n",
       "\n",
       "   Policy End Dateyear  Policy End Datemonth  Policy End Dateday  \\\n",
       "0                 2011                     5                  13   \n",
       "1                 2011                    11                  28   \n",
       "2                 2011                     3                  20   \n",
       "3                 2011                     8                  20   \n",
       "4                 2010                    12                  31   \n",
       "\n",
       "   First Transaction Dateyear  First Transaction Datemonth  \\\n",
       "0                        2010                            5   \n",
       "1                        2010                           11   \n",
       "2                        2010                            3   \n",
       "3                        2010                            8   \n",
       "4                        2010                            8   \n",
       "\n",
       "   First Transaction Dateday  \n",
       "0                         14  \n",
       "1                         29  \n",
       "2                         21  \n",
       "3                         21  \n",
       "4                         29  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 861,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in dcol:\n",
    "  for date_feature in ['year', 'month', 'day']:\n",
    "    fin_data[col+date_feature] = getattr(fin_data[col].dt, date_feature)\n",
    "\n",
    "fin_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data[\"Policy_Month_Diff\"] = abs(fin_data['Policy End Datemonth'] - fin_data['Policy Start Datemonth'])\n",
    "fin_data['Policy_Day_Diff'] = abs(fin_data['Policy End Date'] - fin_data['Policy Start Date']).dt.days\n",
    "fin_data['Policy_Week_Diff'] = abs(round(fin_data['Policy_Day_Diff']/7, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data.drop(['Policy Start Date','Policy End Date','First Transaction Date'], axis =1, inplace = True)\n",
    "fin_data.drop(['Policy Start Dateyear','Policy End Dateyear','First Transaction Dateyear'], axis =1, inplace = True)\n",
    "fin_data.drop(['First Transaction Datemonth'], axis =1, inplace = True)\n",
    "fin_data.drop(['First Transaction Dateday'], axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data.drop(['Policy_Day_Diff'], axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop policy end date day and policy end datemonth since we have taken the difference already\n",
    "fin_data.drop(['Policy End Dateday','Policy End Datemonth'], axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "listt = []\n",
    "for i in range(len(fin_data['Age'])):\n",
    "    if fin_data['Age'][i] < 0:\n",
    "        fin_data['Age'][i] = abs(fin_data['Age'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  30,   79,   43,    2,   20,   37,   40,   71,   58,   45,   51,\n",
       "        120,   38,   81,   69,   31,   70,   34,    1,   41,   47,   36,\n",
       "         46,   48,   39,   63,   42,   27,   64,   50,   53,   33,   23,\n",
       "         32,   59,   60,   52,   54,   44,   11,   78,   28,   29,   57,\n",
       "         12,   65,   35,   73,   56,   55,   26,   49,   18,   14,   62,\n",
       "         25,   61,   72,   82,   67,    7,   10,   68,   21,   76,   24,\n",
       "         66,    3,   93,   22,   77,   19,   80,    9,    6,   89,   74,\n",
       "         75,   84,   16,   90,  140,    8,    5,   13,   86,   15,  320,\n",
       "         83,   85, 6099, 5939,    4,  144,  112,   17,    0,   88,   87,\n",
       "        133,  102,  128,  100], dtype=int64)"
      ]
     },
     "execution_count": 867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data['Age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data['Age'][fin_data['Age']==6099] = fin_data['Age'].mode()[0]\n",
    "fin_data['Age'][fin_data['Age']==5939] = fin_data['Age'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Age, dtype: int64)"
      ]
     },
     "execution_count": 869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data['Age'][fin_data['Age']==6099]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skewness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Policy_Week_Diff</th>\n",
       "      <td>44.518024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No_Pol</th>\n",
       "      <td>3.772737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>3.278167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Policy_Month_Diff</th>\n",
       "      <td>3.210912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Policy Start Datemonth</th>\n",
       "      <td>0.030754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Policy Start Dateday</th>\n",
       "      <td>-0.047862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Skewness\n",
       "Policy_Week_Diff        44.518024\n",
       "No_Pol                   3.772737\n",
       "Age                      3.278167\n",
       "Policy_Month_Diff        3.210912\n",
       "Policy Start Datemonth   0.030754\n",
       "Policy Start Dateday    -0.047862"
      ]
     },
     "execution_count": 870,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical = fin_data.drop(['target'], axis =1).dtypes[fin_data.drop(['target'], axis =1).dtypes != 'object'].index\n",
    "\n",
    "skewness = fin_data.drop(['target'], axis =1)[numerical].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "\n",
    "skewness_df = pd.DataFrame({'Skewness': skewness})\n",
    "skewness_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import boxcox1p\n",
    "\n",
    "boxcox_features = skewness_df[np.abs(skewness_df['Skewness'])>0.75].index\n",
    "lam = 0.25\n",
    "\n",
    "for col in boxcox_features:\n",
    "    fin_data.loc[:, col] = boxcox1p(fin_data[col], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skewness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Policy_Month_Diff</th>\n",
       "      <td>2.623812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No_Pol</th>\n",
       "      <td>2.484713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Policy_Week_Diff</th>\n",
       "      <td>0.550963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Policy Start Datemonth</th>\n",
       "      <td>0.030754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Policy Start Dateday</th>\n",
       "      <td>-0.047862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-1.356334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Skewness\n",
       "Policy_Month_Diff       2.623812\n",
       "No_Pol                  2.484713\n",
       "Policy_Week_Diff        0.550963\n",
       "Policy Start Datemonth  0.030754\n",
       "Policy Start Dateday   -0.047862\n",
       "Age                    -1.356334"
      ]
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical = fin_data.drop(['target'], axis =1).dtypes[fin_data.drop(['target'], axis =1).dtypes != 'object'].index\n",
    "\n",
    "skewness = fin_data.drop(['target'], axis =1)[numerical].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "\n",
    "skewness_df = pd.DataFrame({'Skewness': skewness})\n",
    "skewness_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data.drop(['Subject_Car_Colour'], axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data.drop(['Subject_Car_Make'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Saloon    6633\n",
       "None      4110\n",
       "JEEP      2223\n",
       "Other      315\n",
       "Name: Car_Category, dtype: int64"
      ]
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Regrouping the Car_Category feature\"\"\"\n",
    "\n",
    "mapper = {'Mini Van':'Other','Pick Up':'Other','Sedan':'Other','Mini Van':'Other',\n",
    "          'Tipper Truck':'Other',\"Van\":'Other',\"Bus\":'Other',\"Truck\":\"Other\",\n",
    "         \"Mini Bus\":'Other', \"Wagon\": 'Other',\"Shape Of Vehicle Chasis\":'Other', \n",
    "         \"Station 4 Wheel\": 'Other', \"Pick Up > 3 Tons\": 'Other', \"CAMRY CAR HIRE\": 'Other',\"Motorcycle\": 'Other'}\n",
    "fin_data.Car_Category = fin_data.Car_Category.replace(mapper)\n",
    "\n",
    "# Confirm mappings\n",
    "fin_data.Car_Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Saloon    6633\n",
       "Other     4425\n",
       "JEEP      2223\n",
       "Name: Car_Category, dtype: int64"
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## intution: join the \"other\" and \"none\" category together\n",
    "\n",
    "mapper = {\"None\": 'Other'}\n",
    "fin_data.Car_Category = fin_data.Car_Category.replace(mapper)\n",
    "\n",
    "# Confirm mappings\n",
    "fin_data.Car_Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Car Classic         7147\n",
       "CarSafe             4154\n",
       "Customized Motor     654\n",
       "Car Plus             523\n",
       "CVTP                 509\n",
       "CarFlex              194\n",
       "Muuve                100\n",
       "Name: ProductName, dtype: int64"
      ]
     },
     "execution_count": 877,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper = {\"Car Vintage\": 'Car Classic',\"Motor Cycle\": \"Customized Motor\"}\n",
    "fin_data.ProductName = fin_data.ProductName.replace(mapper)\n",
    "\n",
    "# Confirm mappings\n",
    "fin_data.ProductName.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Car Classic    7147\n",
       "CarSafe        4154\n",
       "Other          1980\n",
       "Name: ProductName, dtype: int64"
      ]
     },
     "execution_count": 878,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper = {\"CVTP\": 'Other',\"CarFlex\": \"Other\",\"Muuve\": \"Other\",\"Car Plus\": \"Other\",\"Customized Motor\":\"Other\"}\n",
    "fin_data.ProductName = fin_data.ProductName.replace(mapper)\n",
    "\n",
    "# Confirm mappings\n",
    "fin_data.ProductName.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "import pandas as pd\n",
    "# Create new features\n",
    "#fin_data['ProductName'] = le.fit_transform(fin_data['ProductName'])\n",
    "#fin_data['Car_Category'] = le.fit_transform(fin_data['Car_Category'])\n",
    "#fin_data['State'] = le.fit_transform(fin_data['State'])\n",
    "#fin_data['Gender'] = le.fit_transform(fin_data['State'])\n",
    "\n",
    "fin_data = pd.get_dummies(fin_data, columns=['Gender'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data = pd.get_dummies(fin_data, columns=['ProductName'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>No_Pol</th>\n",
       "      <th>Car_Category</th>\n",
       "      <th>State</th>\n",
       "      <th>target</th>\n",
       "      <th>Policy Start Datemonth</th>\n",
       "      <th>Policy Start Dateday</th>\n",
       "      <th>Policy_Month_Diff</th>\n",
       "      <th>Policy_Week_Diff</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Gender_None</th>\n",
       "      <th>Gender_Other</th>\n",
       "      <th>ProductName_CarSafe</th>\n",
       "      <th>ProductName_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.438444</td>\n",
       "      <td>0.756828</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.792672</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.962790</td>\n",
       "      <td>0.756828</td>\n",
       "      <td>JEEP</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.792672</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.302038</td>\n",
       "      <td>0.756828</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.792672</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.264296</td>\n",
       "      <td>0.756828</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.792672</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.562781</td>\n",
       "      <td>1.656854</td>\n",
       "      <td>Other</td>\n",
       "      <td>Geo1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>1.981395</td>\n",
       "      <td>4.351191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13276</th>\n",
       "      <td>7.486487</td>\n",
       "      <td>1.264296</td>\n",
       "      <td>JEEP</td>\n",
       "      <td>Geo1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.792672</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13277</th>\n",
       "      <td>6.302038</td>\n",
       "      <td>0.756828</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>Geo1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.792672</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13278</th>\n",
       "      <td>5.438444</td>\n",
       "      <td>0.756828</td>\n",
       "      <td>Other</td>\n",
       "      <td>Geo1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.792672</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13279</th>\n",
       "      <td>6.360080</td>\n",
       "      <td>1.264296</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>Geo2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.792672</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13280</th>\n",
       "      <td>5.282383</td>\n",
       "      <td>0.756828</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.792672</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13281 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age    No_Pol Car_Category State  target  Policy Start Datemonth  \\\n",
       "0      5.438444  0.756828       Saloon  None     0.0                       5   \n",
       "1      7.962790  0.756828         JEEP  None     1.0                      11   \n",
       "2      6.302038  0.756828       Saloon  None     0.0                       3   \n",
       "3      1.264296  0.756828        Other  None     0.0                       8   \n",
       "4      4.562781  1.656854        Other  Geo1     1.0                       8   \n",
       "...         ...       ...          ...   ...     ...                     ...   \n",
       "13276  7.486487  1.264296         JEEP  Geo1     NaN                      12   \n",
       "13277  6.302038  0.756828       Saloon  Geo1     NaN                       1   \n",
       "13278  5.438444  0.756828        Other  Geo1     NaN                       7   \n",
       "13279  6.360080  1.264296       Saloon  Geo2     NaN                       2   \n",
       "13280  5.282383  0.756828       Saloon  None     NaN                       3   \n",
       "\n",
       "       Policy Start Dateday  Policy_Month_Diff  Policy_Week_Diff  \\\n",
       "0                        14           0.000000          6.792672   \n",
       "1                        29           0.000000          6.792672   \n",
       "2                        21           0.000000          6.792672   \n",
       "3                        21           0.000000          6.792672   \n",
       "4                        29           1.981395          4.351191   \n",
       "...                     ...                ...               ...   \n",
       "13276                     5           0.000000          6.792672   \n",
       "13277                    14           0.000000          6.792672   \n",
       "13278                    26           0.000000          6.792672   \n",
       "13279                    16           0.000000          6.792672   \n",
       "13280                    18           0.000000          6.792672   \n",
       "\n",
       "       Gender_Female  Gender_Male  Gender_None  Gender_Other  \\\n",
       "0                  0            1            0             0   \n",
       "1                  1            0            0             0   \n",
       "2                  0            1            0             0   \n",
       "3                  0            1            0             0   \n",
       "4                  0            0            0             0   \n",
       "...              ...          ...          ...           ...   \n",
       "13276              0            1            0             0   \n",
       "13277              0            1            0             0   \n",
       "13278              0            1            0             0   \n",
       "13279              0            1            0             0   \n",
       "13280              0            1            0             0   \n",
       "\n",
       "       ProductName_CarSafe  ProductName_Other  \n",
       "0                        0                  0  \n",
       "1                        0                  0  \n",
       "2                        0                  0  \n",
       "3                        1                  0  \n",
       "4                        0                  1  \n",
       "...                    ...                ...  \n",
       "13276                    0                  0  \n",
       "13277                    0                  0  \n",
       "13278                    0                  1  \n",
       "13279                    0                  0  \n",
       "13280                    0                  0  \n",
       "\n",
       "[13281 rows x 15 columns]"
      ]
     },
     "execution_count": 881,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fin_data.drop(['Policy_Month_Diff'], axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits = 8, shuffle = True, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "split=ttrain.shape[0]\n",
    "train_df=fin_data[:split]\n",
    "test_df=fin_data[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mean_target_encoding(train, test, target, categorical, alpha=5):\n",
    "    # Calculate global mean on the train data\n",
    "    global_mean = train[target].mean()\n",
    "    \n",
    "    # Group by the categorical feature and calculate its properties\n",
    "    train_groups = train.groupby(categorical)\n",
    "    category_sum = train_groups[target].sum()\n",
    "    category_size = train_groups.size()\n",
    "    \n",
    "    # Calculate smoothed mean target statistics\n",
    "    train_statistics = (category_sum + global_mean * alpha) / (category_size + alpha)\n",
    "    \n",
    "    # Apply statistics to the test data and fill new categories\n",
    "    test_feature = test[categorical].map(train_statistics).fillna(global_mean)\n",
    "    return test_feature.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mean_target_encoding(train, target, categorical, alpha=5):\n",
    "    # Create 5-fold cross-validation\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state=99)\n",
    "    train_feature = pd.Series(index=train.index)\n",
    "    \n",
    "    # For each folds split\n",
    "    for train_index, test_index in kf.split(train):\n",
    "        cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]\n",
    "      \n",
    "        # Calculate out-of-fold statistics and apply to cv_test\n",
    "        cv_test_feature = test_mean_target_encoding(cv_train, cv_test, target, categorical, alpha)\n",
    "        \n",
    "        # Save new feature for this particular fold\n",
    "        train_feature.iloc[test_index] = cv_test_feature       \n",
    "    return train_feature.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_target_encoding(train, test, target, categorical, alpha=5):\n",
    "  \n",
    "    # Get the train feature\n",
    "    train_feature = train_mean_target_encoding(train, target, categorical, alpha)\n",
    "  \n",
    "    # Get the test feature\n",
    "    test_feature = test_mean_target_encoding(train, test, target, categorical, alpha)\n",
    "    \n",
    "    # Return new features to add to the model\n",
    "    return train_feature, test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat, test_feat = mean_target_encoding(train_df, test_df, 'target', 'Car_Category', alpha=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Car_Category'] = train_feat\n",
    "test_df['Car_Category'] = test_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat2, test_feat2 = mean_target_encoding(train_df, test_df, 'target', 'State', alpha=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['State'] = train_feat2\n",
    "test_df['State'] = test_feat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_feat3, test_feat3 = mean_target_encoding(train_df, test_df, 'target', 'ProductName', alpha=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df['ProductName'] = train_feat3\n",
    "#test_df['ProductName'] = test_feat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_feat4, test_feat4 = mean_target_encoding(train_df, test_df, 'target', 'Gender', alpha=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df['Gender'] = train_feat4\n",
    "#test_df['Gender'] = test_feat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['target'], axis =1)\n",
    "y = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "#ros = RandomOverSampler()\n",
    "#X, y = ros.fit_resample(X, y)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "over = SMOTE(sampling_strategy = 'minority', random_state=7)\n",
    "X, y = over.fit_resample(X, y)\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "#ros = RandomOverSampler()\n",
    "#X, y = ros.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "under = RandomUnderSampler(sampling_strategy=1)\n",
    "\n",
    "# X, y = under.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25,random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.033601\n",
      "0:\tlearn: 0.6643894\ttotal: 12.1ms\tremaining: 12.1s\n",
      "1:\tlearn: 0.6383095\ttotal: 24ms\tremaining: 12s\n",
      "2:\tlearn: 0.6178210\ttotal: 36.6ms\tremaining: 12.2s\n",
      "3:\tlearn: 0.5996998\ttotal: 48.2ms\tremaining: 12s\n",
      "4:\tlearn: 0.5796064\ttotal: 59.6ms\tremaining: 11.9s\n",
      "5:\tlearn: 0.5686583\ttotal: 71.4ms\tremaining: 11.8s\n",
      "6:\tlearn: 0.5532169\ttotal: 82.4ms\tremaining: 11.7s\n",
      "7:\tlearn: 0.5438273\ttotal: 93.6ms\tremaining: 11.6s\n",
      "8:\tlearn: 0.5331225\ttotal: 105ms\tremaining: 11.5s\n",
      "9:\tlearn: 0.5264323\ttotal: 116ms\tremaining: 11.5s\n",
      "10:\tlearn: 0.5197622\ttotal: 127ms\tremaining: 11.4s\n",
      "11:\tlearn: 0.5108591\ttotal: 139ms\tremaining: 11.4s\n",
      "12:\tlearn: 0.5056409\ttotal: 150ms\tremaining: 11.4s\n",
      "13:\tlearn: 0.4982682\ttotal: 162ms\tremaining: 11.4s\n",
      "14:\tlearn: 0.4921231\ttotal: 173ms\tremaining: 11.4s\n",
      "15:\tlearn: 0.4881340\ttotal: 191ms\tremaining: 11.8s\n",
      "16:\tlearn: 0.4845754\ttotal: 205ms\tremaining: 11.9s\n",
      "17:\tlearn: 0.4796624\ttotal: 217ms\tremaining: 11.9s\n",
      "18:\tlearn: 0.4751485\ttotal: 240ms\tremaining: 12.4s\n",
      "19:\tlearn: 0.4710675\ttotal: 253ms\tremaining: 12.4s\n",
      "20:\tlearn: 0.4662870\ttotal: 264ms\tremaining: 12.3s\n",
      "21:\tlearn: 0.4616612\ttotal: 276ms\tremaining: 12.3s\n",
      "22:\tlearn: 0.4550422\ttotal: 288ms\tremaining: 12.2s\n",
      "23:\tlearn: 0.4510727\ttotal: 300ms\tremaining: 12.2s\n",
      "24:\tlearn: 0.4455829\ttotal: 312ms\tremaining: 12.2s\n",
      "25:\tlearn: 0.4406318\ttotal: 324ms\tremaining: 12.1s\n",
      "26:\tlearn: 0.4383954\ttotal: 335ms\tremaining: 12.1s\n",
      "27:\tlearn: 0.4349944\ttotal: 346ms\tremaining: 12s\n",
      "28:\tlearn: 0.4316204\ttotal: 358ms\tremaining: 12s\n",
      "29:\tlearn: 0.4274241\ttotal: 372ms\tremaining: 12s\n",
      "30:\tlearn: 0.4252447\ttotal: 385ms\tremaining: 12s\n",
      "31:\tlearn: 0.4240042\ttotal: 400ms\tremaining: 12.1s\n",
      "32:\tlearn: 0.4212475\ttotal: 412ms\tremaining: 12.1s\n",
      "33:\tlearn: 0.4196654\ttotal: 425ms\tremaining: 12.1s\n",
      "34:\tlearn: 0.4175901\ttotal: 439ms\tremaining: 12.1s\n",
      "35:\tlearn: 0.4138958\ttotal: 451ms\tremaining: 12.1s\n",
      "36:\tlearn: 0.4108471\ttotal: 472ms\tremaining: 12.3s\n",
      "37:\tlearn: 0.4089315\ttotal: 483ms\tremaining: 12.2s\n",
      "38:\tlearn: 0.4073708\ttotal: 494ms\tremaining: 12.2s\n",
      "39:\tlearn: 0.4020513\ttotal: 505ms\tremaining: 12.1s\n",
      "40:\tlearn: 0.4007390\ttotal: 517ms\tremaining: 12.1s\n",
      "41:\tlearn: 0.3983375\ttotal: 528ms\tremaining: 12s\n",
      "42:\tlearn: 0.3965069\ttotal: 541ms\tremaining: 12.1s\n",
      "43:\tlearn: 0.3949087\ttotal: 555ms\tremaining: 12.1s\n",
      "44:\tlearn: 0.3931123\ttotal: 577ms\tremaining: 12.2s\n",
      "45:\tlearn: 0.3917387\ttotal: 589ms\tremaining: 12.2s\n",
      "46:\tlearn: 0.3898184\ttotal: 601ms\tremaining: 12.2s\n",
      "47:\tlearn: 0.3886023\ttotal: 612ms\tremaining: 12.1s\n",
      "48:\tlearn: 0.3859338\ttotal: 623ms\tremaining: 12.1s\n",
      "49:\tlearn: 0.3838037\ttotal: 635ms\tremaining: 12.1s\n",
      "50:\tlearn: 0.3828633\ttotal: 646ms\tremaining: 12s\n",
      "51:\tlearn: 0.3786790\ttotal: 657ms\tremaining: 12s\n",
      "52:\tlearn: 0.3753142\ttotal: 668ms\tremaining: 11.9s\n",
      "53:\tlearn: 0.3714232\ttotal: 679ms\tremaining: 11.9s\n",
      "54:\tlearn: 0.3702436\ttotal: 690ms\tremaining: 11.9s\n",
      "55:\tlearn: 0.3684359\ttotal: 702ms\tremaining: 11.8s\n",
      "56:\tlearn: 0.3662255\ttotal: 713ms\tremaining: 11.8s\n",
      "57:\tlearn: 0.3641110\ttotal: 727ms\tremaining: 11.8s\n",
      "58:\tlearn: 0.3605905\ttotal: 741ms\tremaining: 11.8s\n",
      "59:\tlearn: 0.3593318\ttotal: 753ms\tremaining: 11.8s\n",
      "60:\tlearn: 0.3539892\ttotal: 766ms\tremaining: 11.8s\n",
      "61:\tlearn: 0.3530632\ttotal: 778ms\tremaining: 11.8s\n",
      "62:\tlearn: 0.3523946\ttotal: 792ms\tremaining: 11.8s\n",
      "63:\tlearn: 0.3511781\ttotal: 803ms\tremaining: 11.8s\n",
      "64:\tlearn: 0.3497367\ttotal: 814ms\tremaining: 11.7s\n",
      "65:\tlearn: 0.3490789\ttotal: 826ms\tremaining: 11.7s\n",
      "66:\tlearn: 0.3477955\ttotal: 837ms\tremaining: 11.7s\n",
      "67:\tlearn: 0.3469245\ttotal: 848ms\tremaining: 11.6s\n",
      "68:\tlearn: 0.3456880\ttotal: 867ms\tremaining: 11.7s\n",
      "69:\tlearn: 0.3431269\ttotal: 879ms\tremaining: 11.7s\n",
      "70:\tlearn: 0.3410915\ttotal: 895ms\tremaining: 11.7s\n",
      "71:\tlearn: 0.3402491\ttotal: 910ms\tremaining: 11.7s\n",
      "72:\tlearn: 0.3391797\ttotal: 929ms\tremaining: 11.8s\n",
      "73:\tlearn: 0.3385328\ttotal: 956ms\tremaining: 12s\n",
      "74:\tlearn: 0.3377627\ttotal: 971ms\tremaining: 12s\n",
      "75:\tlearn: 0.3368392\ttotal: 990ms\tremaining: 12s\n",
      "76:\tlearn: 0.3355401\ttotal: 1s\tremaining: 12s\n",
      "77:\tlearn: 0.3344612\ttotal: 1.02s\tremaining: 12.1s\n",
      "78:\tlearn: 0.3337060\ttotal: 1.04s\tremaining: 12.1s\n",
      "79:\tlearn: 0.3317283\ttotal: 1.06s\tremaining: 12.1s\n",
      "80:\tlearn: 0.3297618\ttotal: 1.07s\tremaining: 12.1s\n",
      "81:\tlearn: 0.3272763\ttotal: 1.08s\tremaining: 12.1s\n",
      "82:\tlearn: 0.3267849\ttotal: 1.11s\tremaining: 12.3s\n",
      "83:\tlearn: 0.3255597\ttotal: 1.12s\tremaining: 12.3s\n",
      "84:\tlearn: 0.3237592\ttotal: 1.14s\tremaining: 12.2s\n",
      "85:\tlearn: 0.3226373\ttotal: 1.15s\tremaining: 12.2s\n",
      "86:\tlearn: 0.3216553\ttotal: 1.16s\tremaining: 12.2s\n",
      "87:\tlearn: 0.3207445\ttotal: 1.18s\tremaining: 12.2s\n",
      "88:\tlearn: 0.3201940\ttotal: 1.19s\tremaining: 12.2s\n",
      "89:\tlearn: 0.3196268\ttotal: 1.2s\tremaining: 12.1s\n",
      "90:\tlearn: 0.3187751\ttotal: 1.21s\tremaining: 12.1s\n",
      "91:\tlearn: 0.3174475\ttotal: 1.22s\tremaining: 12.1s\n",
      "92:\tlearn: 0.3157445\ttotal: 1.24s\tremaining: 12.1s\n",
      "93:\tlearn: 0.3151760\ttotal: 1.25s\tremaining: 12.1s\n",
      "94:\tlearn: 0.3144108\ttotal: 1.27s\tremaining: 12.1s\n",
      "95:\tlearn: 0.3131903\ttotal: 1.28s\tremaining: 12.1s\n",
      "96:\tlearn: 0.3127177\ttotal: 1.29s\tremaining: 12s\n",
      "97:\tlearn: 0.3117922\ttotal: 1.3s\tremaining: 12s\n",
      "98:\tlearn: 0.3111042\ttotal: 1.32s\tremaining: 12s\n",
      "99:\tlearn: 0.3100872\ttotal: 1.33s\tremaining: 12s\n",
      "100:\tlearn: 0.3097047\ttotal: 1.34s\tremaining: 11.9s\n",
      "101:\tlearn: 0.3090956\ttotal: 1.36s\tremaining: 11.9s\n",
      "102:\tlearn: 0.3072668\ttotal: 1.38s\tremaining: 12s\n",
      "103:\tlearn: 0.3067654\ttotal: 1.39s\tremaining: 12s\n",
      "104:\tlearn: 0.3043805\ttotal: 1.4s\tremaining: 12s\n",
      "105:\tlearn: 0.3037789\ttotal: 1.42s\tremaining: 12s\n",
      "106:\tlearn: 0.3033094\ttotal: 1.44s\tremaining: 12s\n",
      "107:\tlearn: 0.3028958\ttotal: 1.45s\tremaining: 12s\n",
      "108:\tlearn: 0.3024897\ttotal: 1.47s\tremaining: 12s\n",
      "109:\tlearn: 0.3006967\ttotal: 1.48s\tremaining: 12s\n",
      "110:\tlearn: 0.2998446\ttotal: 1.5s\tremaining: 12s\n",
      "111:\tlearn: 0.2989236\ttotal: 1.52s\tremaining: 12s\n",
      "112:\tlearn: 0.2980164\ttotal: 1.53s\tremaining: 12s\n",
      "113:\tlearn: 0.2968456\ttotal: 1.54s\tremaining: 12s\n",
      "114:\tlearn: 0.2961240\ttotal: 1.56s\tremaining: 12s\n",
      "115:\tlearn: 0.2952628\ttotal: 1.58s\tremaining: 12s\n",
      "116:\tlearn: 0.2947254\ttotal: 1.59s\tremaining: 12s\n",
      "117:\tlearn: 0.2936002\ttotal: 1.61s\tremaining: 12s\n",
      "118:\tlearn: 0.2928914\ttotal: 1.62s\tremaining: 12s\n",
      "119:\tlearn: 0.2924679\ttotal: 1.63s\tremaining: 12s\n",
      "120:\tlearn: 0.2918907\ttotal: 1.65s\tremaining: 12s\n",
      "121:\tlearn: 0.2914093\ttotal: 1.67s\tremaining: 12s\n",
      "122:\tlearn: 0.2908779\ttotal: 1.69s\tremaining: 12s\n",
      "123:\tlearn: 0.2906711\ttotal: 1.7s\tremaining: 12s\n",
      "124:\tlearn: 0.2885169\ttotal: 1.72s\tremaining: 12s\n",
      "125:\tlearn: 0.2881188\ttotal: 1.73s\tremaining: 12s\n",
      "126:\tlearn: 0.2877641\ttotal: 1.75s\tremaining: 12s\n",
      "127:\tlearn: 0.2869845\ttotal: 1.76s\tremaining: 12s\n",
      "128:\tlearn: 0.2865336\ttotal: 1.77s\tremaining: 12s\n",
      "129:\tlearn: 0.2851090\ttotal: 1.79s\tremaining: 12s\n",
      "130:\tlearn: 0.2846120\ttotal: 1.81s\tremaining: 12s\n",
      "131:\tlearn: 0.2839614\ttotal: 1.83s\tremaining: 12s\n",
      "132:\tlearn: 0.2830844\ttotal: 1.84s\tremaining: 12s\n",
      "133:\tlearn: 0.2827492\ttotal: 1.85s\tremaining: 12s\n",
      "134:\tlearn: 0.2822090\ttotal: 1.87s\tremaining: 12s\n",
      "135:\tlearn: 0.2818229\ttotal: 1.89s\tremaining: 12s\n",
      "136:\tlearn: 0.2814677\ttotal: 1.9s\tremaining: 12s\n",
      "137:\tlearn: 0.2811280\ttotal: 1.91s\tremaining: 12s\n",
      "138:\tlearn: 0.2805155\ttotal: 1.93s\tremaining: 12s\n",
      "139:\tlearn: 0.2797309\ttotal: 1.94s\tremaining: 11.9s\n",
      "140:\tlearn: 0.2785473\ttotal: 1.96s\tremaining: 11.9s\n",
      "141:\tlearn: 0.2782676\ttotal: 1.97s\tremaining: 11.9s\n",
      "142:\tlearn: 0.2775924\ttotal: 1.98s\tremaining: 11.9s\n",
      "143:\tlearn: 0.2763880\ttotal: 2s\tremaining: 11.9s\n",
      "144:\tlearn: 0.2761029\ttotal: 2.01s\tremaining: 11.9s\n",
      "145:\tlearn: 0.2757070\ttotal: 2.02s\tremaining: 11.8s\n",
      "146:\tlearn: 0.2754049\ttotal: 2.04s\tremaining: 11.8s\n",
      "147:\tlearn: 0.2749207\ttotal: 2.05s\tremaining: 11.8s\n",
      "148:\tlearn: 0.2743617\ttotal: 2.06s\tremaining: 11.8s\n",
      "149:\tlearn: 0.2736369\ttotal: 2.08s\tremaining: 11.8s\n",
      "150:\tlearn: 0.2733267\ttotal: 2.1s\tremaining: 11.8s\n",
      "151:\tlearn: 0.2730462\ttotal: 2.12s\tremaining: 11.8s\n",
      "152:\tlearn: 0.2727580\ttotal: 2.13s\tremaining: 11.8s\n",
      "153:\tlearn: 0.2711034\ttotal: 2.14s\tremaining: 11.8s\n",
      "154:\tlearn: 0.2703479\ttotal: 2.16s\tremaining: 11.8s\n",
      "155:\tlearn: 0.2689317\ttotal: 2.18s\tremaining: 11.8s\n",
      "156:\tlearn: 0.2686309\ttotal: 2.19s\tremaining: 11.8s\n",
      "157:\tlearn: 0.2683503\ttotal: 2.22s\tremaining: 11.8s\n",
      "158:\tlearn: 0.2680352\ttotal: 2.23s\tremaining: 11.8s\n",
      "159:\tlearn: 0.2676272\ttotal: 2.24s\tremaining: 11.8s\n",
      "160:\tlearn: 0.2673735\ttotal: 2.26s\tremaining: 11.8s\n",
      "161:\tlearn: 0.2666648\ttotal: 2.27s\tremaining: 11.7s\n",
      "162:\tlearn: 0.2662035\ttotal: 2.28s\tremaining: 11.7s\n",
      "163:\tlearn: 0.2659968\ttotal: 2.3s\tremaining: 11.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164:\tlearn: 0.2655242\ttotal: 2.32s\tremaining: 11.7s\n",
      "165:\tlearn: 0.2653550\ttotal: 2.33s\tremaining: 11.7s\n",
      "166:\tlearn: 0.2651216\ttotal: 2.36s\tremaining: 11.8s\n",
      "167:\tlearn: 0.2645755\ttotal: 2.37s\tremaining: 11.7s\n",
      "168:\tlearn: 0.2643694\ttotal: 2.38s\tremaining: 11.7s\n",
      "169:\tlearn: 0.2635545\ttotal: 2.4s\tremaining: 11.7s\n",
      "170:\tlearn: 0.2632990\ttotal: 2.41s\tremaining: 11.7s\n",
      "171:\tlearn: 0.2629461\ttotal: 2.43s\tremaining: 11.7s\n",
      "172:\tlearn: 0.2622751\ttotal: 2.44s\tremaining: 11.7s\n",
      "173:\tlearn: 0.2615472\ttotal: 2.45s\tremaining: 11.7s\n",
      "174:\tlearn: 0.2613872\ttotal: 2.47s\tremaining: 11.7s\n",
      "175:\tlearn: 0.2602747\ttotal: 2.49s\tremaining: 11.7s\n",
      "176:\tlearn: 0.2600655\ttotal: 2.51s\tremaining: 11.7s\n",
      "177:\tlearn: 0.2595238\ttotal: 2.52s\tremaining: 11.6s\n",
      "178:\tlearn: 0.2586678\ttotal: 2.53s\tremaining: 11.6s\n",
      "179:\tlearn: 0.2578927\ttotal: 2.54s\tremaining: 11.6s\n",
      "180:\tlearn: 0.2572591\ttotal: 2.56s\tremaining: 11.6s\n",
      "181:\tlearn: 0.2567722\ttotal: 2.57s\tremaining: 11.5s\n",
      "182:\tlearn: 0.2564301\ttotal: 2.58s\tremaining: 11.5s\n",
      "183:\tlearn: 0.2559624\ttotal: 2.59s\tremaining: 11.5s\n",
      "184:\tlearn: 0.2556977\ttotal: 2.6s\tremaining: 11.5s\n",
      "185:\tlearn: 0.2554218\ttotal: 2.61s\tremaining: 11.4s\n",
      "186:\tlearn: 0.2551973\ttotal: 2.62s\tremaining: 11.4s\n",
      "187:\tlearn: 0.2549626\ttotal: 2.64s\tremaining: 11.4s\n",
      "188:\tlearn: 0.2547605\ttotal: 2.65s\tremaining: 11.4s\n",
      "189:\tlearn: 0.2540663\ttotal: 2.66s\tremaining: 11.4s\n",
      "190:\tlearn: 0.2536076\ttotal: 2.68s\tremaining: 11.3s\n",
      "191:\tlearn: 0.2532438\ttotal: 2.69s\tremaining: 11.3s\n",
      "192:\tlearn: 0.2530507\ttotal: 2.7s\tremaining: 11.3s\n",
      "193:\tlearn: 0.2528637\ttotal: 2.71s\tremaining: 11.3s\n",
      "194:\tlearn: 0.2526152\ttotal: 2.72s\tremaining: 11.2s\n",
      "195:\tlearn: 0.2521283\ttotal: 2.73s\tremaining: 11.2s\n",
      "196:\tlearn: 0.2515571\ttotal: 2.75s\tremaining: 11.2s\n",
      "197:\tlearn: 0.2511271\ttotal: 2.76s\tremaining: 11.2s\n",
      "198:\tlearn: 0.2504965\ttotal: 2.77s\tremaining: 11.2s\n",
      "199:\tlearn: 0.2502799\ttotal: 2.78s\tremaining: 11.1s\n",
      "200:\tlearn: 0.2498791\ttotal: 2.79s\tremaining: 11.1s\n",
      "201:\tlearn: 0.2495704\ttotal: 2.81s\tremaining: 11.1s\n",
      "202:\tlearn: 0.2490434\ttotal: 2.82s\tremaining: 11.1s\n",
      "203:\tlearn: 0.2485565\ttotal: 2.83s\tremaining: 11.1s\n",
      "204:\tlearn: 0.2482931\ttotal: 2.86s\tremaining: 11.1s\n",
      "205:\tlearn: 0.2478469\ttotal: 2.87s\tremaining: 11.1s\n",
      "206:\tlearn: 0.2469530\ttotal: 2.89s\tremaining: 11.1s\n",
      "207:\tlearn: 0.2467502\ttotal: 2.9s\tremaining: 11.1s\n",
      "208:\tlearn: 0.2461163\ttotal: 2.92s\tremaining: 11s\n",
      "209:\tlearn: 0.2453980\ttotal: 2.94s\tremaining: 11.1s\n",
      "210:\tlearn: 0.2450981\ttotal: 2.96s\tremaining: 11.1s\n",
      "211:\tlearn: 0.2449402\ttotal: 2.98s\tremaining: 11.1s\n",
      "212:\tlearn: 0.2447129\ttotal: 2.99s\tremaining: 11s\n",
      "213:\tlearn: 0.2442959\ttotal: 3s\tremaining: 11s\n",
      "214:\tlearn: 0.2437720\ttotal: 3.02s\tremaining: 11s\n",
      "215:\tlearn: 0.2436102\ttotal: 3.04s\tremaining: 11s\n",
      "216:\tlearn: 0.2433907\ttotal: 3.05s\tremaining: 11s\n",
      "217:\tlearn: 0.2429143\ttotal: 3.07s\tremaining: 11s\n",
      "218:\tlearn: 0.2422946\ttotal: 3.08s\tremaining: 11s\n",
      "219:\tlearn: 0.2417174\ttotal: 3.1s\tremaining: 11s\n",
      "220:\tlearn: 0.2414702\ttotal: 3.11s\tremaining: 11s\n",
      "221:\tlearn: 0.2411972\ttotal: 3.13s\tremaining: 11s\n",
      "222:\tlearn: 0.2408761\ttotal: 3.14s\tremaining: 10.9s\n",
      "223:\tlearn: 0.2407530\ttotal: 3.16s\tremaining: 11s\n",
      "224:\tlearn: 0.2405262\ttotal: 3.18s\tremaining: 10.9s\n",
      "225:\tlearn: 0.2400214\ttotal: 3.19s\tremaining: 10.9s\n",
      "226:\tlearn: 0.2396709\ttotal: 3.21s\tremaining: 10.9s\n",
      "227:\tlearn: 0.2392778\ttotal: 3.22s\tremaining: 10.9s\n",
      "228:\tlearn: 0.2388688\ttotal: 3.25s\tremaining: 10.9s\n",
      "229:\tlearn: 0.2386061\ttotal: 3.26s\tremaining: 10.9s\n",
      "230:\tlearn: 0.2381850\ttotal: 3.28s\tremaining: 10.9s\n",
      "231:\tlearn: 0.2377839\ttotal: 3.3s\tremaining: 10.9s\n",
      "232:\tlearn: 0.2373285\ttotal: 3.32s\tremaining: 10.9s\n",
      "233:\tlearn: 0.2370479\ttotal: 3.33s\tremaining: 10.9s\n",
      "234:\tlearn: 0.2367374\ttotal: 3.34s\tremaining: 10.9s\n",
      "235:\tlearn: 0.2363105\ttotal: 3.37s\tremaining: 10.9s\n",
      "236:\tlearn: 0.2361026\ttotal: 3.38s\tremaining: 10.9s\n",
      "237:\tlearn: 0.2357747\ttotal: 3.4s\tremaining: 10.9s\n",
      "238:\tlearn: 0.2355944\ttotal: 3.41s\tremaining: 10.9s\n",
      "239:\tlearn: 0.2348979\ttotal: 3.42s\tremaining: 10.8s\n",
      "240:\tlearn: 0.2347768\ttotal: 3.44s\tremaining: 10.8s\n",
      "241:\tlearn: 0.2346646\ttotal: 3.46s\tremaining: 10.8s\n",
      "242:\tlearn: 0.2340966\ttotal: 3.47s\tremaining: 10.8s\n",
      "243:\tlearn: 0.2339349\ttotal: 3.48s\tremaining: 10.8s\n",
      "244:\tlearn: 0.2337672\ttotal: 3.5s\tremaining: 10.8s\n",
      "245:\tlearn: 0.2334024\ttotal: 3.51s\tremaining: 10.8s\n",
      "246:\tlearn: 0.2330864\ttotal: 3.52s\tremaining: 10.7s\n",
      "247:\tlearn: 0.2328234\ttotal: 3.54s\tremaining: 10.7s\n",
      "248:\tlearn: 0.2325953\ttotal: 3.56s\tremaining: 10.7s\n",
      "249:\tlearn: 0.2321648\ttotal: 3.57s\tremaining: 10.7s\n",
      "250:\tlearn: 0.2319671\ttotal: 3.58s\tremaining: 10.7s\n",
      "251:\tlearn: 0.2317740\ttotal: 3.59s\tremaining: 10.7s\n",
      "252:\tlearn: 0.2315253\ttotal: 3.61s\tremaining: 10.7s\n",
      "253:\tlearn: 0.2314127\ttotal: 3.62s\tremaining: 10.6s\n",
      "254:\tlearn: 0.2309415\ttotal: 3.64s\tremaining: 10.6s\n",
      "255:\tlearn: 0.2307212\ttotal: 3.65s\tremaining: 10.6s\n",
      "256:\tlearn: 0.2305093\ttotal: 3.66s\tremaining: 10.6s\n",
      "257:\tlearn: 0.2304347\ttotal: 3.67s\tremaining: 10.6s\n",
      "258:\tlearn: 0.2302175\ttotal: 3.68s\tremaining: 10.5s\n",
      "259:\tlearn: 0.2298998\ttotal: 3.7s\tremaining: 10.5s\n",
      "260:\tlearn: 0.2297432\ttotal: 3.72s\tremaining: 10.5s\n",
      "261:\tlearn: 0.2294487\ttotal: 3.74s\tremaining: 10.5s\n",
      "262:\tlearn: 0.2291175\ttotal: 3.76s\tremaining: 10.5s\n",
      "263:\tlearn: 0.2286415\ttotal: 3.77s\tremaining: 10.5s\n",
      "264:\tlearn: 0.2284896\ttotal: 3.79s\tremaining: 10.5s\n",
      "265:\tlearn: 0.2282734\ttotal: 3.8s\tremaining: 10.5s\n",
      "266:\tlearn: 0.2274660\ttotal: 3.81s\tremaining: 10.5s\n",
      "267:\tlearn: 0.2273223\ttotal: 3.82s\tremaining: 10.4s\n",
      "268:\tlearn: 0.2271007\ttotal: 3.83s\tremaining: 10.4s\n",
      "269:\tlearn: 0.2267289\ttotal: 3.85s\tremaining: 10.4s\n",
      "270:\tlearn: 0.2263631\ttotal: 3.86s\tremaining: 10.4s\n",
      "271:\tlearn: 0.2261819\ttotal: 3.87s\tremaining: 10.4s\n",
      "272:\tlearn: 0.2259585\ttotal: 3.88s\tremaining: 10.3s\n",
      "273:\tlearn: 0.2257957\ttotal: 3.89s\tremaining: 10.3s\n",
      "274:\tlearn: 0.2256351\ttotal: 3.91s\tremaining: 10.3s\n",
      "275:\tlearn: 0.2254179\ttotal: 3.93s\tremaining: 10.3s\n",
      "276:\tlearn: 0.2251057\ttotal: 3.94s\tremaining: 10.3s\n",
      "277:\tlearn: 0.2249882\ttotal: 3.95s\tremaining: 10.3s\n",
      "278:\tlearn: 0.2248328\ttotal: 3.96s\tremaining: 10.2s\n",
      "279:\tlearn: 0.2245405\ttotal: 3.98s\tremaining: 10.2s\n",
      "280:\tlearn: 0.2243191\ttotal: 3.99s\tremaining: 10.2s\n",
      "281:\tlearn: 0.2242404\ttotal: 4s\tremaining: 10.2s\n",
      "282:\tlearn: 0.2235736\ttotal: 4.01s\tremaining: 10.2s\n",
      "283:\tlearn: 0.2233841\ttotal: 4.02s\tremaining: 10.1s\n",
      "284:\tlearn: 0.2230909\ttotal: 4.04s\tremaining: 10.1s\n",
      "285:\tlearn: 0.2226053\ttotal: 4.05s\tremaining: 10.1s\n",
      "286:\tlearn: 0.2222903\ttotal: 4.06s\tremaining: 10.1s\n",
      "287:\tlearn: 0.2221310\ttotal: 4.07s\tremaining: 10.1s\n",
      "288:\tlearn: 0.2218416\ttotal: 4.09s\tremaining: 10.1s\n",
      "289:\tlearn: 0.2216184\ttotal: 4.11s\tremaining: 10.1s\n",
      "290:\tlearn: 0.2215130\ttotal: 4.12s\tremaining: 10s\n",
      "291:\tlearn: 0.2213242\ttotal: 4.13s\tremaining: 10s\n",
      "292:\tlearn: 0.2211192\ttotal: 4.14s\tremaining: 10s\n",
      "293:\tlearn: 0.2208511\ttotal: 4.16s\tremaining: 9.98s\n",
      "294:\tlearn: 0.2205539\ttotal: 4.17s\tremaining: 9.96s\n",
      "295:\tlearn: 0.2204667\ttotal: 4.18s\tremaining: 9.95s\n",
      "296:\tlearn: 0.2202248\ttotal: 4.2s\tremaining: 9.93s\n",
      "297:\tlearn: 0.2200024\ttotal: 4.21s\tremaining: 9.91s\n",
      "298:\tlearn: 0.2197749\ttotal: 4.22s\tremaining: 9.89s\n",
      "299:\tlearn: 0.2195108\ttotal: 4.23s\tremaining: 9.88s\n",
      "300:\tlearn: 0.2193108\ttotal: 4.25s\tremaining: 9.86s\n",
      "301:\tlearn: 0.2190924\ttotal: 4.27s\tremaining: 9.86s\n",
      "302:\tlearn: 0.2189170\ttotal: 4.28s\tremaining: 9.84s\n",
      "303:\tlearn: 0.2187239\ttotal: 4.29s\tremaining: 9.82s\n",
      "304:\tlearn: 0.2182005\ttotal: 4.3s\tremaining: 9.8s\n",
      "305:\tlearn: 0.2174341\ttotal: 4.31s\tremaining: 9.78s\n",
      "306:\tlearn: 0.2173214\ttotal: 4.33s\tremaining: 9.77s\n",
      "307:\tlearn: 0.2171639\ttotal: 4.34s\tremaining: 9.75s\n",
      "308:\tlearn: 0.2169420\ttotal: 4.35s\tremaining: 9.73s\n",
      "309:\tlearn: 0.2167829\ttotal: 4.37s\tremaining: 9.73s\n",
      "310:\tlearn: 0.2165462\ttotal: 4.38s\tremaining: 9.71s\n",
      "311:\tlearn: 0.2161623\ttotal: 4.4s\tremaining: 9.7s\n",
      "312:\tlearn: 0.2160114\ttotal: 4.41s\tremaining: 9.69s\n",
      "313:\tlearn: 0.2158075\ttotal: 4.42s\tremaining: 9.67s\n",
      "314:\tlearn: 0.2153304\ttotal: 4.44s\tremaining: 9.66s\n",
      "315:\tlearn: 0.2147819\ttotal: 4.45s\tremaining: 9.64s\n",
      "316:\tlearn: 0.2142470\ttotal: 4.46s\tremaining: 9.62s\n",
      "317:\tlearn: 0.2137655\ttotal: 4.48s\tremaining: 9.61s\n",
      "318:\tlearn: 0.2134650\ttotal: 4.49s\tremaining: 9.59s\n",
      "319:\tlearn: 0.2133127\ttotal: 4.5s\tremaining: 9.57s\n",
      "320:\tlearn: 0.2128898\ttotal: 4.52s\tremaining: 9.55s\n",
      "321:\tlearn: 0.2127234\ttotal: 4.53s\tremaining: 9.54s\n",
      "322:\tlearn: 0.2124524\ttotal: 4.54s\tremaining: 9.52s\n",
      "323:\tlearn: 0.2122604\ttotal: 4.55s\tremaining: 9.5s\n",
      "324:\tlearn: 0.2117518\ttotal: 4.57s\tremaining: 9.48s\n",
      "325:\tlearn: 0.2115938\ttotal: 4.59s\tremaining: 9.48s\n",
      "326:\tlearn: 0.2111864\ttotal: 4.6s\tremaining: 9.47s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327:\tlearn: 0.2110394\ttotal: 4.61s\tremaining: 9.45s\n",
      "328:\tlearn: 0.2104938\ttotal: 4.63s\tremaining: 9.43s\n",
      "329:\tlearn: 0.2103895\ttotal: 4.64s\tremaining: 9.41s\n",
      "330:\tlearn: 0.2100991\ttotal: 4.66s\tremaining: 9.41s\n",
      "331:\tlearn: 0.2099026\ttotal: 4.67s\tremaining: 9.39s\n",
      "332:\tlearn: 0.2094264\ttotal: 4.68s\tremaining: 9.38s\n",
      "333:\tlearn: 0.2091175\ttotal: 4.69s\tremaining: 9.36s\n",
      "334:\tlearn: 0.2088381\ttotal: 4.7s\tremaining: 9.34s\n",
      "335:\tlearn: 0.2087231\ttotal: 4.72s\tremaining: 9.32s\n",
      "336:\tlearn: 0.2086135\ttotal: 4.73s\tremaining: 9.3s\n",
      "337:\tlearn: 0.2084740\ttotal: 4.74s\tremaining: 9.29s\n",
      "338:\tlearn: 0.2081433\ttotal: 4.75s\tremaining: 9.27s\n",
      "339:\tlearn: 0.2079279\ttotal: 4.77s\tremaining: 9.25s\n",
      "340:\tlearn: 0.2077591\ttotal: 4.78s\tremaining: 9.23s\n",
      "341:\tlearn: 0.2075810\ttotal: 4.79s\tremaining: 9.22s\n",
      "342:\tlearn: 0.2074631\ttotal: 4.81s\tremaining: 9.22s\n",
      "343:\tlearn: 0.2073151\ttotal: 4.83s\tremaining: 9.21s\n",
      "344:\tlearn: 0.2071756\ttotal: 4.84s\tremaining: 9.2s\n",
      "345:\tlearn: 0.2070848\ttotal: 4.86s\tremaining: 9.18s\n",
      "346:\tlearn: 0.2067486\ttotal: 4.87s\tremaining: 9.16s\n",
      "347:\tlearn: 0.2066018\ttotal: 4.89s\tremaining: 9.17s\n",
      "348:\tlearn: 0.2065373\ttotal: 4.91s\tremaining: 9.15s\n",
      "349:\tlearn: 0.2062315\ttotal: 4.92s\tremaining: 9.13s\n",
      "350:\tlearn: 0.2061287\ttotal: 4.93s\tremaining: 9.12s\n",
      "351:\tlearn: 0.2058943\ttotal: 4.94s\tremaining: 9.1s\n",
      "352:\tlearn: 0.2057177\ttotal: 4.95s\tremaining: 9.08s\n",
      "353:\tlearn: 0.2055878\ttotal: 4.97s\tremaining: 9.07s\n",
      "354:\tlearn: 0.2053851\ttotal: 4.99s\tremaining: 9.06s\n",
      "355:\tlearn: 0.2052311\ttotal: 5s\tremaining: 9.04s\n",
      "356:\tlearn: 0.2050933\ttotal: 5.01s\tremaining: 9.03s\n",
      "357:\tlearn: 0.2049446\ttotal: 5.03s\tremaining: 9.02s\n",
      "358:\tlearn: 0.2047644\ttotal: 5.04s\tremaining: 9.01s\n",
      "359:\tlearn: 0.2044997\ttotal: 5.06s\tremaining: 8.99s\n",
      "360:\tlearn: 0.2042397\ttotal: 5.07s\tremaining: 8.97s\n",
      "361:\tlearn: 0.2040444\ttotal: 5.08s\tremaining: 8.96s\n",
      "362:\tlearn: 0.2039492\ttotal: 5.09s\tremaining: 8.94s\n",
      "363:\tlearn: 0.2036869\ttotal: 5.11s\tremaining: 8.92s\n",
      "364:\tlearn: 0.2035964\ttotal: 5.12s\tremaining: 8.9s\n",
      "365:\tlearn: 0.2034418\ttotal: 5.13s\tremaining: 8.89s\n",
      "366:\tlearn: 0.2032808\ttotal: 5.15s\tremaining: 8.88s\n",
      "367:\tlearn: 0.2031867\ttotal: 5.17s\tremaining: 8.87s\n",
      "368:\tlearn: 0.2030441\ttotal: 5.18s\tremaining: 8.85s\n",
      "369:\tlearn: 0.2027111\ttotal: 5.19s\tremaining: 8.84s\n",
      "370:\tlearn: 0.2025263\ttotal: 5.2s\tremaining: 8.82s\n",
      "371:\tlearn: 0.2024208\ttotal: 5.22s\tremaining: 8.81s\n",
      "372:\tlearn: 0.2020575\ttotal: 5.23s\tremaining: 8.79s\n",
      "373:\tlearn: 0.2019518\ttotal: 5.24s\tremaining: 8.78s\n",
      "374:\tlearn: 0.2018052\ttotal: 5.26s\tremaining: 8.76s\n",
      "375:\tlearn: 0.2016421\ttotal: 5.27s\tremaining: 8.74s\n",
      "376:\tlearn: 0.2015099\ttotal: 5.28s\tremaining: 8.72s\n",
      "377:\tlearn: 0.2014095\ttotal: 5.29s\tremaining: 8.71s\n",
      "378:\tlearn: 0.2012287\ttotal: 5.3s\tremaining: 8.69s\n",
      "379:\tlearn: 0.2010597\ttotal: 5.32s\tremaining: 8.68s\n",
      "380:\tlearn: 0.2008539\ttotal: 5.33s\tremaining: 8.66s\n",
      "381:\tlearn: 0.2007103\ttotal: 5.34s\tremaining: 8.65s\n",
      "382:\tlearn: 0.2004734\ttotal: 5.36s\tremaining: 8.63s\n",
      "383:\tlearn: 0.2001451\ttotal: 5.37s\tremaining: 8.61s\n",
      "384:\tlearn: 0.2000158\ttotal: 5.38s\tremaining: 8.6s\n",
      "385:\tlearn: 0.1997881\ttotal: 5.4s\tremaining: 8.59s\n",
      "386:\tlearn: 0.1996906\ttotal: 5.41s\tremaining: 8.57s\n",
      "387:\tlearn: 0.1995244\ttotal: 5.42s\tremaining: 8.55s\n",
      "388:\tlearn: 0.1993487\ttotal: 5.43s\tremaining: 8.53s\n",
      "389:\tlearn: 0.1992716\ttotal: 5.45s\tremaining: 8.52s\n",
      "390:\tlearn: 0.1991495\ttotal: 5.46s\tremaining: 8.5s\n",
      "391:\tlearn: 0.1990574\ttotal: 5.47s\tremaining: 8.49s\n",
      "392:\tlearn: 0.1989129\ttotal: 5.48s\tremaining: 8.47s\n",
      "393:\tlearn: 0.1987407\ttotal: 5.5s\tremaining: 8.45s\n",
      "394:\tlearn: 0.1986328\ttotal: 5.51s\tremaining: 8.44s\n",
      "395:\tlearn: 0.1985084\ttotal: 5.53s\tremaining: 8.43s\n",
      "396:\tlearn: 0.1983743\ttotal: 5.54s\tremaining: 8.41s\n",
      "397:\tlearn: 0.1982073\ttotal: 5.55s\tremaining: 8.4s\n",
      "398:\tlearn: 0.1980889\ttotal: 5.56s\tremaining: 8.38s\n",
      "399:\tlearn: 0.1980287\ttotal: 5.58s\tremaining: 8.36s\n",
      "400:\tlearn: 0.1979000\ttotal: 5.59s\tremaining: 8.35s\n",
      "401:\tlearn: 0.1978101\ttotal: 5.6s\tremaining: 8.33s\n",
      "402:\tlearn: 0.1975063\ttotal: 5.61s\tremaining: 8.31s\n",
      "403:\tlearn: 0.1974032\ttotal: 5.62s\tremaining: 8.29s\n",
      "404:\tlearn: 0.1973092\ttotal: 5.63s\tremaining: 8.28s\n",
      "405:\tlearn: 0.1971115\ttotal: 5.64s\tremaining: 8.26s\n",
      "406:\tlearn: 0.1967924\ttotal: 5.66s\tremaining: 8.24s\n",
      "407:\tlearn: 0.1964832\ttotal: 5.67s\tremaining: 8.22s\n",
      "408:\tlearn: 0.1962230\ttotal: 5.7s\tremaining: 8.23s\n",
      "409:\tlearn: 0.1960892\ttotal: 5.71s\tremaining: 8.21s\n",
      "410:\tlearn: 0.1958961\ttotal: 5.72s\tremaining: 8.2s\n",
      "411:\tlearn: 0.1957099\ttotal: 5.73s\tremaining: 8.18s\n",
      "412:\tlearn: 0.1956187\ttotal: 5.74s\tremaining: 8.16s\n",
      "413:\tlearn: 0.1955283\ttotal: 5.76s\tremaining: 8.15s\n",
      "414:\tlearn: 0.1953990\ttotal: 5.77s\tremaining: 8.13s\n",
      "415:\tlearn: 0.1952579\ttotal: 5.78s\tremaining: 8.12s\n",
      "416:\tlearn: 0.1947747\ttotal: 5.79s\tremaining: 8.1s\n",
      "417:\tlearn: 0.1945621\ttotal: 5.8s\tremaining: 8.08s\n",
      "418:\tlearn: 0.1944247\ttotal: 5.82s\tremaining: 8.07s\n",
      "419:\tlearn: 0.1942024\ttotal: 5.83s\tremaining: 8.05s\n",
      "420:\tlearn: 0.1940654\ttotal: 5.84s\tremaining: 8.03s\n",
      "421:\tlearn: 0.1939290\ttotal: 5.85s\tremaining: 8.02s\n",
      "422:\tlearn: 0.1937706\ttotal: 5.87s\tremaining: 8s\n",
      "423:\tlearn: 0.1936515\ttotal: 5.88s\tremaining: 7.99s\n",
      "424:\tlearn: 0.1935091\ttotal: 5.89s\tremaining: 7.98s\n",
      "425:\tlearn: 0.1934382\ttotal: 5.91s\tremaining: 7.96s\n",
      "426:\tlearn: 0.1932650\ttotal: 5.92s\tremaining: 7.94s\n",
      "427:\tlearn: 0.1931385\ttotal: 5.93s\tremaining: 7.93s\n",
      "428:\tlearn: 0.1930379\ttotal: 5.94s\tremaining: 7.91s\n",
      "429:\tlearn: 0.1929443\ttotal: 5.96s\tremaining: 7.9s\n",
      "430:\tlearn: 0.1928516\ttotal: 5.97s\tremaining: 7.88s\n",
      "431:\tlearn: 0.1927268\ttotal: 5.98s\tremaining: 7.86s\n",
      "432:\tlearn: 0.1926827\ttotal: 5.99s\tremaining: 7.85s\n",
      "433:\tlearn: 0.1926243\ttotal: 6s\tremaining: 7.83s\n",
      "434:\tlearn: 0.1925567\ttotal: 6.01s\tremaining: 7.81s\n",
      "435:\tlearn: 0.1924103\ttotal: 6.03s\tremaining: 7.79s\n",
      "436:\tlearn: 0.1922889\ttotal: 6.04s\tremaining: 7.78s\n",
      "437:\tlearn: 0.1921621\ttotal: 6.06s\tremaining: 7.78s\n",
      "438:\tlearn: 0.1920133\ttotal: 6.07s\tremaining: 7.76s\n",
      "439:\tlearn: 0.1919161\ttotal: 6.08s\tremaining: 7.74s\n",
      "440:\tlearn: 0.1918481\ttotal: 6.1s\tremaining: 7.73s\n",
      "441:\tlearn: 0.1917672\ttotal: 6.11s\tremaining: 7.71s\n",
      "442:\tlearn: 0.1917017\ttotal: 6.12s\tremaining: 7.7s\n",
      "443:\tlearn: 0.1915340\ttotal: 6.13s\tremaining: 7.68s\n",
      "444:\tlearn: 0.1914135\ttotal: 6.14s\tremaining: 7.66s\n",
      "445:\tlearn: 0.1913457\ttotal: 6.16s\tremaining: 7.65s\n",
      "446:\tlearn: 0.1911732\ttotal: 6.17s\tremaining: 7.63s\n",
      "447:\tlearn: 0.1910190\ttotal: 6.18s\tremaining: 7.62s\n",
      "448:\tlearn: 0.1908076\ttotal: 6.19s\tremaining: 7.6s\n",
      "449:\tlearn: 0.1906752\ttotal: 6.21s\tremaining: 7.58s\n",
      "450:\tlearn: 0.1905283\ttotal: 6.23s\tremaining: 7.58s\n",
      "451:\tlearn: 0.1903451\ttotal: 6.24s\tremaining: 7.57s\n",
      "452:\tlearn: 0.1902526\ttotal: 6.25s\tremaining: 7.55s\n",
      "453:\tlearn: 0.1901382\ttotal: 6.26s\tremaining: 7.54s\n",
      "454:\tlearn: 0.1899195\ttotal: 6.28s\tremaining: 7.52s\n",
      "455:\tlearn: 0.1895768\ttotal: 6.29s\tremaining: 7.5s\n",
      "456:\tlearn: 0.1894479\ttotal: 6.3s\tremaining: 7.49s\n",
      "457:\tlearn: 0.1892762\ttotal: 6.31s\tremaining: 7.47s\n",
      "458:\tlearn: 0.1890778\ttotal: 6.32s\tremaining: 7.45s\n",
      "459:\tlearn: 0.1889636\ttotal: 6.33s\tremaining: 7.44s\n",
      "460:\tlearn: 0.1888854\ttotal: 6.34s\tremaining: 7.42s\n",
      "461:\tlearn: 0.1887299\ttotal: 6.36s\tremaining: 7.4s\n",
      "462:\tlearn: 0.1883255\ttotal: 6.37s\tremaining: 7.39s\n",
      "463:\tlearn: 0.1880356\ttotal: 6.38s\tremaining: 7.37s\n",
      "464:\tlearn: 0.1879057\ttotal: 6.39s\tremaining: 7.36s\n",
      "465:\tlearn: 0.1877434\ttotal: 6.41s\tremaining: 7.34s\n",
      "466:\tlearn: 0.1875946\ttotal: 6.42s\tremaining: 7.33s\n",
      "467:\tlearn: 0.1875055\ttotal: 6.43s\tremaining: 7.31s\n",
      "468:\tlearn: 0.1873839\ttotal: 6.45s\tremaining: 7.3s\n",
      "469:\tlearn: 0.1872804\ttotal: 6.46s\tremaining: 7.28s\n",
      "470:\tlearn: 0.1871474\ttotal: 6.47s\tremaining: 7.27s\n",
      "471:\tlearn: 0.1870324\ttotal: 6.48s\tremaining: 7.25s\n",
      "472:\tlearn: 0.1869197\ttotal: 6.49s\tremaining: 7.23s\n",
      "473:\tlearn: 0.1868185\ttotal: 6.5s\tremaining: 7.22s\n",
      "474:\tlearn: 0.1867089\ttotal: 6.52s\tremaining: 7.2s\n",
      "475:\tlearn: 0.1865685\ttotal: 6.53s\tremaining: 7.19s\n",
      "476:\tlearn: 0.1863767\ttotal: 6.54s\tremaining: 7.17s\n",
      "477:\tlearn: 0.1863004\ttotal: 6.55s\tremaining: 7.15s\n",
      "478:\tlearn: 0.1861909\ttotal: 6.57s\tremaining: 7.14s\n",
      "479:\tlearn: 0.1861136\ttotal: 6.58s\tremaining: 7.13s\n",
      "480:\tlearn: 0.1860136\ttotal: 6.59s\tremaining: 7.12s\n",
      "481:\tlearn: 0.1859428\ttotal: 6.61s\tremaining: 7.1s\n",
      "482:\tlearn: 0.1858633\ttotal: 6.62s\tremaining: 7.08s\n",
      "483:\tlearn: 0.1857286\ttotal: 6.63s\tremaining: 7.07s\n",
      "484:\tlearn: 0.1855984\ttotal: 6.64s\tremaining: 7.05s\n",
      "485:\tlearn: 0.1852457\ttotal: 6.65s\tremaining: 7.04s\n",
      "486:\tlearn: 0.1850476\ttotal: 6.67s\tremaining: 7.02s\n",
      "487:\tlearn: 0.1849845\ttotal: 6.68s\tremaining: 7.01s\n",
      "488:\tlearn: 0.1847339\ttotal: 6.69s\tremaining: 6.99s\n",
      "489:\tlearn: 0.1846145\ttotal: 6.7s\tremaining: 6.97s\n",
      "490:\tlearn: 0.1845167\ttotal: 6.71s\tremaining: 6.96s\n",
      "491:\tlearn: 0.1843142\ttotal: 6.72s\tremaining: 6.94s\n",
      "492:\tlearn: 0.1841924\ttotal: 6.74s\tremaining: 6.93s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493:\tlearn: 0.1840906\ttotal: 6.75s\tremaining: 6.91s\n",
      "494:\tlearn: 0.1840023\ttotal: 6.77s\tremaining: 6.91s\n",
      "495:\tlearn: 0.1839303\ttotal: 6.78s\tremaining: 6.89s\n",
      "496:\tlearn: 0.1837125\ttotal: 6.79s\tremaining: 6.88s\n",
      "497:\tlearn: 0.1835934\ttotal: 6.8s\tremaining: 6.86s\n",
      "498:\tlearn: 0.1834831\ttotal: 6.82s\tremaining: 6.84s\n",
      "499:\tlearn: 0.1833524\ttotal: 6.83s\tremaining: 6.83s\n",
      "500:\tlearn: 0.1832285\ttotal: 6.84s\tremaining: 6.81s\n",
      "501:\tlearn: 0.1831176\ttotal: 6.85s\tremaining: 6.8s\n",
      "502:\tlearn: 0.1829606\ttotal: 6.86s\tremaining: 6.78s\n",
      "503:\tlearn: 0.1828677\ttotal: 6.88s\tremaining: 6.76s\n",
      "504:\tlearn: 0.1827801\ttotal: 6.89s\tremaining: 6.75s\n",
      "505:\tlearn: 0.1826495\ttotal: 6.9s\tremaining: 6.74s\n",
      "506:\tlearn: 0.1825211\ttotal: 6.91s\tremaining: 6.72s\n",
      "507:\tlearn: 0.1824431\ttotal: 6.93s\tremaining: 6.71s\n",
      "508:\tlearn: 0.1823101\ttotal: 6.94s\tremaining: 6.7s\n",
      "509:\tlearn: 0.1821581\ttotal: 6.95s\tremaining: 6.68s\n",
      "510:\tlearn: 0.1820394\ttotal: 6.97s\tremaining: 6.67s\n",
      "511:\tlearn: 0.1819339\ttotal: 6.98s\tremaining: 6.65s\n",
      "512:\tlearn: 0.1818725\ttotal: 6.99s\tremaining: 6.64s\n",
      "513:\tlearn: 0.1817677\ttotal: 7s\tremaining: 6.62s\n",
      "514:\tlearn: 0.1816527\ttotal: 7.01s\tremaining: 6.61s\n",
      "515:\tlearn: 0.1815507\ttotal: 7.03s\tremaining: 6.59s\n",
      "516:\tlearn: 0.1814275\ttotal: 7.04s\tremaining: 6.58s\n",
      "517:\tlearn: 0.1813322\ttotal: 7.05s\tremaining: 6.56s\n",
      "518:\tlearn: 0.1812582\ttotal: 7.06s\tremaining: 6.54s\n",
      "519:\tlearn: 0.1811702\ttotal: 7.08s\tremaining: 6.53s\n",
      "520:\tlearn: 0.1811188\ttotal: 7.09s\tremaining: 6.51s\n",
      "521:\tlearn: 0.1809515\ttotal: 7.1s\tremaining: 6.5s\n",
      "522:\tlearn: 0.1807347\ttotal: 7.11s\tremaining: 6.49s\n",
      "523:\tlearn: 0.1805413\ttotal: 7.14s\tremaining: 6.48s\n",
      "524:\tlearn: 0.1803466\ttotal: 7.15s\tremaining: 6.47s\n",
      "525:\tlearn: 0.1800542\ttotal: 7.16s\tremaining: 6.45s\n",
      "526:\tlearn: 0.1799525\ttotal: 7.17s\tremaining: 6.44s\n",
      "527:\tlearn: 0.1798408\ttotal: 7.18s\tremaining: 6.42s\n",
      "528:\tlearn: 0.1797259\ttotal: 7.2s\tremaining: 6.41s\n",
      "529:\tlearn: 0.1796196\ttotal: 7.21s\tremaining: 6.39s\n",
      "530:\tlearn: 0.1794666\ttotal: 7.22s\tremaining: 6.38s\n",
      "531:\tlearn: 0.1793358\ttotal: 7.23s\tremaining: 6.36s\n",
      "532:\tlearn: 0.1792260\ttotal: 7.24s\tremaining: 6.35s\n",
      "533:\tlearn: 0.1791457\ttotal: 7.25s\tremaining: 6.33s\n",
      "534:\tlearn: 0.1790366\ttotal: 7.27s\tremaining: 6.32s\n",
      "535:\tlearn: 0.1788940\ttotal: 7.28s\tremaining: 6.3s\n",
      "536:\tlearn: 0.1787755\ttotal: 7.3s\tremaining: 6.29s\n",
      "537:\tlearn: 0.1786823\ttotal: 7.31s\tremaining: 6.28s\n",
      "538:\tlearn: 0.1785999\ttotal: 7.32s\tremaining: 6.26s\n",
      "539:\tlearn: 0.1784880\ttotal: 7.33s\tremaining: 6.25s\n",
      "540:\tlearn: 0.1783745\ttotal: 7.34s\tremaining: 6.23s\n",
      "541:\tlearn: 0.1782720\ttotal: 7.36s\tremaining: 6.22s\n",
      "542:\tlearn: 0.1781351\ttotal: 7.37s\tremaining: 6.2s\n",
      "543:\tlearn: 0.1780786\ttotal: 7.38s\tremaining: 6.18s\n",
      "544:\tlearn: 0.1779782\ttotal: 7.39s\tremaining: 6.17s\n",
      "545:\tlearn: 0.1778702\ttotal: 7.4s\tremaining: 6.16s\n",
      "546:\tlearn: 0.1777878\ttotal: 7.41s\tremaining: 6.14s\n",
      "547:\tlearn: 0.1777153\ttotal: 7.42s\tremaining: 6.12s\n",
      "548:\tlearn: 0.1776303\ttotal: 7.44s\tremaining: 6.11s\n",
      "549:\tlearn: 0.1775820\ttotal: 7.45s\tremaining: 6.09s\n",
      "550:\tlearn: 0.1774992\ttotal: 7.46s\tremaining: 6.08s\n",
      "551:\tlearn: 0.1773621\ttotal: 7.48s\tremaining: 6.07s\n",
      "552:\tlearn: 0.1772891\ttotal: 7.49s\tremaining: 6.05s\n",
      "553:\tlearn: 0.1772007\ttotal: 7.5s\tremaining: 6.04s\n",
      "554:\tlearn: 0.1771452\ttotal: 7.51s\tremaining: 6.02s\n",
      "555:\tlearn: 0.1770415\ttotal: 7.52s\tremaining: 6.01s\n",
      "556:\tlearn: 0.1769443\ttotal: 7.54s\tremaining: 5.99s\n",
      "557:\tlearn: 0.1768346\ttotal: 7.55s\tremaining: 5.98s\n",
      "558:\tlearn: 0.1767248\ttotal: 7.56s\tremaining: 5.96s\n",
      "559:\tlearn: 0.1766516\ttotal: 7.57s\tremaining: 5.95s\n",
      "560:\tlearn: 0.1765618\ttotal: 7.58s\tremaining: 5.93s\n",
      "561:\tlearn: 0.1765051\ttotal: 7.6s\tremaining: 5.92s\n",
      "562:\tlearn: 0.1763824\ttotal: 7.61s\tremaining: 5.91s\n",
      "563:\tlearn: 0.1762124\ttotal: 7.62s\tremaining: 5.89s\n",
      "564:\tlearn: 0.1759667\ttotal: 7.64s\tremaining: 5.88s\n",
      "565:\tlearn: 0.1758966\ttotal: 7.66s\tremaining: 5.87s\n",
      "566:\tlearn: 0.1757561\ttotal: 7.67s\tremaining: 5.86s\n",
      "567:\tlearn: 0.1756574\ttotal: 7.68s\tremaining: 5.84s\n",
      "568:\tlearn: 0.1755462\ttotal: 7.69s\tremaining: 5.83s\n",
      "569:\tlearn: 0.1754092\ttotal: 7.71s\tremaining: 5.81s\n",
      "570:\tlearn: 0.1753629\ttotal: 7.72s\tremaining: 5.8s\n",
      "571:\tlearn: 0.1752076\ttotal: 7.73s\tremaining: 5.79s\n",
      "572:\tlearn: 0.1751280\ttotal: 7.75s\tremaining: 5.77s\n",
      "573:\tlearn: 0.1750473\ttotal: 7.76s\tremaining: 5.76s\n",
      "574:\tlearn: 0.1749493\ttotal: 7.77s\tremaining: 5.74s\n",
      "575:\tlearn: 0.1749273\ttotal: 7.78s\tremaining: 5.73s\n",
      "576:\tlearn: 0.1748035\ttotal: 7.79s\tremaining: 5.71s\n",
      "577:\tlearn: 0.1747455\ttotal: 7.81s\tremaining: 5.7s\n",
      "578:\tlearn: 0.1746063\ttotal: 7.83s\tremaining: 5.7s\n",
      "579:\tlearn: 0.1745253\ttotal: 7.85s\tremaining: 5.68s\n",
      "580:\tlearn: 0.1744267\ttotal: 7.86s\tremaining: 5.67s\n",
      "581:\tlearn: 0.1743665\ttotal: 7.87s\tremaining: 5.66s\n",
      "582:\tlearn: 0.1742981\ttotal: 7.89s\tremaining: 5.64s\n",
      "583:\tlearn: 0.1742307\ttotal: 7.9s\tremaining: 5.63s\n",
      "584:\tlearn: 0.1741114\ttotal: 7.91s\tremaining: 5.61s\n",
      "585:\tlearn: 0.1740229\ttotal: 7.92s\tremaining: 5.6s\n",
      "586:\tlearn: 0.1739153\ttotal: 7.93s\tremaining: 5.58s\n",
      "587:\tlearn: 0.1737870\ttotal: 7.95s\tremaining: 5.57s\n",
      "588:\tlearn: 0.1737063\ttotal: 7.96s\tremaining: 5.55s\n",
      "589:\tlearn: 0.1736685\ttotal: 7.97s\tremaining: 5.54s\n",
      "590:\tlearn: 0.1736576\ttotal: 7.98s\tremaining: 5.52s\n",
      "591:\tlearn: 0.1735947\ttotal: 8s\tremaining: 5.52s\n",
      "592:\tlearn: 0.1735174\ttotal: 8.02s\tremaining: 5.5s\n",
      "593:\tlearn: 0.1734855\ttotal: 8.03s\tremaining: 5.49s\n",
      "594:\tlearn: 0.1734420\ttotal: 8.04s\tremaining: 5.47s\n",
      "595:\tlearn: 0.1733481\ttotal: 8.05s\tremaining: 5.46s\n",
      "596:\tlearn: 0.1732766\ttotal: 8.07s\tremaining: 5.45s\n",
      "597:\tlearn: 0.1732273\ttotal: 8.08s\tremaining: 5.43s\n",
      "598:\tlearn: 0.1731284\ttotal: 8.1s\tremaining: 5.42s\n",
      "599:\tlearn: 0.1730191\ttotal: 8.11s\tremaining: 5.4s\n",
      "600:\tlearn: 0.1729491\ttotal: 8.12s\tremaining: 5.39s\n",
      "601:\tlearn: 0.1728717\ttotal: 8.13s\tremaining: 5.37s\n",
      "602:\tlearn: 0.1727792\ttotal: 8.14s\tremaining: 5.36s\n",
      "603:\tlearn: 0.1726570\ttotal: 8.15s\tremaining: 5.34s\n",
      "604:\tlearn: 0.1725579\ttotal: 8.17s\tremaining: 5.34s\n",
      "605:\tlearn: 0.1724844\ttotal: 8.19s\tremaining: 5.32s\n",
      "606:\tlearn: 0.1723711\ttotal: 8.2s\tremaining: 5.31s\n",
      "607:\tlearn: 0.1722519\ttotal: 8.21s\tremaining: 5.29s\n",
      "608:\tlearn: 0.1721731\ttotal: 8.23s\tremaining: 5.28s\n",
      "609:\tlearn: 0.1721286\ttotal: 8.24s\tremaining: 5.27s\n",
      "610:\tlearn: 0.1720740\ttotal: 8.25s\tremaining: 5.25s\n",
      "611:\tlearn: 0.1720113\ttotal: 8.26s\tremaining: 5.24s\n",
      "612:\tlearn: 0.1719215\ttotal: 8.28s\tremaining: 5.22s\n",
      "613:\tlearn: 0.1718546\ttotal: 8.29s\tremaining: 5.21s\n",
      "614:\tlearn: 0.1717406\ttotal: 8.3s\tremaining: 5.2s\n",
      "615:\tlearn: 0.1716276\ttotal: 8.31s\tremaining: 5.18s\n",
      "616:\tlearn: 0.1715371\ttotal: 8.33s\tremaining: 5.17s\n",
      "617:\tlearn: 0.1714531\ttotal: 8.35s\tremaining: 5.16s\n",
      "618:\tlearn: 0.1713501\ttotal: 8.36s\tremaining: 5.15s\n",
      "619:\tlearn: 0.1712790\ttotal: 8.37s\tremaining: 5.13s\n",
      "620:\tlearn: 0.1712335\ttotal: 8.38s\tremaining: 5.12s\n",
      "621:\tlearn: 0.1711168\ttotal: 8.4s\tremaining: 5.1s\n",
      "622:\tlearn: 0.1710300\ttotal: 8.41s\tremaining: 5.09s\n",
      "623:\tlearn: 0.1709736\ttotal: 8.42s\tremaining: 5.07s\n",
      "624:\tlearn: 0.1709048\ttotal: 8.43s\tremaining: 5.06s\n",
      "625:\tlearn: 0.1708450\ttotal: 8.44s\tremaining: 5.04s\n",
      "626:\tlearn: 0.1707996\ttotal: 8.45s\tremaining: 5.03s\n",
      "627:\tlearn: 0.1707096\ttotal: 8.47s\tremaining: 5.01s\n",
      "628:\tlearn: 0.1706779\ttotal: 8.48s\tremaining: 5s\n",
      "629:\tlearn: 0.1705711\ttotal: 8.49s\tremaining: 4.99s\n",
      "630:\tlearn: 0.1704753\ttotal: 8.5s\tremaining: 4.97s\n",
      "631:\tlearn: 0.1703789\ttotal: 8.51s\tremaining: 4.96s\n",
      "632:\tlearn: 0.1702552\ttotal: 8.53s\tremaining: 4.95s\n",
      "633:\tlearn: 0.1701905\ttotal: 8.55s\tremaining: 4.93s\n",
      "634:\tlearn: 0.1700880\ttotal: 8.56s\tremaining: 4.92s\n",
      "635:\tlearn: 0.1700234\ttotal: 8.57s\tremaining: 4.91s\n",
      "636:\tlearn: 0.1699312\ttotal: 8.59s\tremaining: 4.89s\n",
      "637:\tlearn: 0.1698827\ttotal: 8.6s\tremaining: 4.88s\n",
      "638:\tlearn: 0.1698242\ttotal: 8.61s\tremaining: 4.87s\n",
      "639:\tlearn: 0.1697038\ttotal: 8.63s\tremaining: 4.85s\n",
      "640:\tlearn: 0.1696133\ttotal: 8.64s\tremaining: 4.84s\n",
      "641:\tlearn: 0.1695267\ttotal: 8.65s\tremaining: 4.83s\n",
      "642:\tlearn: 0.1694526\ttotal: 8.67s\tremaining: 4.81s\n",
      "643:\tlearn: 0.1693678\ttotal: 8.68s\tremaining: 4.8s\n",
      "644:\tlearn: 0.1693057\ttotal: 8.69s\tremaining: 4.78s\n",
      "645:\tlearn: 0.1692180\ttotal: 8.71s\tremaining: 4.77s\n",
      "646:\tlearn: 0.1690677\ttotal: 8.73s\tremaining: 4.76s\n",
      "647:\tlearn: 0.1689721\ttotal: 8.74s\tremaining: 4.75s\n",
      "648:\tlearn: 0.1689043\ttotal: 8.75s\tremaining: 4.73s\n",
      "649:\tlearn: 0.1688256\ttotal: 8.76s\tremaining: 4.72s\n",
      "650:\tlearn: 0.1687023\ttotal: 8.77s\tremaining: 4.7s\n",
      "651:\tlearn: 0.1685852\ttotal: 8.79s\tremaining: 4.69s\n",
      "652:\tlearn: 0.1685100\ttotal: 8.8s\tremaining: 4.67s\n",
      "653:\tlearn: 0.1683821\ttotal: 8.81s\tremaining: 4.66s\n",
      "654:\tlearn: 0.1683089\ttotal: 8.82s\tremaining: 4.65s\n",
      "655:\tlearn: 0.1682294\ttotal: 8.84s\tremaining: 4.63s\n",
      "656:\tlearn: 0.1680432\ttotal: 8.85s\tremaining: 4.62s\n",
      "657:\tlearn: 0.1678937\ttotal: 8.86s\tremaining: 4.61s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658:\tlearn: 0.1678524\ttotal: 8.88s\tremaining: 4.59s\n",
      "659:\tlearn: 0.1677690\ttotal: 8.89s\tremaining: 4.58s\n",
      "660:\tlearn: 0.1677228\ttotal: 8.9s\tremaining: 4.57s\n",
      "661:\tlearn: 0.1676685\ttotal: 8.91s\tremaining: 4.55s\n",
      "662:\tlearn: 0.1675904\ttotal: 8.93s\tremaining: 4.54s\n",
      "663:\tlearn: 0.1675148\ttotal: 8.95s\tremaining: 4.53s\n",
      "664:\tlearn: 0.1674615\ttotal: 8.96s\tremaining: 4.51s\n",
      "665:\tlearn: 0.1673485\ttotal: 8.98s\tremaining: 4.5s\n",
      "666:\tlearn: 0.1671791\ttotal: 8.99s\tremaining: 4.49s\n",
      "667:\tlearn: 0.1671242\ttotal: 9s\tremaining: 4.47s\n",
      "668:\tlearn: 0.1670725\ttotal: 9.01s\tremaining: 4.46s\n",
      "669:\tlearn: 0.1669606\ttotal: 9.03s\tremaining: 4.45s\n",
      "670:\tlearn: 0.1668853\ttotal: 9.04s\tremaining: 4.43s\n",
      "671:\tlearn: 0.1668207\ttotal: 9.06s\tremaining: 4.42s\n",
      "672:\tlearn: 0.1667610\ttotal: 9.08s\tremaining: 4.41s\n",
      "673:\tlearn: 0.1667138\ttotal: 9.09s\tremaining: 4.4s\n",
      "674:\tlearn: 0.1666659\ttotal: 9.1s\tremaining: 4.38s\n",
      "675:\tlearn: 0.1665988\ttotal: 9.11s\tremaining: 4.37s\n",
      "676:\tlearn: 0.1665210\ttotal: 9.12s\tremaining: 4.35s\n",
      "677:\tlearn: 0.1664384\ttotal: 9.14s\tremaining: 4.34s\n",
      "678:\tlearn: 0.1663813\ttotal: 9.15s\tremaining: 4.32s\n",
      "679:\tlearn: 0.1663177\ttotal: 9.16s\tremaining: 4.31s\n",
      "680:\tlearn: 0.1662419\ttotal: 9.17s\tremaining: 4.3s\n",
      "681:\tlearn: 0.1661881\ttotal: 9.18s\tremaining: 4.28s\n",
      "682:\tlearn: 0.1660697\ttotal: 9.2s\tremaining: 4.27s\n",
      "683:\tlearn: 0.1659729\ttotal: 9.21s\tremaining: 4.25s\n",
      "684:\tlearn: 0.1659219\ttotal: 9.22s\tremaining: 4.24s\n",
      "685:\tlearn: 0.1657837\ttotal: 9.23s\tremaining: 4.23s\n",
      "686:\tlearn: 0.1656851\ttotal: 9.25s\tremaining: 4.21s\n",
      "687:\tlearn: 0.1655973\ttotal: 9.26s\tremaining: 4.2s\n",
      "688:\tlearn: 0.1655419\ttotal: 9.28s\tremaining: 4.19s\n",
      "689:\tlearn: 0.1654264\ttotal: 9.29s\tremaining: 4.17s\n",
      "690:\tlearn: 0.1653371\ttotal: 9.3s\tremaining: 4.16s\n",
      "691:\tlearn: 0.1652523\ttotal: 9.32s\tremaining: 4.15s\n",
      "692:\tlearn: 0.1652187\ttotal: 9.34s\tremaining: 4.14s\n",
      "693:\tlearn: 0.1651084\ttotal: 9.36s\tremaining: 4.13s\n",
      "694:\tlearn: 0.1650383\ttotal: 9.37s\tremaining: 4.11s\n",
      "695:\tlearn: 0.1650106\ttotal: 9.39s\tremaining: 4.1s\n",
      "696:\tlearn: 0.1649497\ttotal: 9.41s\tremaining: 4.09s\n",
      "697:\tlearn: 0.1648485\ttotal: 9.42s\tremaining: 4.08s\n",
      "698:\tlearn: 0.1648052\ttotal: 9.44s\tremaining: 4.07s\n",
      "699:\tlearn: 0.1647360\ttotal: 9.46s\tremaining: 4.05s\n",
      "700:\tlearn: 0.1646267\ttotal: 9.47s\tremaining: 4.04s\n",
      "701:\tlearn: 0.1645797\ttotal: 9.49s\tremaining: 4.03s\n",
      "702:\tlearn: 0.1645200\ttotal: 9.5s\tremaining: 4.01s\n",
      "703:\tlearn: 0.1644359\ttotal: 9.51s\tremaining: 4s\n",
      "704:\tlearn: 0.1643384\ttotal: 9.52s\tremaining: 3.98s\n",
      "705:\tlearn: 0.1643303\ttotal: 9.54s\tremaining: 3.97s\n",
      "706:\tlearn: 0.1642151\ttotal: 9.55s\tremaining: 3.96s\n",
      "707:\tlearn: 0.1641295\ttotal: 9.56s\tremaining: 3.94s\n",
      "708:\tlearn: 0.1640905\ttotal: 9.57s\tremaining: 3.93s\n",
      "709:\tlearn: 0.1640633\ttotal: 9.58s\tremaining: 3.91s\n",
      "710:\tlearn: 0.1639870\ttotal: 9.59s\tremaining: 3.9s\n",
      "711:\tlearn: 0.1639214\ttotal: 9.61s\tremaining: 3.89s\n",
      "712:\tlearn: 0.1638575\ttotal: 9.62s\tremaining: 3.87s\n",
      "713:\tlearn: 0.1638237\ttotal: 9.63s\tremaining: 3.86s\n",
      "714:\tlearn: 0.1637527\ttotal: 9.64s\tremaining: 3.84s\n",
      "715:\tlearn: 0.1636863\ttotal: 9.66s\tremaining: 3.83s\n",
      "716:\tlearn: 0.1635669\ttotal: 9.67s\tremaining: 3.82s\n",
      "717:\tlearn: 0.1634492\ttotal: 9.68s\tremaining: 3.8s\n",
      "718:\tlearn: 0.1634111\ttotal: 9.69s\tremaining: 3.79s\n",
      "719:\tlearn: 0.1633720\ttotal: 9.71s\tremaining: 3.77s\n",
      "720:\tlearn: 0.1632632\ttotal: 9.72s\tremaining: 3.76s\n",
      "721:\tlearn: 0.1632046\ttotal: 9.73s\tremaining: 3.75s\n",
      "722:\tlearn: 0.1631507\ttotal: 9.74s\tremaining: 3.73s\n",
      "723:\tlearn: 0.1631001\ttotal: 9.76s\tremaining: 3.72s\n",
      "724:\tlearn: 0.1629764\ttotal: 9.77s\tremaining: 3.71s\n",
      "725:\tlearn: 0.1628752\ttotal: 9.79s\tremaining: 3.69s\n",
      "726:\tlearn: 0.1627658\ttotal: 9.8s\tremaining: 3.68s\n",
      "727:\tlearn: 0.1626814\ttotal: 9.81s\tremaining: 3.67s\n",
      "728:\tlearn: 0.1626370\ttotal: 9.82s\tremaining: 3.65s\n",
      "729:\tlearn: 0.1625384\ttotal: 9.83s\tremaining: 3.64s\n",
      "730:\tlearn: 0.1624798\ttotal: 9.85s\tremaining: 3.62s\n",
      "731:\tlearn: 0.1623869\ttotal: 9.86s\tremaining: 3.61s\n",
      "732:\tlearn: 0.1622853\ttotal: 9.87s\tremaining: 3.6s\n",
      "733:\tlearn: 0.1622110\ttotal: 9.88s\tremaining: 3.58s\n",
      "734:\tlearn: 0.1621505\ttotal: 9.9s\tremaining: 3.57s\n",
      "735:\tlearn: 0.1620927\ttotal: 9.91s\tremaining: 3.56s\n",
      "736:\tlearn: 0.1619510\ttotal: 9.93s\tremaining: 3.54s\n",
      "737:\tlearn: 0.1619231\ttotal: 9.94s\tremaining: 3.53s\n",
      "738:\tlearn: 0.1618678\ttotal: 9.96s\tremaining: 3.52s\n",
      "739:\tlearn: 0.1618022\ttotal: 9.97s\tremaining: 3.5s\n",
      "740:\tlearn: 0.1617333\ttotal: 9.99s\tremaining: 3.49s\n",
      "741:\tlearn: 0.1616852\ttotal: 10s\tremaining: 3.48s\n",
      "742:\tlearn: 0.1616254\ttotal: 10s\tremaining: 3.46s\n",
      "743:\tlearn: 0.1615782\ttotal: 10s\tremaining: 3.45s\n",
      "744:\tlearn: 0.1615074\ttotal: 10s\tremaining: 3.44s\n",
      "745:\tlearn: 0.1614611\ttotal: 10.1s\tremaining: 3.42s\n",
      "746:\tlearn: 0.1614154\ttotal: 10.1s\tremaining: 3.41s\n",
      "747:\tlearn: 0.1613333\ttotal: 10.1s\tremaining: 3.4s\n",
      "748:\tlearn: 0.1612834\ttotal: 10.1s\tremaining: 3.38s\n",
      "749:\tlearn: 0.1611853\ttotal: 10.1s\tremaining: 3.37s\n",
      "750:\tlearn: 0.1611212\ttotal: 10.1s\tremaining: 3.36s\n",
      "751:\tlearn: 0.1610736\ttotal: 10.1s\tremaining: 3.35s\n",
      "752:\tlearn: 0.1609914\ttotal: 10.2s\tremaining: 3.33s\n",
      "753:\tlearn: 0.1608793\ttotal: 10.2s\tremaining: 3.32s\n",
      "754:\tlearn: 0.1608050\ttotal: 10.2s\tremaining: 3.31s\n",
      "755:\tlearn: 0.1607202\ttotal: 10.2s\tremaining: 3.29s\n",
      "756:\tlearn: 0.1606632\ttotal: 10.2s\tremaining: 3.28s\n",
      "757:\tlearn: 0.1605951\ttotal: 10.2s\tremaining: 3.27s\n",
      "758:\tlearn: 0.1605262\ttotal: 10.2s\tremaining: 3.25s\n",
      "759:\tlearn: 0.1604741\ttotal: 10.3s\tremaining: 3.24s\n",
      "760:\tlearn: 0.1604228\ttotal: 10.3s\tremaining: 3.23s\n",
      "761:\tlearn: 0.1603679\ttotal: 10.3s\tremaining: 3.21s\n",
      "762:\tlearn: 0.1602707\ttotal: 10.3s\tremaining: 3.2s\n",
      "763:\tlearn: 0.1601693\ttotal: 10.3s\tremaining: 3.19s\n",
      "764:\tlearn: 0.1601201\ttotal: 10.3s\tremaining: 3.17s\n",
      "765:\tlearn: 0.1600454\ttotal: 10.3s\tremaining: 3.16s\n",
      "766:\tlearn: 0.1599608\ttotal: 10.4s\tremaining: 3.15s\n",
      "767:\tlearn: 0.1598616\ttotal: 10.4s\tremaining: 3.14s\n",
      "768:\tlearn: 0.1597883\ttotal: 10.4s\tremaining: 3.12s\n",
      "769:\tlearn: 0.1597414\ttotal: 10.4s\tremaining: 3.11s\n",
      "770:\tlearn: 0.1596677\ttotal: 10.4s\tremaining: 3.1s\n",
      "771:\tlearn: 0.1595937\ttotal: 10.4s\tremaining: 3.08s\n",
      "772:\tlearn: 0.1595374\ttotal: 10.5s\tremaining: 3.07s\n",
      "773:\tlearn: 0.1594567\ttotal: 10.5s\tremaining: 3.06s\n",
      "774:\tlearn: 0.1593557\ttotal: 10.5s\tremaining: 3.04s\n",
      "775:\tlearn: 0.1592434\ttotal: 10.5s\tremaining: 3.03s\n",
      "776:\tlearn: 0.1591971\ttotal: 10.5s\tremaining: 3.02s\n",
      "777:\tlearn: 0.1591486\ttotal: 10.5s\tremaining: 3.01s\n",
      "778:\tlearn: 0.1590634\ttotal: 10.6s\tremaining: 3s\n",
      "779:\tlearn: 0.1590154\ttotal: 10.6s\tremaining: 2.98s\n",
      "780:\tlearn: 0.1589243\ttotal: 10.6s\tremaining: 2.97s\n",
      "781:\tlearn: 0.1588394\ttotal: 10.6s\tremaining: 2.96s\n",
      "782:\tlearn: 0.1587965\ttotal: 10.6s\tremaining: 2.94s\n",
      "783:\tlearn: 0.1587456\ttotal: 10.6s\tremaining: 2.93s\n",
      "784:\tlearn: 0.1586559\ttotal: 10.6s\tremaining: 2.92s\n",
      "785:\tlearn: 0.1586027\ttotal: 10.7s\tremaining: 2.9s\n",
      "786:\tlearn: 0.1585531\ttotal: 10.7s\tremaining: 2.89s\n",
      "787:\tlearn: 0.1584994\ttotal: 10.7s\tremaining: 2.88s\n",
      "788:\tlearn: 0.1584182\ttotal: 10.7s\tremaining: 2.87s\n",
      "789:\tlearn: 0.1583560\ttotal: 10.7s\tremaining: 2.85s\n",
      "790:\tlearn: 0.1583129\ttotal: 10.7s\tremaining: 2.84s\n",
      "791:\tlearn: 0.1582475\ttotal: 10.8s\tremaining: 2.83s\n",
      "792:\tlearn: 0.1581757\ttotal: 10.8s\tremaining: 2.81s\n",
      "793:\tlearn: 0.1581302\ttotal: 10.8s\tremaining: 2.8s\n",
      "794:\tlearn: 0.1579822\ttotal: 10.8s\tremaining: 2.79s\n",
      "795:\tlearn: 0.1577310\ttotal: 10.8s\tremaining: 2.77s\n",
      "796:\tlearn: 0.1576738\ttotal: 10.8s\tremaining: 2.76s\n",
      "797:\tlearn: 0.1575464\ttotal: 10.9s\tremaining: 2.75s\n",
      "798:\tlearn: 0.1574221\ttotal: 10.9s\tremaining: 2.74s\n",
      "799:\tlearn: 0.1573709\ttotal: 10.9s\tremaining: 2.72s\n",
      "800:\tlearn: 0.1572892\ttotal: 10.9s\tremaining: 2.71s\n",
      "801:\tlearn: 0.1572473\ttotal: 10.9s\tremaining: 2.69s\n",
      "802:\tlearn: 0.1571177\ttotal: 10.9s\tremaining: 2.69s\n",
      "803:\tlearn: 0.1570714\ttotal: 11s\tremaining: 2.67s\n",
      "804:\tlearn: 0.1570173\ttotal: 11s\tremaining: 2.66s\n",
      "805:\tlearn: 0.1569409\ttotal: 11s\tremaining: 2.64s\n",
      "806:\tlearn: 0.1568779\ttotal: 11s\tremaining: 2.63s\n",
      "807:\tlearn: 0.1567956\ttotal: 11s\tremaining: 2.62s\n",
      "808:\tlearn: 0.1567689\ttotal: 11s\tremaining: 2.6s\n",
      "809:\tlearn: 0.1566694\ttotal: 11.1s\tremaining: 2.59s\n",
      "810:\tlearn: 0.1565650\ttotal: 11.1s\tremaining: 2.58s\n",
      "811:\tlearn: 0.1565043\ttotal: 11.1s\tremaining: 2.56s\n",
      "812:\tlearn: 0.1564755\ttotal: 11.1s\tremaining: 2.55s\n",
      "813:\tlearn: 0.1564052\ttotal: 11.1s\tremaining: 2.54s\n",
      "814:\tlearn: 0.1563486\ttotal: 11.1s\tremaining: 2.52s\n",
      "815:\tlearn: 0.1562435\ttotal: 11.1s\tremaining: 2.51s\n",
      "816:\tlearn: 0.1561997\ttotal: 11.2s\tremaining: 2.5s\n",
      "817:\tlearn: 0.1561436\ttotal: 11.2s\tremaining: 2.48s\n",
      "818:\tlearn: 0.1560683\ttotal: 11.2s\tremaining: 2.47s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "819:\tlearn: 0.1559667\ttotal: 11.2s\tremaining: 2.46s\n",
      "820:\tlearn: 0.1558632\ttotal: 11.2s\tremaining: 2.44s\n",
      "821:\tlearn: 0.1558084\ttotal: 11.2s\tremaining: 2.43s\n",
      "822:\tlearn: 0.1556762\ttotal: 11.2s\tremaining: 2.42s\n",
      "823:\tlearn: 0.1556248\ttotal: 11.3s\tremaining: 2.4s\n",
      "824:\tlearn: 0.1555769\ttotal: 11.3s\tremaining: 2.39s\n",
      "825:\tlearn: 0.1555102\ttotal: 11.3s\tremaining: 2.38s\n",
      "826:\tlearn: 0.1554052\ttotal: 11.3s\tremaining: 2.36s\n",
      "827:\tlearn: 0.1553446\ttotal: 11.3s\tremaining: 2.35s\n",
      "828:\tlearn: 0.1553073\ttotal: 11.3s\tremaining: 2.34s\n",
      "829:\tlearn: 0.1552310\ttotal: 11.3s\tremaining: 2.32s\n",
      "830:\tlearn: 0.1551511\ttotal: 11.4s\tremaining: 2.31s\n",
      "831:\tlearn: 0.1550814\ttotal: 11.4s\tremaining: 2.3s\n",
      "832:\tlearn: 0.1550346\ttotal: 11.4s\tremaining: 2.29s\n",
      "833:\tlearn: 0.1549964\ttotal: 11.4s\tremaining: 2.27s\n",
      "834:\tlearn: 0.1549586\ttotal: 11.4s\tremaining: 2.26s\n",
      "835:\tlearn: 0.1548969\ttotal: 11.5s\tremaining: 2.25s\n",
      "836:\tlearn: 0.1548603\ttotal: 11.5s\tremaining: 2.23s\n",
      "837:\tlearn: 0.1547281\ttotal: 11.5s\tremaining: 2.22s\n",
      "838:\tlearn: 0.1546861\ttotal: 11.5s\tremaining: 2.21s\n",
      "839:\tlearn: 0.1546005\ttotal: 11.5s\tremaining: 2.19s\n",
      "840:\tlearn: 0.1545045\ttotal: 11.5s\tremaining: 2.18s\n",
      "841:\tlearn: 0.1543855\ttotal: 11.5s\tremaining: 2.17s\n",
      "842:\tlearn: 0.1543171\ttotal: 11.6s\tremaining: 2.15s\n",
      "843:\tlearn: 0.1542739\ttotal: 11.6s\tremaining: 2.14s\n",
      "844:\tlearn: 0.1542211\ttotal: 11.6s\tremaining: 2.12s\n",
      "845:\tlearn: 0.1541719\ttotal: 11.6s\tremaining: 2.11s\n",
      "846:\tlearn: 0.1541242\ttotal: 11.6s\tremaining: 2.1s\n",
      "847:\tlearn: 0.1540701\ttotal: 11.6s\tremaining: 2.08s\n",
      "848:\tlearn: 0.1540244\ttotal: 11.6s\tremaining: 2.07s\n",
      "849:\tlearn: 0.1539425\ttotal: 11.7s\tremaining: 2.06s\n",
      "850:\tlearn: 0.1538862\ttotal: 11.7s\tremaining: 2.04s\n",
      "851:\tlearn: 0.1537968\ttotal: 11.7s\tremaining: 2.03s\n",
      "852:\tlearn: 0.1537078\ttotal: 11.7s\tremaining: 2.01s\n",
      "853:\tlearn: 0.1536767\ttotal: 11.7s\tremaining: 2s\n",
      "854:\tlearn: 0.1536197\ttotal: 11.7s\tremaining: 1.99s\n",
      "855:\tlearn: 0.1535695\ttotal: 11.7s\tremaining: 1.97s\n",
      "856:\tlearn: 0.1535247\ttotal: 11.7s\tremaining: 1.96s\n",
      "857:\tlearn: 0.1534485\ttotal: 11.8s\tremaining: 1.95s\n",
      "858:\tlearn: 0.1534115\ttotal: 11.8s\tremaining: 1.93s\n",
      "859:\tlearn: 0.1533050\ttotal: 11.8s\tremaining: 1.92s\n",
      "860:\tlearn: 0.1531918\ttotal: 11.8s\tremaining: 1.91s\n",
      "861:\tlearn: 0.1531069\ttotal: 11.8s\tremaining: 1.89s\n",
      "862:\tlearn: 0.1530916\ttotal: 11.8s\tremaining: 1.88s\n",
      "863:\tlearn: 0.1529882\ttotal: 11.8s\tremaining: 1.86s\n",
      "864:\tlearn: 0.1529302\ttotal: 11.9s\tremaining: 1.85s\n",
      "865:\tlearn: 0.1528852\ttotal: 11.9s\tremaining: 1.84s\n",
      "866:\tlearn: 0.1528393\ttotal: 11.9s\tremaining: 1.82s\n",
      "867:\tlearn: 0.1527975\ttotal: 11.9s\tremaining: 1.81s\n",
      "868:\tlearn: 0.1527283\ttotal: 11.9s\tremaining: 1.8s\n",
      "869:\tlearn: 0.1527087\ttotal: 11.9s\tremaining: 1.78s\n",
      "870:\tlearn: 0.1526185\ttotal: 12s\tremaining: 1.77s\n",
      "871:\tlearn: 0.1525515\ttotal: 12s\tremaining: 1.76s\n",
      "872:\tlearn: 0.1525112\ttotal: 12s\tremaining: 1.74s\n",
      "873:\tlearn: 0.1524924\ttotal: 12s\tremaining: 1.73s\n",
      "874:\tlearn: 0.1524137\ttotal: 12s\tremaining: 1.72s\n",
      "875:\tlearn: 0.1523224\ttotal: 12s\tremaining: 1.7s\n",
      "876:\tlearn: 0.1522808\ttotal: 12s\tremaining: 1.69s\n",
      "877:\tlearn: 0.1522009\ttotal: 12s\tremaining: 1.67s\n",
      "878:\tlearn: 0.1521478\ttotal: 12.1s\tremaining: 1.66s\n",
      "879:\tlearn: 0.1521048\ttotal: 12.1s\tremaining: 1.65s\n",
      "880:\tlearn: 0.1520411\ttotal: 12.1s\tremaining: 1.63s\n",
      "881:\tlearn: 0.1519744\ttotal: 12.1s\tremaining: 1.62s\n",
      "882:\tlearn: 0.1518885\ttotal: 12.1s\tremaining: 1.61s\n",
      "883:\tlearn: 0.1517917\ttotal: 12.1s\tremaining: 1.59s\n",
      "884:\tlearn: 0.1516861\ttotal: 12.2s\tremaining: 1.58s\n",
      "885:\tlearn: 0.1516064\ttotal: 12.2s\tremaining: 1.56s\n",
      "886:\tlearn: 0.1515591\ttotal: 12.2s\tremaining: 1.55s\n",
      "887:\tlearn: 0.1514902\ttotal: 12.2s\tremaining: 1.54s\n",
      "888:\tlearn: 0.1514196\ttotal: 12.2s\tremaining: 1.52s\n",
      "889:\tlearn: 0.1513952\ttotal: 12.2s\tremaining: 1.51s\n",
      "890:\tlearn: 0.1513657\ttotal: 12.2s\tremaining: 1.5s\n",
      "891:\tlearn: 0.1513126\ttotal: 12.3s\tremaining: 1.48s\n",
      "892:\tlearn: 0.1512561\ttotal: 12.3s\tremaining: 1.47s\n",
      "893:\tlearn: 0.1511772\ttotal: 12.3s\tremaining: 1.46s\n",
      "894:\tlearn: 0.1511094\ttotal: 12.3s\tremaining: 1.44s\n",
      "895:\tlearn: 0.1510630\ttotal: 12.3s\tremaining: 1.43s\n",
      "896:\tlearn: 0.1510096\ttotal: 12.3s\tremaining: 1.42s\n",
      "897:\tlearn: 0.1509709\ttotal: 12.3s\tremaining: 1.4s\n",
      "898:\tlearn: 0.1509055\ttotal: 12.4s\tremaining: 1.39s\n",
      "899:\tlearn: 0.1508382\ttotal: 12.4s\tremaining: 1.37s\n",
      "900:\tlearn: 0.1508155\ttotal: 12.4s\tremaining: 1.36s\n",
      "901:\tlearn: 0.1507854\ttotal: 12.4s\tremaining: 1.35s\n",
      "902:\tlearn: 0.1507577\ttotal: 12.4s\tremaining: 1.33s\n",
      "903:\tlearn: 0.1507053\ttotal: 12.4s\tremaining: 1.32s\n",
      "904:\tlearn: 0.1506337\ttotal: 12.5s\tremaining: 1.31s\n",
      "905:\tlearn: 0.1505853\ttotal: 12.5s\tremaining: 1.29s\n",
      "906:\tlearn: 0.1505184\ttotal: 12.5s\tremaining: 1.28s\n",
      "907:\tlearn: 0.1504917\ttotal: 12.5s\tremaining: 1.27s\n",
      "908:\tlearn: 0.1504547\ttotal: 12.5s\tremaining: 1.25s\n",
      "909:\tlearn: 0.1503809\ttotal: 12.5s\tremaining: 1.24s\n",
      "910:\tlearn: 0.1503273\ttotal: 12.5s\tremaining: 1.22s\n",
      "911:\tlearn: 0.1502635\ttotal: 12.6s\tremaining: 1.21s\n",
      "912:\tlearn: 0.1502053\ttotal: 12.6s\tremaining: 1.2s\n",
      "913:\tlearn: 0.1501603\ttotal: 12.6s\tremaining: 1.18s\n",
      "914:\tlearn: 0.1501109\ttotal: 12.6s\tremaining: 1.17s\n",
      "915:\tlearn: 0.1500555\ttotal: 12.6s\tremaining: 1.16s\n",
      "916:\tlearn: 0.1499519\ttotal: 12.6s\tremaining: 1.14s\n",
      "917:\tlearn: 0.1499065\ttotal: 12.6s\tremaining: 1.13s\n",
      "918:\tlearn: 0.1498609\ttotal: 12.7s\tremaining: 1.12s\n",
      "919:\tlearn: 0.1498271\ttotal: 12.7s\tremaining: 1.1s\n",
      "920:\tlearn: 0.1497832\ttotal: 12.7s\tremaining: 1.09s\n",
      "921:\tlearn: 0.1497065\ttotal: 12.7s\tremaining: 1.07s\n",
      "922:\tlearn: 0.1496092\ttotal: 12.7s\tremaining: 1.06s\n",
      "923:\tlearn: 0.1495478\ttotal: 12.7s\tremaining: 1.05s\n",
      "924:\tlearn: 0.1494884\ttotal: 12.8s\tremaining: 1.03s\n",
      "925:\tlearn: 0.1494517\ttotal: 12.8s\tremaining: 1.02s\n",
      "926:\tlearn: 0.1494303\ttotal: 12.8s\tremaining: 1.01s\n",
      "927:\tlearn: 0.1493994\ttotal: 12.8s\tremaining: 994ms\n",
      "928:\tlearn: 0.1493444\ttotal: 12.8s\tremaining: 980ms\n",
      "929:\tlearn: 0.1492742\ttotal: 12.8s\tremaining: 967ms\n",
      "930:\tlearn: 0.1492267\ttotal: 12.9s\tremaining: 953ms\n",
      "931:\tlearn: 0.1491656\ttotal: 12.9s\tremaining: 939ms\n",
      "932:\tlearn: 0.1491187\ttotal: 12.9s\tremaining: 925ms\n",
      "933:\tlearn: 0.1490376\ttotal: 12.9s\tremaining: 911ms\n",
      "934:\tlearn: 0.1489833\ttotal: 12.9s\tremaining: 898ms\n",
      "935:\tlearn: 0.1489617\ttotal: 12.9s\tremaining: 884ms\n",
      "936:\tlearn: 0.1489209\ttotal: 12.9s\tremaining: 870ms\n",
      "937:\tlearn: 0.1488508\ttotal: 13s\tremaining: 856ms\n",
      "938:\tlearn: 0.1488090\ttotal: 13s\tremaining: 842ms\n",
      "939:\tlearn: 0.1487063\ttotal: 13s\tremaining: 829ms\n",
      "940:\tlearn: 0.1486384\ttotal: 13s\tremaining: 815ms\n",
      "941:\tlearn: 0.1486100\ttotal: 13s\tremaining: 801ms\n",
      "942:\tlearn: 0.1485874\ttotal: 13s\tremaining: 787ms\n",
      "943:\tlearn: 0.1485206\ttotal: 13s\tremaining: 773ms\n",
      "944:\tlearn: 0.1484568\ttotal: 13.1s\tremaining: 760ms\n",
      "945:\tlearn: 0.1483818\ttotal: 13.1s\tremaining: 746ms\n",
      "946:\tlearn: 0.1482980\ttotal: 13.1s\tremaining: 732ms\n",
      "947:\tlearn: 0.1482415\ttotal: 13.1s\tremaining: 718ms\n",
      "948:\tlearn: 0.1481862\ttotal: 13.1s\tremaining: 705ms\n",
      "949:\tlearn: 0.1481493\ttotal: 13.1s\tremaining: 691ms\n",
      "950:\tlearn: 0.1480860\ttotal: 13.1s\tremaining: 677ms\n",
      "951:\tlearn: 0.1480334\ttotal: 13.2s\tremaining: 664ms\n",
      "952:\tlearn: 0.1479278\ttotal: 13.2s\tremaining: 650ms\n",
      "953:\tlearn: 0.1478833\ttotal: 13.2s\tremaining: 636ms\n",
      "954:\tlearn: 0.1478168\ttotal: 13.2s\tremaining: 623ms\n",
      "955:\tlearn: 0.1477508\ttotal: 13.2s\tremaining: 609ms\n",
      "956:\tlearn: 0.1477006\ttotal: 13.2s\tremaining: 595ms\n",
      "957:\tlearn: 0.1476794\ttotal: 13.3s\tremaining: 581ms\n",
      "958:\tlearn: 0.1476459\ttotal: 13.3s\tremaining: 568ms\n",
      "959:\tlearn: 0.1476107\ttotal: 13.3s\tremaining: 554ms\n",
      "960:\tlearn: 0.1475579\ttotal: 13.3s\tremaining: 540ms\n",
      "961:\tlearn: 0.1475075\ttotal: 13.3s\tremaining: 526ms\n",
      "962:\tlearn: 0.1474396\ttotal: 13.3s\tremaining: 513ms\n",
      "963:\tlearn: 0.1473311\ttotal: 13.4s\tremaining: 499ms\n",
      "964:\tlearn: 0.1472766\ttotal: 13.4s\tremaining: 485ms\n",
      "965:\tlearn: 0.1472392\ttotal: 13.4s\tremaining: 471ms\n",
      "966:\tlearn: 0.1471494\ttotal: 13.4s\tremaining: 457ms\n",
      "967:\tlearn: 0.1470635\ttotal: 13.4s\tremaining: 443ms\n",
      "968:\tlearn: 0.1469829\ttotal: 13.4s\tremaining: 429ms\n",
      "969:\tlearn: 0.1469395\ttotal: 13.4s\tremaining: 416ms\n",
      "970:\tlearn: 0.1469017\ttotal: 13.5s\tremaining: 402ms\n",
      "971:\tlearn: 0.1468244\ttotal: 13.5s\tremaining: 388ms\n",
      "972:\tlearn: 0.1467680\ttotal: 13.5s\tremaining: 374ms\n",
      "973:\tlearn: 0.1467220\ttotal: 13.5s\tremaining: 360ms\n",
      "974:\tlearn: 0.1467034\ttotal: 13.5s\tremaining: 347ms\n",
      "975:\tlearn: 0.1466572\ttotal: 13.5s\tremaining: 333ms\n",
      "976:\tlearn: 0.1466070\ttotal: 13.5s\tremaining: 319ms\n",
      "977:\tlearn: 0.1465741\ttotal: 13.6s\tremaining: 305ms\n",
      "978:\tlearn: 0.1464661\ttotal: 13.6s\tremaining: 291ms\n",
      "979:\tlearn: 0.1463596\ttotal: 13.6s\tremaining: 277ms\n",
      "980:\tlearn: 0.1463275\ttotal: 13.6s\tremaining: 263ms\n",
      "981:\tlearn: 0.1462790\ttotal: 13.6s\tremaining: 250ms\n",
      "982:\tlearn: 0.1462190\ttotal: 13.6s\tremaining: 236ms\n",
      "983:\tlearn: 0.1461259\ttotal: 13.6s\tremaining: 222ms\n",
      "984:\tlearn: 0.1460617\ttotal: 13.7s\tremaining: 208ms\n",
      "985:\tlearn: 0.1460234\ttotal: 13.7s\tremaining: 194ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "986:\tlearn: 0.1459549\ttotal: 13.7s\tremaining: 180ms\n",
      "987:\tlearn: 0.1459002\ttotal: 13.7s\tremaining: 166ms\n",
      "988:\tlearn: 0.1458276\ttotal: 13.7s\tremaining: 152ms\n",
      "989:\tlearn: 0.1457735\ttotal: 13.7s\tremaining: 139ms\n",
      "990:\tlearn: 0.1457222\ttotal: 13.7s\tremaining: 125ms\n",
      "991:\tlearn: 0.1455915\ttotal: 13.8s\tremaining: 111ms\n",
      "992:\tlearn: 0.1455523\ttotal: 13.8s\tremaining: 97ms\n",
      "993:\tlearn: 0.1454740\ttotal: 13.8s\tremaining: 83.1ms\n",
      "994:\tlearn: 0.1453690\ttotal: 13.8s\tremaining: 69.3ms\n",
      "995:\tlearn: 0.1452960\ttotal: 13.8s\tremaining: 55.4ms\n",
      "996:\tlearn: 0.1452684\ttotal: 13.8s\tremaining: 41.6ms\n",
      "997:\tlearn: 0.1452484\ttotal: 13.8s\tremaining: 27.7ms\n",
      "998:\tlearn: 0.1452207\ttotal: 13.8s\tremaining: 13.9ms\n",
      "999:\tlearn: 0.1451853\ttotal: 13.9s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "from catboost import Pool\n",
    "cat_model= CatBoostClassifier()\n",
    "cat_model.fit(Pool(X_train,y_train))\n",
    "cat = cat_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9219716623428458\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_test,cat))\n",
    "#print(classification_report(y_test,cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cat_model.predict(test_df.drop(['target'],axis =1))\n",
    "sub= ttest[[\"ID\"]]\n",
    "sub['target'] = predictions\n",
    "sub.to_csv('catuu.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.])"
      ]
     },
     "execution_count": 902,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(model,train,label,test,model_name):\n",
    "    mean_train = []\n",
    "    mean_test = []\n",
    "    test_pred = np.zeros(test.shape[0])\n",
    "    val_pred = np.zeros(train.shape[0])\n",
    "    for count, (train_index,test_index) in enumerate(skf.split(train,label)):\n",
    "        x_train,x_test = train.iloc[train_index],train.iloc[test_index]\n",
    "        y_train,y_test = label.iloc[train_index],label.iloc[test_index]\n",
    "        print(f'========================Fold{count +1}==========================')\n",
    "        model.fit(x_train, y_train)\n",
    "        train_predict = model.predict(x_train)\n",
    "        test_predict = model.predict(x_test)\n",
    "        val_pred[test_index] = test_predict\n",
    "        test_pred+= model.predict(test)\n",
    "        \n",
    "        print('\\nValidation scores', f1_score(y_test,test_predict))\n",
    "        print('\\nTraining scores', f1_score(y_train,train_predict))\n",
    "        mean_train.append(f1_score(y_train, train_predict))\n",
    "        mean_test.append(f1_score(y_test,test_predict))\n",
    "    print('Average Testing ROC score for 10 folds split:',np.mean(mean_test))\n",
    "    print('Average Training ROC score for 10 folds split:',np.mean(mean_train))\n",
    "    print('standard Deviation for 10 folds split:',np.std(mean_test))\n",
    "    return val_pred, test_pred, model_name\n",
    "        \n",
    "def Stacking(model,Train_stack,Test_stack,target,file_name):\n",
    "    prediction = model.fit(Train_stack, target).predict(Test_stack)\n",
    "    submission['target'] = prediction\n",
    "    submission.to_csv(file_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb(model,train,label,test,model_name):\n",
    "    mean_train = []\n",
    "    mean_test = []\n",
    "    test_pred = np.zeros(test.shape[0])\n",
    "    val_pred = np.zeros(train.shape[0])\n",
    "    for count, (train_index,test_index) in enumerate(skf.split(train,label)):\n",
    "        x_train,x_test = train.iloc[train_index],train.iloc[test_index]\n",
    "        y_train,y_test = label.iloc[train_index],label.iloc[test_index]\n",
    "        print(f'========================Fold{count +1}==========================')\n",
    "        model.fit(x_train,y_train,eval_set=[(x_test,y_test)],early_stopping_rounds=500,\n",
    "                               verbose=250)\n",
    "        train_predict = model.predict(x_train, num_iteration = model.best_iteration_)\n",
    "        test_predict = model.predict(x_test, num_iteration = model.best_iteration_)\n",
    "        val_pred[test_index] = test_predict\n",
    "        test_pred+= model.predict(test, num_iteration = model.best_iteration_)\n",
    "        \n",
    "        print('\\nValidation scores', f1_score(y_test,test_predict))\n",
    "        print('\\nTraining scores', f1_score(y_train,train_predict))\n",
    "        mean_train.append(f1_score(y_train, train_predict))\n",
    "        mean_test.append(f1_score(y_test,test_predict))\n",
    "    print('Average F1 score for 10 folds split:',np.mean(mean_test))\n",
    "    print('Average Training ROC score for 10 folds split:',np.mean(mean_train))\n",
    "    print('standard Deviation for 10 folds split:',np.std(mean_test))\n",
    "    return val_pred, test_pred, model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================Fold1==========================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\tvalid_0's auc: 0.970902\n",
      "[500]\tvalid_0's auc: 0.970902\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's auc: 0.970964\n",
      "\n",
      "Validation scores 0.9172576832151301\n",
      "\n",
      "Training scores 0.9420005603810591\n",
      "========================Fold2==========================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\tvalid_0's auc: 0.970638\n",
      "[500]\tvalid_0's auc: 0.970638\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's auc: 0.970791\n",
      "\n",
      "Validation scores 0.9207221350078493\n",
      "\n",
      "Training scores 0.9417752670731027\n",
      "========================Fold3==========================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\tvalid_0's auc: 0.973628\n",
      "[500]\tvalid_0's auc: 0.973628\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's auc: 0.973888\n",
      "\n",
      "Validation scores 0.926771653543307\n",
      "\n",
      "Training scores 0.9411698789780368\n",
      "========================Fold4==========================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\tvalid_0's auc: 0.970382\n",
      "[500]\tvalid_0's auc: 0.970382\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.970417\n",
      "\n",
      "Validation scores 0.9221135029354208\n",
      "\n",
      "Training scores 0.9422247128047073\n",
      "========================Fold5==========================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\tvalid_0's auc: 0.969739\n",
      "[500]\tvalid_0's auc: 0.969739\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's auc: 0.969756\n",
      "\n",
      "Validation scores 0.92\n",
      "\n",
      "Training scores 0.9428027759122453\n",
      "========================Fold6==========================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\tvalid_0's auc: 0.974616\n",
      "[500]\tvalid_0's auc: 0.974616\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's auc: 0.97503\n",
      "\n",
      "Validation scores 0.9320695102685623\n",
      "\n",
      "Training scores 0.9387181935628828\n",
      "========================Fold7==========================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\tvalid_0's auc: 0.973842\n",
      "[500]\tvalid_0's auc: 0.973842\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's auc: 0.973861\n",
      "\n",
      "Validation scores 0.9209486166007905\n",
      "\n",
      "Training scores 0.9421404119198609\n",
      "========================Fold8==========================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\tvalid_0's auc: 0.979141\n",
      "[500]\tvalid_0's auc: 0.979141\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's auc: 0.979207\n",
      "\n",
      "Validation scores 0.9347826086956522\n",
      "\n",
      "Training scores 0.9409457642312865\n",
      "Average F1 score for 10 folds split: 0.9243332137833391\n",
      "Average Training ROC score for 10 folds split: 0.9414721956078976\n",
      "standard Deviation for 10 folds split: 0.0058443188715281355\n"
     ]
    }
   ],
   "source": [
    "lgb_model = lgbm.LGBMClassifier(random_state=34, n_estimators=8000, num_leaves=25,reg_lambda=6,reg_alpha=6 ,metric='AUC', learning_rate=0.5,\n",
    "    max_depth=8, class_weight = 'balanced')\n",
    "LGB1_train, LGB1_test, LGB1_name =lgb(lgb_model,X, y, test_df.drop(['target'], axis =1),'lightgbm(1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8., 8., 8., ..., 8., 8., 8.])"
      ]
     },
     "execution_count": 906,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGB1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat(model,train,label,test,model_name):\n",
    "    mean_train = []\n",
    "    mean_test = []\n",
    "    test_pred = np.zeros(test.shape[0])\n",
    "    val_pred = np.zeros(train.shape[0])\n",
    "    for count, (train_index,test_index) in enumerate(skf.split(train,label)):\n",
    "        x_train,x_test = train.iloc[train_index],train.iloc[test_index]\n",
    "        y_train,y_test = label.iloc[train_index],label.iloc[test_index]\n",
    "        print(f'========================Fold{count +1}==========================')\n",
    "        model.fit(x_train,y_train,eval_set=[(x_test,y_test)],early_stopping_rounds=500,\n",
    "                           verbose=250,use_best_model=True)\n",
    "        train_predict = model.predict(x_train)\n",
    "        test_predict = model.predict(x_test)\n",
    "        val_pred[test_index] = test_predict\n",
    "        test_pred+= model.predict(test)\n",
    "        print('\\nTesting scores', f1_score(y_test,test_predict))\n",
    "        print('\\nTraining scores', f1_score(y_train,train_predict))\n",
    "        mean_train.append(f1_score(y_train, train_predict))\n",
    "        mean_test.append(f1_score(y_test,test_predict))\n",
    "    print('Average Testing ROC score for 8 folds split:',np.mean(mean_test))\n",
    "    print('Average Training ROC score for 8 folds split:',np.mean(mean_train))\n",
    "    print('standard Deviation for 8 folds split:',np.std(mean_test))\n",
    "    return val_pred, test_pred, model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================Fold1==========================\n",
      "0:\ttest: 0.8121674\tbest: 0.8121674 (0)\ttotal: 15.5ms\tremaining: 3m 6s\n",
      "250:\ttest: 0.9497211\tbest: 0.9497211 (250)\ttotal: 3.76s\tremaining: 2m 55s\n",
      "500:\ttest: 0.9592273\tbest: 0.9592273 (500)\ttotal: 7.26s\tremaining: 2m 46s\n",
      "750:\ttest: 0.9624563\tbest: 0.9624563 (750)\ttotal: 10.9s\tremaining: 2m 42s\n",
      "1000:\ttest: 0.9646150\tbest: 0.9646150 (1000)\ttotal: 14.5s\tremaining: 2m 39s\n",
      "1250:\ttest: 0.9664646\tbest: 0.9664646 (1250)\ttotal: 17.9s\tremaining: 2m 33s\n",
      "1500:\ttest: 0.9678266\tbest: 0.9678266 (1500)\ttotal: 21.3s\tremaining: 2m 29s\n",
      "1750:\ttest: 0.9690281\tbest: 0.9690281 (1750)\ttotal: 24.8s\tremaining: 2m 25s\n",
      "2000:\ttest: 0.9698622\tbest: 0.9698996 (1982)\ttotal: 28.3s\tremaining: 2m 21s\n",
      "2250:\ttest: 0.9705614\tbest: 0.9705653 (2248)\ttotal: 32.3s\tremaining: 2m 19s\n",
      "2500:\ttest: 0.9709900\tbest: 0.9709900 (2500)\ttotal: 35.5s\tremaining: 2m 14s\n",
      "2750:\ttest: 0.9714017\tbest: 0.9714091 (2742)\ttotal: 38.8s\tremaining: 2m 10s\n",
      "3000:\ttest: 0.9717595\tbest: 0.9717606 (2996)\ttotal: 42.1s\tremaining: 2m 6s\n",
      "3250:\ttest: 0.9719942\tbest: 0.9720050 (3249)\ttotal: 45.4s\tremaining: 2m 2s\n",
      "3500:\ttest: 0.9722284\tbest: 0.9722290 (3495)\ttotal: 48.6s\tremaining: 1m 57s\n",
      "3750:\ttest: 0.9724110\tbest: 0.9724212 (3747)\ttotal: 52.1s\tremaining: 1m 54s\n",
      "4000:\ttest: 0.9726418\tbest: 0.9726480 (3987)\ttotal: 55.5s\tremaining: 1m 51s\n",
      "4250:\ttest: 0.9728085\tbest: 0.9728091 (4241)\ttotal: 58.9s\tremaining: 1m 47s\n",
      "4500:\ttest: 0.9729134\tbest: 0.9729208 (4494)\ttotal: 1m 2s\tremaining: 1m 43s\n",
      "4750:\ttest: 0.9730988\tbest: 0.9730994 (4749)\ttotal: 1m 5s\tremaining: 1m 40s\n",
      "5000:\ttest: 0.9732729\tbest: 0.9732757 (4999)\ttotal: 1m 8s\tremaining: 1m 36s\n",
      "5250:\ttest: 0.9734237\tbest: 0.9734237 (5250)\ttotal: 1m 12s\tremaining: 1m 32s\n",
      "5500:\ttest: 0.9734799\tbest: 0.9734963 (5449)\ttotal: 1m 15s\tremaining: 1m 29s\n",
      "5750:\ttest: 0.9735643\tbest: 0.9735797 (5733)\ttotal: 1m 18s\tremaining: 1m 25s\n",
      "6000:\ttest: 0.9736318\tbest: 0.9736381 (5998)\ttotal: 1m 21s\tremaining: 1m 21s\n",
      "6250:\ttest: 0.9736392\tbest: 0.9736415 (6243)\ttotal: 1m 25s\tremaining: 1m 18s\n",
      "6500:\ttest: 0.9737050\tbest: 0.9737191 (6374)\ttotal: 1m 29s\tremaining: 1m 15s\n",
      "6750:\ttest: 0.9737792\tbest: 0.9737934 (6743)\ttotal: 1m 33s\tremaining: 1m 12s\n",
      "7000:\ttest: 0.9738433\tbest: 0.9738462 (6924)\ttotal: 1m 38s\tremaining: 1m 9s\n",
      "7250:\ttest: 0.9738790\tbest: 0.9738836 (7238)\ttotal: 1m 41s\tremaining: 1m 6s\n",
      "7500:\ttest: 0.9738966\tbest: 0.9739108 (7435)\ttotal: 1m 46s\tremaining: 1m 3s\n",
      "7750:\ttest: 0.9739777\tbest: 0.9739811 (7741)\ttotal: 1m 50s\tremaining: 1m\n",
      "8000:\ttest: 0.9739930\tbest: 0.9740123 (7981)\ttotal: 1m 54s\tremaining: 57.3s\n",
      "8250:\ttest: 0.9740072\tbest: 0.9740265 (8196)\ttotal: 1m 58s\tremaining: 54s\n",
      "8500:\ttest: 0.9740951\tbest: 0.9740951 (8499)\ttotal: 2m 2s\tremaining: 50.6s\n",
      "8750:\ttest: 0.9741297\tbest: 0.9741438 (8734)\ttotal: 2m 6s\tremaining: 47s\n",
      "9000:\ttest: 0.9741705\tbest: 0.9741818 (8997)\ttotal: 2m 10s\tremaining: 43.4s\n",
      "9250:\ttest: 0.9741705\tbest: 0.9741926 (9132)\ttotal: 2m 13s\tremaining: 39.7s\n",
      "9500:\ttest: 0.9742419\tbest: 0.9742470 (9493)\ttotal: 2m 16s\tremaining: 36s\n",
      "9750:\ttest: 0.9742607\tbest: 0.9742981 (9599)\ttotal: 2m 20s\tremaining: 32.3s\n",
      "10000:\ttest: 0.9742487\tbest: 0.9742981 (9599)\ttotal: 2m 23s\tremaining: 28.7s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.9742980771\n",
      "bestIteration = 9599\n",
      "\n",
      "Shrink model to first 9600 iterations.\n",
      "\n",
      "Testing scores 0.9192789968652039\n",
      "\n",
      "Training scores 0.9592855558020856\n",
      "========================Fold2==========================\n",
      "0:\ttest: 0.8148291\tbest: 0.8148291 (0)\ttotal: 16.7ms\tremaining: 3m 20s\n",
      "250:\ttest: 0.9477425\tbest: 0.9477425 (250)\ttotal: 3.43s\tremaining: 2m 40s\n",
      "500:\ttest: 0.9589095\tbest: 0.9589163 (499)\ttotal: 6.71s\tremaining: 2m 33s\n",
      "750:\ttest: 0.9625725\tbest: 0.9625725 (750)\ttotal: 10s\tremaining: 2m 30s\n",
      "1000:\ttest: 0.9648593\tbest: 0.9648593 (1000)\ttotal: 13.4s\tremaining: 2m 27s\n",
      "1250:\ttest: 0.9665020\tbest: 0.9665020 (1249)\ttotal: 16.7s\tremaining: 2m 23s\n",
      "1500:\ttest: 0.9676508\tbest: 0.9676508 (1500)\ttotal: 20.1s\tremaining: 2m 20s\n",
      "1750:\ttest: 0.9686822\tbest: 0.9686822 (1750)\ttotal: 23.4s\tremaining: 2m 17s\n",
      "2000:\ttest: 0.9693383\tbest: 0.9693383 (2000)\ttotal: 26.8s\tremaining: 2m 13s\n",
      "2250:\ttest: 0.9699541\tbest: 0.9699598 (2249)\ttotal: 30.2s\tremaining: 2m 10s\n",
      "2500:\ttest: 0.9704054\tbest: 0.9704054 (2500)\ttotal: 33.7s\tremaining: 2m 7s\n",
      "2750:\ttest: 0.9707281\tbest: 0.9707309 (2742)\ttotal: 37.4s\tremaining: 2m 5s\n",
      "3000:\ttest: 0.9709696\tbest: 0.9709855 (2990)\ttotal: 40.8s\tremaining: 2m 2s\n",
      "3250:\ttest: 0.9712582\tbest: 0.9712594 (3186)\ttotal: 44.2s\tremaining: 1m 58s\n",
      "3500:\ttest: 0.9714346\tbest: 0.9714363 (3499)\ttotal: 47.5s\tremaining: 1m 55s\n",
      "3750:\ttest: 0.9716245\tbest: 0.9716410 (3737)\ttotal: 50.9s\tremaining: 1m 51s\n",
      "4000:\ttest: 0.9717640\tbest: 0.9717725 (3988)\ttotal: 54.3s\tremaining: 1m 48s\n",
      "4250:\ttest: 0.9719443\tbest: 0.9719631 (4222)\ttotal: 57.6s\tremaining: 1m 45s\n",
      "4500:\ttest: 0.9721162\tbest: 0.9721292 (4494)\ttotal: 1m\tremaining: 1m 41s\n",
      "4750:\ttest: 0.9722528\tbest: 0.9722653 (4739)\ttotal: 1m 4s\tremaining: 1m 38s\n",
      "5000:\ttest: 0.9723963\tbest: 0.9723974 (4997)\ttotal: 1m 7s\tremaining: 1m 34s\n",
      "5250:\ttest: 0.9724456\tbest: 0.9724666 (5208)\ttotal: 1m 11s\tremaining: 1m 31s\n",
      "5500:\ttest: 0.9725698\tbest: 0.9725823 (5489)\ttotal: 1m 14s\tremaining: 1m 27s\n",
      "5750:\ttest: 0.9726429\tbest: 0.9726486 (5744)\ttotal: 1m 17s\tremaining: 1m 24s\n",
      "6000:\ttest: 0.9727427\tbest: 0.9727427 (6000)\ttotal: 1m 21s\tremaining: 1m 21s\n",
      "6250:\ttest: 0.9727376\tbest: 0.9727518 (6228)\ttotal: 1m 24s\tremaining: 1m 17s\n",
      "6500:\ttest: 0.9728028\tbest: 0.9728028 (6500)\ttotal: 1m 28s\tremaining: 1m 14s\n",
      "6750:\ttest: 0.9728731\tbest: 0.9728731 (6750)\ttotal: 1m 31s\tremaining: 1m 11s\n",
      "7000:\ttest: 0.9729134\tbest: 0.9729174 (6985)\ttotal: 1m 34s\tremaining: 1m 7s\n",
      "7250:\ttest: 0.9729480\tbest: 0.9729985 (7202)\ttotal: 1m 38s\tremaining: 1m 4s\n",
      "7500:\ttest: 0.9729707\tbest: 0.9729985 (7202)\ttotal: 1m 41s\tremaining: 1m 1s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.9729984509\n",
      "bestIteration = 7202\n",
      "\n",
      "Shrink model to first 7203 iterations.\n",
      "\n",
      "Testing scores 0.9222309505106049\n",
      "\n",
      "Training scores 0.951987955166453\n",
      "========================Fold3==========================\n",
      "0:\ttest: 0.8035069\tbest: 0.8035069 (0)\ttotal: 14.6ms\tremaining: 2m 55s\n",
      "250:\ttest: 0.9522566\tbest: 0.9522566 (250)\ttotal: 3.35s\tremaining: 2m 36s\n",
      "500:\ttest: 0.9642231\tbest: 0.9642231 (500)\ttotal: 6.67s\tremaining: 2m 32s\n",
      "750:\ttest: 0.9683970\tbest: 0.9683970 (750)\ttotal: 10s\tremaining: 2m 30s\n",
      "1000:\ttest: 0.9704366\tbest: 0.9704366 (1000)\ttotal: 13.4s\tremaining: 2m 27s\n",
      "1250:\ttest: 0.9719500\tbest: 0.9719512 (1238)\ttotal: 16.8s\tremaining: 2m 24s\n",
      "1500:\ttest: 0.9733483\tbest: 0.9733551 (1497)\ttotal: 20.1s\tremaining: 2m 20s\n",
      "1750:\ttest: 0.9745402\tbest: 0.9745402 (1750)\ttotal: 23.4s\tremaining: 2m 17s\n",
      "2000:\ttest: 0.9752359\tbest: 0.9752359 (2000)\ttotal: 26.7s\tremaining: 2m 13s\n",
      "2250:\ttest: 0.9757990\tbest: 0.9758047 (2249)\ttotal: 30.1s\tremaining: 2m 10s\n",
      "2500:\ttest: 0.9762804\tbest: 0.9762827 (2498)\ttotal: 33.5s\tremaining: 2m 7s\n",
      "2750:\ttest: 0.9766331\tbest: 0.9766331 (2750)\ttotal: 36.9s\tremaining: 2m 3s\n",
      "3000:\ttest: 0.9768854\tbest: 0.9768985 (2986)\ttotal: 40.3s\tremaining: 2m\n",
      "3250:\ttest: 0.9769455\tbest: 0.9769608 (3166)\ttotal: 43.6s\tremaining: 1m 57s\n",
      "3500:\ttest: 0.9770901\tbest: 0.9770958 (3498)\ttotal: 46.9s\tremaining: 1m 53s\n",
      "3750:\ttest: 0.9772341\tbest: 0.9772449 (3739)\ttotal: 50.3s\tremaining: 1m 50s\n",
      "4000:\ttest: 0.9773056\tbest: 0.9773124 (3996)\ttotal: 53.7s\tremaining: 1m 47s\n",
      "4250:\ttest: 0.9773804\tbest: 0.9773838 (4231)\ttotal: 57.3s\tremaining: 1m 44s\n",
      "4500:\ttest: 0.9774230\tbest: 0.9774230 (4499)\ttotal: 1m\tremaining: 1m 41s\n",
      "4750:\ttest: 0.9774553\tbest: 0.9774797 (4740)\ttotal: 1m 4s\tremaining: 1m 37s\n",
      "5000:\ttest: 0.9774729\tbest: 0.9774893 (4991)\ttotal: 1m 7s\tremaining: 1m 34s\n",
      "5250:\ttest: 0.9775846\tbest: 0.9776055 (5205)\ttotal: 1m 10s\tremaining: 1m 31s\n",
      "5500:\ttest: 0.9775693\tbest: 0.9776055 (5205)\ttotal: 1m 14s\tremaining: 1m 27s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.9776055464\n",
      "bestIteration = 5205\n",
      "\n",
      "Shrink model to first 5206 iterations.\n",
      "\n",
      "Testing scores 0.9289099526066351\n",
      "\n",
      "Training scores 0.9454239191465469\n",
      "========================Fold4==========================\n",
      "0:\ttest: 0.8123838\tbest: 0.8123838 (0)\ttotal: 15ms\tremaining: 3m\n",
      "250:\ttest: 0.9429111\tbest: 0.9429111 (250)\ttotal: 3.42s\tremaining: 2m 40s\n",
      "500:\ttest: 0.9540527\tbest: 0.9540527 (500)\ttotal: 6.74s\tremaining: 2m 34s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750:\ttest: 0.9597343\tbest: 0.9597377 (749)\ttotal: 10.1s\tremaining: 2m 31s\n",
      "1000:\ttest: 0.9628688\tbest: 0.9628688 (1000)\ttotal: 13.5s\tremaining: 2m 28s\n",
      "1250:\ttest: 0.9654204\tbest: 0.9654204 (1250)\ttotal: 16.9s\tremaining: 2m 24s\n",
      "1500:\ttest: 0.9675133\tbest: 0.9675133 (1500)\ttotal: 20.3s\tremaining: 2m 22s\n",
      "1750:\ttest: 0.9690250\tbest: 0.9690250 (1750)\ttotal: 23.7s\tremaining: 2m 18s\n",
      "2000:\ttest: 0.9701795\tbest: 0.9701795 (2000)\ttotal: 27s\tremaining: 2m 14s\n",
      "2250:\ttest: 0.9709121\tbest: 0.9709223 (2248)\ttotal: 30.4s\tremaining: 2m 11s\n",
      "2500:\ttest: 0.9716265\tbest: 0.9716328 (2498)\ttotal: 33.8s\tremaining: 2m 8s\n",
      "2750:\ttest: 0.9720161\tbest: 0.9720161 (2750)\ttotal: 37.2s\tremaining: 2m 4s\n",
      "3000:\ttest: 0.9723863\tbest: 0.9724107 (2948)\ttotal: 40.6s\tremaining: 2m 1s\n",
      "3250:\ttest: 0.9725842\tbest: 0.9725899 (3243)\ttotal: 44.4s\tremaining: 1m 59s\n",
      "3500:\ttest: 0.9728513\tbest: 0.9728558 (3493)\ttotal: 48.3s\tremaining: 1m 57s\n",
      "3750:\ttest: 0.9730061\tbest: 0.9730373 (3707)\ttotal: 51.6s\tremaining: 1m 53s\n",
      "4000:\ttest: 0.9730611\tbest: 0.9730810 (3929)\ttotal: 55s\tremaining: 1m 49s\n",
      "4250:\ttest: 0.9731547\tbest: 0.9731654 (4222)\ttotal: 58.4s\tremaining: 1m 46s\n",
      "4500:\ttest: 0.9732635\tbest: 0.9732709 (4478)\ttotal: 1m 1s\tremaining: 1m 42s\n",
      "4750:\ttest: 0.9732896\tbest: 0.9733106 (4741)\ttotal: 1m 5s\tremaining: 1m 39s\n",
      "5000:\ttest: 0.9733837\tbest: 0.9734053 (4991)\ttotal: 1m 8s\tremaining: 1m 35s\n",
      "5250:\ttest: 0.9733747\tbest: 0.9734053 (4991)\ttotal: 1m 11s\tremaining: 1m 32s\n",
      "5500:\ttest: 0.9734688\tbest: 0.9734767 (5478)\ttotal: 1m 15s\tremaining: 1m 28s\n",
      "5750:\ttest: 0.9734648\tbest: 0.9734960 (5612)\ttotal: 1m 18s\tremaining: 1m 25s\n",
      "6000:\ttest: 0.9734541\tbest: 0.9734960 (5612)\ttotal: 1m 21s\tremaining: 1m 21s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.9734960172\n",
      "bestIteration = 5612\n",
      "\n",
      "Shrink model to first 5613 iterations.\n",
      "\n",
      "Testing scores 0.9246548323471401\n",
      "\n",
      "Training scores 0.9476929977014072\n",
      "========================Fold5==========================\n",
      "0:\ttest: 0.7886914\tbest: 0.7886914 (0)\ttotal: 17.1ms\tremaining: 3m 25s\n",
      "250:\ttest: 0.9456836\tbest: 0.9456836 (250)\ttotal: 3.38s\tremaining: 2m 38s\n",
      "500:\ttest: 0.9577845\tbest: 0.9577845 (500)\ttotal: 6.77s\tremaining: 2m 35s\n",
      "750:\ttest: 0.9618008\tbest: 0.9618008 (750)\ttotal: 10.4s\tremaining: 2m 35s\n",
      "1000:\ttest: 0.9640065\tbest: 0.9640235 (994)\ttotal: 13.7s\tremaining: 2m 30s\n",
      "1250:\ttest: 0.9655352\tbest: 0.9655352 (1250)\ttotal: 17.2s\tremaining: 2m 27s\n",
      "1500:\ttest: 0.9666602\tbest: 0.9666619 (1497)\ttotal: 20.6s\tremaining: 2m 23s\n",
      "1750:\ttest: 0.9675108\tbest: 0.9675108 (1750)\ttotal: 24.2s\tremaining: 2m 21s\n",
      "2000:\ttest: 0.9681719\tbest: 0.9681759 (1993)\ttotal: 27.6s\tremaining: 2m 18s\n",
      "2250:\ttest: 0.9687452\tbest: 0.9687503 (2248)\ttotal: 31s\tremaining: 2m 14s\n",
      "2500:\ttest: 0.9690525\tbest: 0.9690553 (2499)\ttotal: 34.3s\tremaining: 2m 10s\n",
      "2750:\ttest: 0.9694766\tbest: 0.9694846 (2747)\ttotal: 37.8s\tremaining: 2m 6s\n",
      "3000:\ttest: 0.9698741\tbest: 0.9698849 (2988)\ttotal: 41.1s\tremaining: 2m 3s\n",
      "3250:\ttest: 0.9701327\tbest: 0.9701344 (3246)\ttotal: 44.5s\tremaining: 1m 59s\n",
      "3500:\ttest: 0.9704378\tbest: 0.9704542 (3498)\ttotal: 48s\tremaining: 1m 56s\n",
      "3750:\ttest: 0.9706107\tbest: 0.9706107 (3750)\ttotal: 51.3s\tremaining: 1m 52s\n",
      "4000:\ttest: 0.9708506\tbest: 0.9708602 (3996)\ttotal: 54.7s\tremaining: 1m 49s\n",
      "4250:\ttest: 0.9710751\tbest: 0.9710751 (4250)\ttotal: 58.1s\tremaining: 1m 45s\n",
      "4500:\ttest: 0.9711902\tbest: 0.9711902 (4500)\ttotal: 1m 1s\tremaining: 1m 42s\n",
      "4750:\ttest: 0.9713297\tbest: 0.9713450 (4739)\ttotal: 1m 4s\tremaining: 1m 38s\n",
      "5000:\ttest: 0.9714828\tbest: 0.9714936 (4996)\ttotal: 1m 8s\tremaining: 1m 35s\n",
      "5250:\ttest: 0.9715310\tbest: 0.9715491 (5229)\ttotal: 1m 11s\tremaining: 1m 32s\n",
      "5500:\ttest: 0.9715832\tbest: 0.9715877 (5364)\ttotal: 1m 15s\tremaining: 1m 28s\n",
      "5750:\ttest: 0.9716960\tbest: 0.9717039 (5730)\ttotal: 1m 18s\tremaining: 1m 25s\n",
      "6000:\ttest: 0.9718207\tbest: 0.9718281 (5999)\ttotal: 1m 21s\tremaining: 1m 21s\n",
      "6250:\ttest: 0.9718638\tbest: 0.9718910 (6088)\ttotal: 1m 25s\tremaining: 1m 18s\n",
      "6500:\ttest: 0.9719245\tbest: 0.9719268 (6460)\ttotal: 1m 29s\tremaining: 1m 15s\n",
      "6750:\ttest: 0.9720209\tbest: 0.9720260 (6740)\ttotal: 1m 32s\tremaining: 1m 12s\n",
      "7000:\ttest: 0.9720220\tbest: 0.9720583 (6782)\ttotal: 1m 36s\tremaining: 1m 8s\n",
      "7250:\ttest: 0.9720770\tbest: 0.9720889 (7237)\ttotal: 1m 39s\tremaining: 1m 5s\n",
      "7500:\ttest: 0.9721604\tbest: 0.9721604 (7500)\ttotal: 1m 42s\tremaining: 1m 1s\n",
      "7750:\ttest: 0.9721938\tbest: 0.9721938 (7750)\ttotal: 1m 46s\tremaining: 58.2s\n",
      "8000:\ttest: 0.9722233\tbest: 0.9722301 (7983)\ttotal: 1m 49s\tremaining: 54.7s\n",
      "8250:\ttest: 0.9722454\tbest: 0.9722454 (8244)\ttotal: 1m 52s\tremaining: 51.3s\n",
      "8500:\ttest: 0.9722993\tbest: 0.9723061 (8498)\ttotal: 1m 56s\tremaining: 47.9s\n",
      "8750:\ttest: 0.9723452\tbest: 0.9723481 (8748)\ttotal: 1m 59s\tremaining: 44.4s\n",
      "9000:\ttest: 0.9723866\tbest: 0.9723866 (9000)\ttotal: 2m 3s\tremaining: 41s\n",
      "9250:\ttest: 0.9724110\tbest: 0.9724246 (9180)\ttotal: 2m 6s\tremaining: 37.6s\n",
      "9500:\ttest: 0.9724802\tbest: 0.9724870 (9494)\ttotal: 2m 9s\tremaining: 34.2s\n",
      "9750:\ttest: 0.9725290\tbest: 0.9725454 (9628)\ttotal: 2m 13s\tremaining: 30.8s\n",
      "10000:\ttest: 0.9725341\tbest: 0.9725454 (9628)\ttotal: 2m 16s\tremaining: 27.4s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.9725453962\n",
      "bestIteration = 9628\n",
      "\n",
      "Shrink model to first 9629 iterations.\n",
      "\n",
      "Testing scores 0.9220524872698785\n",
      "\n",
      "Training scores 0.9588418016418904\n",
      "========================Fold6==========================\n",
      "0:\ttest: 0.8194795\tbest: 0.8194795 (0)\ttotal: 15.4ms\tremaining: 3m 5s\n",
      "250:\ttest: 0.9488714\tbest: 0.9489026 (246)\ttotal: 3.57s\tremaining: 2m 47s\n",
      "500:\ttest: 0.9613327\tbest: 0.9613327 (500)\ttotal: 6.98s\tremaining: 2m 40s\n",
      "750:\ttest: 0.9661893\tbest: 0.9661893 (750)\ttotal: 10.4s\tremaining: 2m 35s\n",
      "1000:\ttest: 0.9691928\tbest: 0.9692036 (998)\ttotal: 14s\tremaining: 2m 34s\n",
      "1250:\ttest: 0.9711105\tbest: 0.9711105 (1250)\ttotal: 17.6s\tremaining: 2m 31s\n",
      "1500:\ttest: 0.9727169\tbest: 0.9727186 (1496)\ttotal: 21s\tremaining: 2m 26s\n",
      "1750:\ttest: 0.9738884\tbest: 0.9738884 (1750)\ttotal: 24.4s\tremaining: 2m 23s\n",
      "2000:\ttest: 0.9748484\tbest: 0.9748484 (2000)\ttotal: 27.9s\tremaining: 2m 19s\n",
      "2250:\ttest: 0.9755441\tbest: 0.9755441 (2250)\ttotal: 31.3s\tremaining: 2m 15s\n",
      "2500:\ttest: 0.9760369\tbest: 0.9760556 (2492)\ttotal: 34.7s\tremaining: 2m 11s\n",
      "2750:\ttest: 0.9765086\tbest: 0.9765120 (2748)\ttotal: 38s\tremaining: 2m 7s\n",
      "3000:\ttest: 0.9769050\tbest: 0.9769084 (2999)\ttotal: 41.5s\tremaining: 2m 4s\n",
      "3250:\ttest: 0.9771579\tbest: 0.9771681 (3245)\ttotal: 45s\tremaining: 2m 1s\n",
      "3500:\ttest: 0.9774505\tbest: 0.9774505 (3500)\ttotal: 48.4s\tremaining: 1m 57s\n",
      "3750:\ttest: 0.9776529\tbest: 0.9776648 (3746)\ttotal: 51.8s\tremaining: 1m 53s\n",
      "4000:\ttest: 0.9778440\tbest: 0.9778440 (4000)\ttotal: 55.2s\tremaining: 1m 50s\n",
      "4250:\ttest: 0.9779115\tbest: 0.9779353 (4181)\ttotal: 58.6s\tremaining: 1m 46s\n",
      "4500:\ttest: 0.9780334\tbest: 0.9780453 (4483)\ttotal: 1m 2s\tremaining: 1m 43s\n",
      "4750:\ttest: 0.9780878\tbest: 0.9780895 (4749)\ttotal: 1m 5s\tremaining: 1m 39s\n",
      "5000:\ttest: 0.9781570\tbest: 0.9781632 (4994)\ttotal: 1m 9s\tremaining: 1m 36s\n",
      "5250:\ttest: 0.9781666\tbest: 0.9782023 (5214)\ttotal: 1m 12s\tremaining: 1m 33s\n",
      "5500:\ttest: 0.9781831\tbest: 0.9782023 (5214)\ttotal: 1m 15s\tremaining: 1m 29s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.9782023425\n",
      "bestIteration = 5214\n",
      "\n",
      "Shrink model to first 5215 iterations.\n",
      "\n",
      "Testing scores 0.9340702724042638\n",
      "\n",
      "Training scores 0.9449561896203099\n",
      "========================Fold7==========================\n",
      "0:\ttest: 0.8151494\tbest: 0.8151494 (0)\ttotal: 15ms\tremaining: 2m 59s\n",
      "250:\ttest: 0.9519980\tbest: 0.9519980 (250)\ttotal: 3.42s\tremaining: 2m 40s\n",
      "500:\ttest: 0.9628314\tbest: 0.9628314 (500)\ttotal: 6.76s\tremaining: 2m 35s\n",
      "750:\ttest: 0.9661842\tbest: 0.9661904 (749)\ttotal: 10.2s\tremaining: 2m 32s\n",
      "1000:\ttest: 0.9682425\tbest: 0.9682425 (1000)\ttotal: 13.6s\tremaining: 2m 29s\n",
      "1250:\ttest: 0.9697100\tbest: 0.9697100 (1250)\ttotal: 17s\tremaining: 2m 25s\n",
      "1500:\ttest: 0.9711060\tbest: 0.9711060 (1500)\ttotal: 20.4s\tremaining: 2m 22s\n",
      "1750:\ttest: 0.9723398\tbest: 0.9723398 (1750)\ttotal: 23.9s\tremaining: 2m 19s\n",
      "2000:\ttest: 0.9730776\tbest: 0.9730776 (2000)\ttotal: 27.3s\tremaining: 2m 16s\n",
      "2250:\ttest: 0.9737342\tbest: 0.9737342 (2249)\ttotal: 30.7s\tremaining: 2m 13s\n",
      "2500:\ttest: 0.9741538\tbest: 0.9741617 (2480)\ttotal: 34.1s\tremaining: 2m 9s\n",
      "2750:\ttest: 0.9745104\tbest: 0.9745308 (2746)\ttotal: 37.5s\tremaining: 2m 5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000:\ttest: 0.9747905\tbest: 0.9748053 (2998)\ttotal: 40.9s\tremaining: 2m 2s\n",
      "3250:\ttest: 0.9750191\tbest: 0.9750298 (3246)\ttotal: 44.3s\tremaining: 1m 59s\n",
      "3500:\ttest: 0.9752878\tbest: 0.9752941 (3481)\ttotal: 47.6s\tremaining: 1m 55s\n",
      "3750:\ttest: 0.9754284\tbest: 0.9754284 (3750)\ttotal: 51s\tremaining: 1m 52s\n",
      "4000:\ttest: 0.9755538\tbest: 0.9755543 (3996)\ttotal: 54.4s\tremaining: 1m 48s\n",
      "4250:\ttest: 0.9755764\tbest: 0.9755764 (4250)\ttotal: 57.7s\tremaining: 1m 45s\n",
      "4500:\ttest: 0.9756354\tbest: 0.9756570 (4483)\ttotal: 1m 1s\tremaining: 1m 42s\n",
      "4750:\ttest: 0.9756819\tbest: 0.9756989 (4722)\ttotal: 1m 4s\tremaining: 1m 39s\n",
      "5000:\ttest: 0.9757052\tbest: 0.9757403 (4881)\ttotal: 1m 8s\tremaining: 1m 35s\n",
      "5250:\ttest: 0.9757789\tbest: 0.9757998 (5206)\ttotal: 1m 11s\tremaining: 1m 32s\n",
      "5500:\ttest: 0.9758169\tbest: 0.9758424 (5347)\ttotal: 1m 15s\tremaining: 1m 28s\n",
      "5750:\ttest: 0.9758106\tbest: 0.9758549 (5544)\ttotal: 1m 18s\tremaining: 1m 25s\n",
      "6000:\ttest: 0.9757636\tbest: 0.9758549 (5544)\ttotal: 1m 21s\tremaining: 1m 21s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.9758548501\n",
      "bestIteration = 5544\n",
      "\n",
      "Shrink model to first 5545 iterations.\n",
      "\n",
      "Testing scores 0.9225908372827804\n",
      "\n",
      "Training scores 0.9478109759515668\n",
      "========================Fold8==========================\n",
      "0:\ttest: 0.7977304\tbest: 0.7977304 (0)\ttotal: 15.2ms\tremaining: 3m 2s\n",
      "250:\ttest: 0.9559485\tbest: 0.9559485 (250)\ttotal: 3.44s\tremaining: 2m 40s\n",
      "500:\ttest: 0.9663203\tbest: 0.9663203 (500)\ttotal: 6.78s\tremaining: 2m 35s\n",
      "750:\ttest: 0.9708985\tbest: 0.9708990 (749)\ttotal: 10.1s\tremaining: 2m 30s\n",
      "1000:\ttest: 0.9729885\tbest: 0.9729948 (998)\ttotal: 13.5s\tremaining: 2m 27s\n",
      "1250:\ttest: 0.9745325\tbest: 0.9745325 (1250)\ttotal: 17s\tremaining: 2m 25s\n",
      "1500:\ttest: 0.9759133\tbest: 0.9759133 (1500)\ttotal: 20.3s\tremaining: 2m 22s\n",
      "1750:\ttest: 0.9768647\tbest: 0.9768653 (1749)\ttotal: 23.6s\tremaining: 2m 18s\n",
      "2000:\ttest: 0.9776801\tbest: 0.9776841 (1995)\ttotal: 27.1s\tremaining: 2m 15s\n",
      "2250:\ttest: 0.9781264\tbest: 0.9781264 (2250)\ttotal: 30.5s\tremaining: 2m 11s\n",
      "2500:\ttest: 0.9786123\tbest: 0.9786123 (2500)\ttotal: 34s\tremaining: 2m 9s\n",
      "2750:\ttest: 0.9789531\tbest: 0.9789605 (2746)\ttotal: 37.4s\tremaining: 2m 5s\n",
      "3000:\ttest: 0.9793750\tbest: 0.9793750 (3000)\ttotal: 40.8s\tremaining: 2m 2s\n",
      "3250:\ttest: 0.9796863\tbest: 0.9796874 (3246)\ttotal: 44.5s\tremaining: 1m 59s\n",
      "3500:\ttest: 0.9798875\tbest: 0.9798938 (3499)\ttotal: 48.1s\tremaining: 1m 56s\n",
      "3750:\ttest: 0.9801047\tbest: 0.9801104 (3749)\ttotal: 51.5s\tremaining: 1m 53s\n",
      "4000:\ttest: 0.9803565\tbest: 0.9803673 (3996)\ttotal: 54.9s\tremaining: 1m 49s\n",
      "4250:\ttest: 0.9804705\tbest: 0.9804733 (4216)\ttotal: 58.3s\tremaining: 1m 46s\n",
      "4500:\ttest: 0.9806088\tbest: 0.9806111 (4497)\ttotal: 1m 1s\tremaining: 1m 42s\n",
      "4750:\ttest: 0.9807415\tbest: 0.9807574 (4732)\ttotal: 1m 5s\tremaining: 1m 39s\n",
      "5000:\ttest: 0.9808345\tbest: 0.9808526 (4967)\ttotal: 1m 8s\tremaining: 1m 35s\n",
      "5250:\ttest: 0.9809519\tbest: 0.9809524 (5249)\ttotal: 1m 11s\tremaining: 1m 32s\n",
      "5500:\ttest: 0.9809564\tbest: 0.9809706 (5290)\ttotal: 1m 15s\tremaining: 1m 28s\n",
      "5750:\ttest: 0.9810023\tbest: 0.9810046 (5748)\ttotal: 1m 18s\tremaining: 1m 25s\n",
      "6000:\ttest: 0.9810448\tbest: 0.9810579 (5897)\ttotal: 1m 21s\tremaining: 1m 21s\n",
      "6250:\ttest: 0.9810437\tbest: 0.9810630 (6245)\ttotal: 1m 25s\tremaining: 1m 18s\n",
      "6500:\ttest: 0.9810828\tbest: 0.9810936 (6427)\ttotal: 1m 28s\tremaining: 1m 15s\n",
      "6750:\ttest: 0.9811203\tbest: 0.9811293 (6730)\ttotal: 1m 32s\tremaining: 1m 11s\n",
      "7000:\ttest: 0.9811679\tbest: 0.9811815 (6969)\ttotal: 1m 35s\tremaining: 1m 8s\n",
      "7250:\ttest: 0.9811917\tbest: 0.9812263 (7125)\ttotal: 1m 38s\tremaining: 1m 4s\n",
      "7500:\ttest: 0.9812235\tbest: 0.9812308 (7371)\ttotal: 1m 42s\tremaining: 1m 1s\n",
      "7750:\ttest: 0.9812235\tbest: 0.9812399 (7518)\ttotal: 1m 45s\tremaining: 57.9s\n",
      "8000:\ttest: 0.9812393\tbest: 0.9812546 (7900)\ttotal: 1m 49s\tremaining: 54.7s\n",
      "8250:\ttest: 0.9812660\tbest: 0.9812722 (8246)\ttotal: 1m 53s\tremaining: 51.4s\n",
      "8500:\ttest: 0.9812711\tbest: 0.9812847 (8410)\ttotal: 1m 56s\tremaining: 47.9s\n",
      "8750:\ttest: 0.9812337\tbest: 0.9812847 (8410)\ttotal: 1m 59s\tremaining: 44.5s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.9812847021\n",
      "bestIteration = 8410\n",
      "\n",
      "Shrink model to first 8411 iterations.\n",
      "\n",
      "Testing scores 0.9387121799844841\n",
      "\n",
      "Training scores 0.9539026834428237\n",
      "Average Testing ROC score for 8 folds split: 0.9265625636588739\n",
      "Average Training ROC score for 8 folds split: 0.9512377598091355\n",
      "standard Deviation for 8 folds split: 0.00633499366850728\n"
     ]
    }
   ],
   "source": [
    "catboost2 =  CatBoostClassifier(random_seed=34,bootstrap_type='Bayesian',max_depth=6,learning_rate=0.007,\n",
    "                          iterations=12000,silent=True,eval_metric='AUC')\n",
    "\n",
    "\n",
    "cat2_train, cat2_test, cat2_name = cat(catboost2,X,y,test_df.drop(['target'], axis =1),'catboost(2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================Fold1==========================\n",
      "0:\ttest: 0.8097014\tbest: 0.8097014 (0)\ttotal: 27.2ms\tremaining: 5m 26s\n",
      "250:\ttest: 0.9659103\tbest: 0.9659103 (250)\ttotal: 3.54s\tremaining: 2m 45s\n",
      "500:\ttest: 0.9704270\tbest: 0.9704270 (500)\ttotal: 6.91s\tremaining: 2m 38s\n",
      "750:\ttest: 0.9720821\tbest: 0.9720838 (748)\ttotal: 10.3s\tremaining: 2m 33s\n",
      "1000:\ttest: 0.9730795\tbest: 0.9731062 (985)\ttotal: 13.6s\tremaining: 2m 29s\n",
      "1250:\ttest: 0.9736534\tbest: 0.9736551 (1249)\ttotal: 17.1s\tremaining: 2m 26s\n",
      "1500:\ttest: 0.9741087\tbest: 0.9741087 (1499)\ttotal: 20.4s\tremaining: 2m 22s\n",
      "1750:\ttest: 0.9742556\tbest: 0.9742935 (1721)\ttotal: 23.7s\tremaining: 2m 18s\n",
      "2000:\ttest: 0.9746746\tbest: 0.9746774 (1998)\ttotal: 27.1s\tremaining: 2m 15s\n",
      "2250:\ttest: 0.9747319\tbest: 0.9748487 (2144)\ttotal: 30.5s\tremaining: 2m 11s\n",
      "2500:\ttest: 0.9747449\tbest: 0.9748487 (2144)\ttotal: 34.1s\tremaining: 2m 9s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.9748486605\n",
      "bestIteration = 2144\n",
      "\n",
      "Shrink model to first 2145 iterations.\n",
      "\n",
      "Testing scores 0.9213836477987422\n",
      "\n",
      "Training scores 0.9597069597069597\n",
      "========================Fold2==========================\n",
      "0:\ttest: 0.8101270\tbest: 0.8101270 (0)\ttotal: 15.5ms\tremaining: 3m 5s\n",
      "250:\ttest: 0.9652653\tbest: 0.9652653 (250)\ttotal: 3.5s\tremaining: 2m 43s\n",
      "500:\ttest: 0.9694007\tbest: 0.9694103 (474)\ttotal: 6.86s\tremaining: 2m 37s\n",
      "750:\ttest: 0.9707593\tbest: 0.9707593 (750)\ttotal: 10.2s\tremaining: 2m 33s\n",
      "1000:\ttest: 0.9713478\tbest: 0.9713773 (963)\ttotal: 14.2s\tremaining: 2m 35s\n",
      "1250:\ttest: 0.9719415\tbest: 0.9719835 (1217)\ttotal: 17.8s\tremaining: 2m 33s\n",
      "1500:\ttest: 0.9720782\tbest: 0.9720855 (1346)\ttotal: 21.3s\tremaining: 2m 28s\n",
      "1750:\ttest: 0.9719466\tbest: 0.9721099 (1533)\ttotal: 24.6s\tremaining: 2m 24s\n",
      "2000:\ttest: 0.9720731\tbest: 0.9721099 (1533)\ttotal: 28.1s\tremaining: 2m 20s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.9721099193\n",
      "bestIteration = 1533\n",
      "\n",
      "Shrink model to first 1534 iterations.\n",
      "\n",
      "Testing scores 0.9228944246737841\n",
      "\n",
      "Training scores 0.951012191030086\n",
      "========================Fold3==========================\n",
      "0:\ttest: 0.8020658\tbest: 0.8020658 (0)\ttotal: 22.9ms\tremaining: 4m 34s\n",
      "250:\ttest: 0.9700527\tbest: 0.9700527 (250)\ttotal: 3.41s\tremaining: 2m 39s\n",
      "500:\ttest: 0.9752297\tbest: 0.9752297 (500)\ttotal: 6.82s\tremaining: 2m 36s\n",
      "750:\ttest: 0.9769484\tbest: 0.9769540 (733)\ttotal: 10.2s\tremaining: 2m 32s\n",
      "1000:\ttest: 0.9772478\tbest: 0.9772478 (1000)\ttotal: 13.6s\tremaining: 2m 29s\n",
      "1250:\ttest: 0.9772001\tbest: 0.9773606 (1094)\ttotal: 17s\tremaining: 2m 25s\n",
      "1500:\ttest: 0.9768032\tbest: 0.9773606 (1094)\ttotal: 20.4s\tremaining: 2m 22s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.9773605907\n",
      "bestIteration = 1094\n",
      "\n",
      "Shrink model to first 1095 iterations.\n",
      "\n",
      "Testing scores 0.9265581579992059\n",
      "\n",
      "Training scores 0.9426492979191339\n",
      "========================Fold4==========================\n",
      "0:\ttest: 0.8113637\tbest: 0.8113637 (0)\ttotal: 15.2ms\tremaining: 3m 2s\n",
      "250:\ttest: 0.9644125\tbest: 0.9644125 (250)\ttotal: 3.44s\tremaining: 2m 41s\n",
      "500:\ttest: 0.9711236\tbest: 0.9711298 (499)\ttotal: 6.82s\tremaining: 2m 36s\n",
      "750:\ttest: 0.9728405\tbest: 0.9728774 (740)\ttotal: 10.3s\tremaining: 2m 34s\n",
      "1000:\ttest: 0.9731944\tbest: 0.9732465 (860)\ttotal: 13.7s\tremaining: 2m 30s\n",
      "1250:\ttest: 0.9731768\tbest: 0.9732465 (860)\ttotal: 17.1s\tremaining: 2m 27s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.9732465253\n",
      "bestIteration = 860\n",
      "\n",
      "Shrink model to first 861 iterations.\n",
      "\n",
      "Testing scores 0.9226475279106858\n",
      "\n",
      "Training scores 0.9379779099405269\n",
      "========================Fold5==========================\n",
      "0:\ttest: 0.7886914\tbest: 0.7886914 (0)\ttotal: 15.6ms\tremaining: 3m 6s\n",
      "250:\ttest: 0.9642895\tbest: 0.9642895 (250)\ttotal: 3.45s\tremaining: 2m 41s\n",
      "500:\ttest: 0.9693190\tbest: 0.9693372 (499)\ttotal: 7.38s\tremaining: 2m 49s\n",
      "750:\ttest: 0.9710314\tbest: 0.9710467 (739)\ttotal: 12.4s\tremaining: 3m 6s\n",
      "1000:\ttest: 0.9717294\tbest: 0.9719171 (943)\ttotal: 17.6s\tremaining: 3m 13s\n",
      "1250:\ttest: 0.9718224\tbest: 0.9719171 (943)\ttotal: 23.1s\tremaining: 3m 18s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.9719171301\n",
      "bestIteration = 943\n",
      "\n",
      "Shrink model to first 944 iterations.\n",
      "\n",
      "Testing scores 0.9153754469606675\n",
      "\n",
      "Training scores 0.9409839765290002\n",
      "========================Fold6==========================\n",
      "0:\ttest: 0.8144421\tbest: 0.8144421 (0)\ttotal: 15.6ms\tremaining: 3m 7s\n",
      "250:\ttest: 0.9696034\tbest: 0.9696034 (250)\ttotal: 3.51s\tremaining: 2m 44s\n",
      "500:\ttest: 0.9745841\tbest: 0.9746159 (499)\ttotal: 6.87s\tremaining: 2m 37s\n",
      "750:\ttest: 0.9765069\tbest: 0.9765069 (750)\ttotal: 10.3s\tremaining: 2m 34s\n",
      "1000:\ttest: 0.9774941\tbest: 0.9775185 (987)\ttotal: 13.7s\tremaining: 2m 30s\n",
      "1250:\ttest: 0.9776393\tbest: 0.9778360 (1186)\ttotal: 17.1s\tremaining: 2m 27s\n",
      "1500:\ttest: 0.9776189\tbest: 0.9778360 (1186)\ttotal: 20.5s\tremaining: 2m 23s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.977836043\n",
      "bestIteration = 1186\n",
      "\n",
      "Shrink model to first 1187 iterations.\n",
      "\n",
      "Testing scores 0.9312796208530806\n",
      "\n",
      "Training scores 0.9449696151249156\n",
      "========================Fold7==========================\n",
      "0:\ttest: 0.8219195\tbest: 0.8219195 (0)\ttotal: 14.9ms\tremaining: 2m 59s\n",
      "250:\ttest: 0.9685090\tbest: 0.9685090 (250)\ttotal: 3.59s\tremaining: 2m 48s\n",
      "500:\ttest: 0.9738317\tbest: 0.9738317 (500)\ttotal: 7.08s\tremaining: 2m 42s\n",
      "750:\ttest: 0.9746204\tbest: 0.9746658 (732)\ttotal: 10.5s\tremaining: 2m 37s\n",
      "1000:\ttest: 0.9750672\tbest: 0.9750933 (990)\ttotal: 14s\tremaining: 2m 33s\n",
      "1250:\ttest: 0.9751653\tbest: 0.9752011 (1235)\ttotal: 17.4s\tremaining: 2m 29s\n",
      "1500:\ttest: 0.9751115\tbest: 0.9752130 (1301)\ttotal: 21.4s\tremaining: 2m 29s\n",
      "1750:\ttest: 0.9749073\tbest: 0.9752130 (1301)\ttotal: 25.3s\tremaining: 2m 28s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.9752129754\n",
      "bestIteration = 1301\n",
      "\n",
      "Shrink model to first 1302 iterations.\n",
      "\n",
      "Testing scores 0.9231987331749801\n",
      "\n",
      "Training scores 0.9496104478448518\n",
      "========================Fold8==========================\n",
      "0:\ttest: 0.7977304\tbest: 0.7977304 (0)\ttotal: 16.6ms\tremaining: 3m 19s\n",
      "250:\ttest: 0.9734291\tbest: 0.9734291 (250)\ttotal: 3.47s\tremaining: 2m 42s\n",
      "500:\ttest: 0.9778411\tbest: 0.9778451 (487)\ttotal: 6.92s\tremaining: 2m 38s\n",
      "750:\ttest: 0.9795377\tbest: 0.9795377 (750)\ttotal: 10.3s\tremaining: 2m 34s\n",
      "1000:\ttest: 0.9806128\tbest: 0.9806156 (988)\ttotal: 13.7s\tremaining: 2m 31s\n",
      "1250:\ttest: 0.9810874\tbest: 0.9811016 (1239)\ttotal: 17.2s\tremaining: 2m 27s\n",
      "1500:\ttest: 0.9812507\tbest: 0.9812722 (1487)\ttotal: 20.6s\tremaining: 2m 24s\n",
      "1750:\ttest: 0.9814457\tbest: 0.9814769 (1708)\ttotal: 24.1s\tremaining: 2m 21s\n",
      "2000:\ttest: 0.9814060\tbest: 0.9815109 (1908)\ttotal: 27.7s\tremaining: 2m 18s\n",
      "2250:\ttest: 0.9811991\tbest: 0.9815109 (1908)\ttotal: 31.2s\tremaining: 2m 15s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.9815109459\n",
      "bestIteration = 1908\n",
      "\n",
      "Shrink model to first 1909 iterations.\n",
      "\n",
      "Testing scores 0.9366990291262135\n",
      "\n",
      "Training scores 0.9549429128376496\n",
      "Average Testing ROC score for 8 folds split: 0.9250045735621699\n",
      "Average Training ROC score for 8 folds split: 0.9477316638666404\n",
      "standard Deviation for 8 folds split: 0.006099700490351075\n"
     ]
    }
   ],
   "source": [
    "catboost =  CatBoostClassifier(random_seed=34,use_best_model=True,\n",
    "                          n_estimators=12000,silent=True,eval_metric='AUC', loss_function = 'CrossEntropy')\n",
    "\n",
    "cat1_train, cat1_test, cat1_name = cat(catboost,X,y,test_df,'catboost(1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================Fold1==========================\n",
      "\n",
      "Validation scores 0.9102072141212585\n",
      "\n",
      "Training scores 0.9927933742067334\n",
      "========================Fold2==========================\n",
      "\n",
      "Validation scores 0.9105382865807431\n",
      "\n",
      "Training scores 0.9926363880677237\n",
      "========================Fold3==========================\n",
      "\n",
      "Validation scores 0.9115749525616698\n",
      "\n",
      "Training scores 0.9926858126277295\n",
      "========================Fold4==========================\n",
      "\n",
      "Validation scores 0.9133918351774132\n",
      "\n",
      "Training scores 0.9928483088670216\n",
      "========================Fold5==========================\n",
      "\n",
      "Validation scores 0.9145921103025662\n",
      "\n",
      "Training scores 0.9924213920988981\n",
      "========================Fold6==========================\n",
      "\n",
      "Validation scores 0.919557758292032\n",
      "\n",
      "Training scores 0.9912818856958348\n",
      "========================Fold7==========================\n",
      "\n",
      "Validation scores 0.908813429988554\n",
      "\n",
      "Training scores 0.9933326164103666\n",
      "========================Fold8==========================\n",
      "\n",
      "Validation scores 0.9246420497362473\n",
      "\n",
      "Training scores 0.9920954992740765\n",
      "Average Testing ROC score for 10 folds split: 0.9141647045950605\n",
      "Average Training ROC score for 10 folds split: 0.992511909656048\n",
      "standard Deviation for 10 folds split: 0.005047219359892687\n"
     ]
    }
   ],
   "source": [
    "gbm_model = GradientBoostingClassifier(max_depth=5,min_samples_leaf=9,n_estimators=3000,learning_rate=0.6,min_samples_split=10,random_state=10)\n",
    "gbm_train, gbm_test, gbm_name= model(gbm_model,X,y,test_df.drop(['target'], axis =1), 'Gbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================Fold1==========================\n",
      "\n",
      "Validation scores 0.7577965607694549\n",
      "\n",
      "Training scores 0.75682823023842\n",
      "========================Fold2==========================\n",
      "\n",
      "Validation scores 0.7527440785673022\n",
      "\n",
      "Training scores 0.7568978374347501\n",
      "========================Fold3==========================\n",
      "\n",
      "Validation scores 0.757699012202208\n",
      "\n",
      "Training scores 0.7557672395941188\n",
      "========================Fold4==========================\n",
      "\n",
      "Validation scores 0.7524467472654001\n",
      "\n",
      "Training scores 0.7569024127352624\n",
      "========================Fold5==========================\n",
      "\n",
      "Validation scores 0.7533217793183131\n",
      "\n",
      "Training scores 0.7573209625978545\n",
      "========================Fold6==========================\n",
      "\n",
      "Validation scores 0.754041570438799\n",
      "\n",
      "Training scores 0.7571440404207737\n",
      "========================Fold7==========================\n",
      "\n",
      "Validation scores 0.763986013986014\n",
      "\n",
      "Training scores 0.755959512497418\n",
      "========================Fold8==========================\n",
      "\n",
      "Validation scores 0.7595231171852282\n",
      "\n",
      "Training scores 0.7565958150690596\n",
      "Average Testing ROC score for 10 folds split: 0.7564448599665899\n",
      "Average Training ROC score for 10 folds split: 0.7566770063234571\n",
      "standard Deviation for 10 folds split: 0.003790692314177352\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "gnb_model = GaussianNB()\n",
    "gnb_train, gnb_test, gnb_name = model(gnb_model,X,y,test_df.drop(['target'], axis =1),'GNB(1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================Fold1==========================\n",
      "\n",
      "Validation scores 0.7509293680297398\n",
      "\n",
      "Training scores 0.7413282369804108\n",
      "========================Fold2==========================\n",
      "\n",
      "Validation scores 0.7370140476968311\n",
      "\n",
      "Training scores 0.75\n",
      "========================Fold3==========================\n",
      "\n",
      "Validation scores 0.7404453306746428\n",
      "\n",
      "Training scores 0.7467145693485865\n",
      "========================Fold4==========================\n",
      "\n",
      "Validation scores 0.7500812479688007\n",
      "\n",
      "Training scores 0.7528552705485864\n",
      "========================Fold5==========================\n",
      "\n",
      "Validation scores 0.7397534155281571\n",
      "\n",
      "Training scores 0.7464528069093154\n",
      "========================Fold6==========================\n",
      "\n",
      "Validation scores 0.7469642271086314\n",
      "\n",
      "Training scores 0.751412429378531\n",
      "========================Fold7==========================\n",
      "\n",
      "Validation scores 0.7455386649041639\n",
      "\n",
      "Training scores 0.7466503113795055\n",
      "========================Fold8==========================\n",
      "\n",
      "Validation scores 0.7644503842298698\n",
      "\n",
      "Training scores 0.7418467956010618\n",
      "Average Testing ROC score for 10 folds split: 0.7468970857676046\n",
      "Average Training ROC score for 10 folds split: 0.7471575525182497\n",
      "standard Deviation for 10 folds split: 0.008114014889761784\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "log_model = LogisticRegression()\n",
    "log_train, log_test, log_name = model(log_model,X,y,test_df.drop(['target'], axis =1),'LOG(1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================Fold1==========================\n",
      "\n",
      "Validation scores 0.7600459242250288\n",
      "\n",
      "Training scores 0.7554018311291962\n",
      "========================Fold2==========================\n",
      "\n",
      "Validation scores 0.587917042380523\n",
      "\n",
      "Training scores 0.5790881221055378\n",
      "========================Fold3==========================\n",
      "\n",
      "Validation scores 0.7556066705002876\n",
      "\n",
      "Training scores 0.755351053777577\n",
      "========================Fold4==========================\n",
      "\n",
      "Validation scores 0.556024378809189\n",
      "\n",
      "Training scores 0.5363105741821637\n",
      "========================Fold5==========================\n",
      "\n",
      "Validation scores 0.7536973833902162\n",
      "\n",
      "Training scores 0.756120412236751\n",
      "========================Fold6==========================\n",
      "\n",
      "Validation scores 0.49688149688149685\n",
      "\n",
      "Training scores 0.4807391401534908\n",
      "========================Fold7==========================\n",
      "\n",
      "Validation scores 0.5186660029865605\n",
      "\n",
      "Training scores 0.5180205949656751\n",
      "========================Fold8==========================\n",
      "\n",
      "Validation scores 0.7570653725378247\n",
      "\n",
      "Training scores 0.7553204476093591\n",
      "Average Testing ROC score for 10 folds split: 0.6482380339638909\n",
      "Average Training ROC score for 10 folds split: 0.6420440220199688\n",
      "standard Deviation for 10 folds split: 0.11114955307523527\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier(loss=\"log\",penalty=\"l2\", max_iter=500)\n",
    "sgd_train, sgd_test, sgd_name = model(sgd_model,X,y,test_df.drop(['target'], axis =1),'SGD(1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================Fold1==========================\n",
      "\n",
      "Validation scores 0.8909606809890555\n",
      "\n",
      "Training scores 0.90938380990737\n",
      "========================Fold2==========================\n",
      "\n",
      "Validation scores 0.9015334947538337\n",
      "\n",
      "Training scores 0.9103559312287965\n",
      "========================Fold3==========================\n",
      "\n",
      "Validation scores 0.9063761097659403\n",
      "\n",
      "Training scores 0.9095303867403315\n",
      "========================Fold4==========================\n",
      "\n",
      "Validation scores 0.8925820835022295\n",
      "\n",
      "Training scores 0.9098722282702115\n",
      "========================Fold5==========================\n",
      "\n",
      "Validation scores 0.8964127367996776\n",
      "\n",
      "Training scores 0.911243964129685\n",
      "========================Fold6==========================\n",
      "\n",
      "Validation scores 0.9087974172719936\n",
      "\n",
      "Training scores 0.90938380990737\n",
      "========================Fold7==========================\n",
      "\n",
      "Validation scores 0.8981744421906693\n",
      "\n",
      "Training scores 0.9126146788990825\n",
      "========================Fold8==========================\n",
      "\n",
      "Validation scores 0.915576694411415\n",
      "\n",
      "Training scores 0.9110524503615286\n",
      "Average Testing ROC score for 10 folds split: 0.9013017074606018\n",
      "Average Training ROC score for 10 folds split: 0.9104296574305469\n",
      "standard Deviation for 10 folds split: 0.007924760996244281\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfm_model = RandomForestClassifier(n_estimators = 2000, oob_score=True, n_jobs=-1, max_features=None, min_samples_leaf=30)\n",
    "rfm_train, rfm_test, rfm_name = model(rfm_model,X,y,test_df.drop(['target'], axis =1),'RFM(1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================Fold1==========================\n",
      "\n",
      "Validation scores 0.918733307897749\n",
      "\n",
      "Training scores 0.9927949241853963\n",
      "========================Fold2==========================\n",
      "\n",
      "Validation scores 0.9256576439191765\n",
      "\n",
      "Training scores 0.9926300500295875\n",
      "========================Fold3==========================\n",
      "\n",
      "Validation scores 0.9241849886277482\n",
      "\n",
      "Training scores 0.9926850258175559\n",
      "========================Fold4==========================\n",
      "\n",
      "Validation scores 0.9272588055130168\n",
      "\n",
      "Training scores 0.992844461182547\n",
      "========================Fold5==========================\n",
      "\n",
      "Validation scores 0.9239005736137668\n",
      "\n",
      "Training scores 0.9924132364810332\n",
      "========================Fold6==========================\n",
      "\n",
      "Validation scores 0.9326702371843917\n",
      "\n",
      "Training scores 0.9925224595190703\n",
      "========================Fold7==========================\n",
      "\n",
      "Validation scores 0.918007662835249\n",
      "\n",
      "Training scores 0.9933275936289281\n",
      "========================Fold8==========================\n",
      "\n",
      "Validation scores 0.9361058601134216\n",
      "\n",
      "Training scores 0.9920937987414619\n",
      "Average Testing ROC score for 10 folds split: 0.925814884963065\n",
      "Average Training ROC score for 10 folds split: 0.9926639436981975\n",
      "standard Deviation for 10 folds split: 0.005835583261499671\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_model = RandomForestClassifier(n_estimators = 2000, random_state=101)\n",
    "ada_train, ada_test, ada_name = model(ada_model,X,y,test_df.drop(['target'], axis =1),'ADA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================Fold1==========================\n",
      "\n",
      "Validation scores 0.7959565705728191\n",
      "\n",
      "Training scores 0.8104485488126649\n",
      "========================Fold2==========================\n",
      "\n",
      "Validation scores 0.7964796479647964\n",
      "\n",
      "Training scores 0.8052938062466914\n",
      "========================Fold3==========================\n",
      "\n",
      "Validation scores 0.8046407185628742\n",
      "\n",
      "Training scores 0.8077231641439804\n",
      "========================Fold4==========================\n",
      "\n",
      "Validation scores 0.8032044583768722\n",
      "\n",
      "Training scores 0.8169576059850375\n",
      "========================Fold5==========================\n",
      "\n",
      "Validation scores 0.7930283224400871\n",
      "\n",
      "Training scores 0.8100753051155545\n",
      "========================Fold6==========================\n",
      "\n",
      "Validation scores 0.811908931698774\n",
      "\n",
      "Training scores 0.8146560319042871\n",
      "========================Fold7==========================\n",
      "\n",
      "Validation scores 0.8142153413089375\n",
      "\n",
      "Training scores 0.8137128072445019\n",
      "========================Fold8==========================\n",
      "\n",
      "Validation scores 0.8152022315202231\n",
      "\n",
      "Training scores 0.8143076846752989\n",
      "Average Testing ROC score for 10 folds split: 0.804329527805673\n",
      "Average Training ROC score for 10 folds split: 0.811646869266002\n",
      "standard Deviation for 10 folds split: 0.008171591399644938\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc_model = DecisionTreeClassifier(max_depth=8,min_samples_leaf=5,criterion = 'entropy',min_samples_split=10,random_state=10)\n",
    "dtc_train, dtc_test, dtc_name= model(dtc_model,X,y,test_df.drop(['target'], axis =1), 'dtc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 917,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb(model,train,label,test,model_name):\n",
    "    mean_train = []\n",
    "    mean_test = []\n",
    "    test_pred = np.zeros(test.shape[0])\n",
    "    val_pred = np.zeros(train.shape[0])\n",
    "    for count, (train_index,test_index) in enumerate(skf.split(train,label)):\n",
    "        x_train,x_test = train.iloc[train_index],train.iloc[test_index]\n",
    "        y_train,y_test = label.iloc[train_index],label.iloc[test_index]\n",
    "        print(f'========================Fold{count +1}==========================')\n",
    "        model.fit(x_train, y_train, early_stopping_rounds = 500, eval_metric=\"auc\",\n",
    "                           eval_set=[(x_test, y_test)],verbose=250)\n",
    "        train_predict = model.predict(x_train, ntree_limit = model.get_booster().best_ntree_limit)\n",
    "        test_predict = model.predict(x_test, ntree_limit = model.get_booster().best_ntree_limit)\n",
    "        val_pred[test_index] = test_predict\n",
    "        test_pred+= model.predict(test, ntree_limit = model.get_booster().best_ntree_limit)\n",
    "        \n",
    "        print('\\nTesting scores', f1_score(y_test,test_predict))\n",
    "        print('\\nTraining scores', f1_score(y_train,train_predict))\n",
    "        mean_train.append(f1_score(y_train, train_predict))\n",
    "        mean_test.append(f1_score(y_test,test_predict))\n",
    "    print('Average Testing ROC score for 10 folds split:',np.mean(mean_test))\n",
    "    print('Average Training ROC score for 10 folds split:',np.mean(mean_train))\n",
    "    print('standard Deviation for 10 folds split:',np.std(mean_test))\n",
    "    return val_pred, test_pred, model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================Fold1==========================\n",
      "[0]\tvalidation_0-auc:0.88633\n",
      "Will train until validation_0-auc hasn't improved in 500 rounds.\n",
      "[250]\tvalidation_0-auc:0.97227\n",
      "[500]\tvalidation_0-auc:0.97176\n",
      "Stopping. Best iteration:\n",
      "[86]\tvalidation_0-auc:0.97268\n",
      "\n",
      "\n",
      "Testing scores 0.9199066874027994\n",
      "\n",
      "Training scores 0.949005666037107\n",
      "========================Fold2==========================\n",
      "[0]\tvalidation_0-auc:0.88508\n",
      "Will train until validation_0-auc hasn't improved in 500 rounds.\n",
      "[250]\tvalidation_0-auc:0.97194\n",
      "[500]\tvalidation_0-auc:0.97095\n",
      "Stopping. Best iteration:\n",
      "[100]\tvalidation_0-auc:0.97307\n",
      "\n",
      "\n",
      "Testing scores 0.9198443579766536\n",
      "\n",
      "Training scores 0.9498971250625591\n",
      "========================Fold3==========================\n",
      "[0]\tvalidation_0-auc:0.88007\n",
      "Will train until validation_0-auc hasn't improved in 500 rounds.\n",
      "[250]\tvalidation_0-auc:0.97457\n",
      "[500]\tvalidation_0-auc:0.97376\n",
      "Stopping. Best iteration:\n",
      "[77]\tvalidation_0-auc:0.97581\n",
      "\n",
      "\n",
      "Testing scores 0.9236165237724083\n",
      "\n",
      "Training scores 0.948000667371114\n",
      "========================Fold4==========================\n",
      "[0]\tvalidation_0-auc:0.86198\n",
      "Will train until validation_0-auc hasn't improved in 500 rounds.\n",
      "[250]\tvalidation_0-auc:0.97117\n",
      "[500]\tvalidation_0-auc:0.97023\n",
      "Stopping. Best iteration:\n",
      "[227]\tvalidation_0-auc:0.97148\n",
      "\n",
      "\n",
      "Testing scores 0.9237911025145068\n",
      "\n",
      "Training scores 0.9619514343923793\n",
      "========================Fold5==========================\n",
      "[0]\tvalidation_0-auc:0.87882\n",
      "Will train until validation_0-auc hasn't improved in 500 rounds.\n",
      "[250]\tvalidation_0-auc:0.96985\n",
      "[500]\tvalidation_0-auc:0.96963\n",
      "Stopping. Best iteration:\n",
      "[230]\tvalidation_0-auc:0.97033\n",
      "\n",
      "\n",
      "Testing scores 0.9176015473887815\n",
      "\n",
      "Training scores 0.9619289340101523\n",
      "========================Fold6==========================\n",
      "[0]\tvalidation_0-auc:0.87045\n",
      "Will train until validation_0-auc hasn't improved in 500 rounds.\n",
      "[250]\tvalidation_0-auc:0.97570\n",
      "[500]\tvalidation_0-auc:0.97533\n",
      "[750]\tvalidation_0-auc:0.97494\n",
      "Stopping. Best iteration:\n",
      "[384]\tvalidation_0-auc:0.97615\n",
      "\n",
      "\n",
      "Testing scores 0.9299610894941635\n",
      "\n",
      "Training scores 0.9664304159112136\n",
      "========================Fold7==========================\n",
      "[0]\tvalidation_0-auc:0.87791\n",
      "Will train until validation_0-auc hasn't improved in 500 rounds.\n",
      "[250]\tvalidation_0-auc:0.97330\n",
      "[500]\tvalidation_0-auc:0.97285\n",
      "Stopping. Best iteration:\n",
      "[119]\tvalidation_0-auc:0.97491\n",
      "\n",
      "\n",
      "Testing scores 0.9200779727095516\n",
      "\n",
      "Training scores 0.9523968042609853\n",
      "========================Fold8==========================\n",
      "[0]\tvalidation_0-auc:0.88721\n",
      "Will train until validation_0-auc hasn't improved in 500 rounds.\n",
      "[250]\tvalidation_0-auc:0.97900\n",
      "[500]\tvalidation_0-auc:0.97861\n",
      "Stopping. Best iteration:\n",
      "[221]\tvalidation_0-auc:0.97954\n",
      "\n",
      "\n",
      "Testing scores 0.9356321839080459\n",
      "\n",
      "Training scores 0.9588284056369163\n",
      "Average Testing ROC score for 10 folds split: 0.9238039331458638\n",
      "Average Training ROC score for 10 folds split: 0.9560549315853034\n",
      "standard Deviation for 10 folds split: 0.005712623165454608\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "Xgboost = XGBClassifier(learning_rate=0.5,subsample=0.7,colsample_bytree=0.9,reg_alpha=6,\n",
    "               n_jobs=-1,n_estimators=5000,max_depth= 7,random_state=34)\n",
    "\n",
    "xgb_train, xgb_test, xgb_name= xgb(Xgboost,X,y,test_df.drop(['target'], axis =1),'xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================Fold1==========================\n",
      "\n",
      "Validation scores 0.9133307423241352\n",
      "\n",
      "Training scores 0.950480822372057\n",
      "========================Fold2==========================\n",
      "\n",
      "Validation scores 0.905320813771518\n",
      "\n",
      "Training scores 0.9222247090420769\n",
      "========================Fold3==========================\n",
      "\n",
      "Validation scores 0.9175738724727837\n",
      "\n",
      "Training scores 0.9373991430638251\n",
      "========================Fold4==========================\n",
      "\n",
      "Validation scores 0.9071290944123314\n",
      "\n",
      "Training scores 0.9528166685040238\n",
      "========================Fold5==========================\n",
      "\n",
      "Validation scores 0.9081751259201859\n",
      "\n",
      "Training scores 0.9367313019390582\n",
      "========================Fold6==========================\n",
      "\n",
      "Validation scores 0.9218139171227522\n",
      "\n",
      "Training scores 0.9319120437548833\n",
      "========================Fold7==========================\n",
      "\n",
      "Validation scores 0.9174168297455968\n",
      "\n",
      "Training scores 0.9369832402234637\n",
      "========================Fold8==========================\n",
      "\n",
      "Validation scores 0.9216589861751152\n",
      "\n",
      "Training scores 0.9441736818785998\n",
      "Average Testing ROC score for 10 folds split: 0.9140524227430522\n",
      "Average Training ROC score for 10 folds split: 0.9390902013472484\n",
      "standard Deviation for 10 folds split: 0.0061345064584260875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "hist_model = HistGradientBoostingClassifier(max_iter = 3000, learning_rate = 0.6, loss='auto',random_state = 1)\n",
    "hist_train, hist_test, hist_name= model(hist_model,X,y,test_df.drop(['target'], axis =1), 'hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stack_Train = pd.concat([pd.DataFrame(LGB1_train), pd.DataFrame(gbm_train), pd.DataFrame(ada_train),pd.DataFrame(xgb_train),\n",
    "                         pd.DataFrame(dtc_train), pd.DataFrame(rfm_train), pd.DataFrame(sgd_train), pd.DataFrame(gnb_train),\n",
    "                         pd.DataFrame(log_train),pd.DataFrame(hist_train)],1)\n",
    "\n",
    "Stack_Test = pd.concat([pd.DataFrame(LGB1_test), pd.DataFrame(gbm_test), pd.DataFrame(ada_test),pd.DataFrame(xgb_test),\n",
    "                         pd.DataFrame(dtc_test), pd.DataFrame(rfm_test), pd.DataFrame(sgd_test), pd.DataFrame(gnb_test),\n",
    "                         pd.DataFrame(log_test),pd.DataFrame(hist_test)],1)\n",
    "\n",
    "Stack_Train.columns=[LGB1_name,gbm_name,ada_name,xgb_name,dtc_name,rfm_name,sgd_name,gnb_name,log_name,hist_name]\n",
    "Stack_Test.columns=[LGB1_name,gbm_name,ada_name,xgb_name,dtc_name,rfm_name,sgd_name,gnb_name,log_name,hist_name]\n",
    "\n",
    "Stack_Test = Stack_Test/8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lightgbm(1)</th>\n",
       "      <th>Gbm</th>\n",
       "      <th>ADA</th>\n",
       "      <th>xgboost</th>\n",
       "      <th>dtc</th>\n",
       "      <th>RFM(1)</th>\n",
       "      <th>SGD(1)</th>\n",
       "      <th>GNB(1)</th>\n",
       "      <th>LOG(1)</th>\n",
       "      <th>hist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lightgbm(1)    Gbm  ADA  xgboost    dtc  RFM(1)  SGD(1)  GNB(1)  LOG(1)  \\\n",
       "0          1.0  0.000  0.0    0.375  0.500   0.875    0.50     1.0     0.0   \n",
       "1          1.0  1.000  0.0    1.000  0.500   1.000    0.50     1.0     1.0   \n",
       "2          1.0  1.000  0.0    1.000  1.000   1.000    0.50     1.0     0.0   \n",
       "3          0.0  0.375  0.0    0.250  0.000   0.000    0.00     0.0     0.0   \n",
       "4          1.0  0.000  0.0    1.000  0.875   0.750    0.75     1.0     1.0   \n",
       "\n",
       "    hist  \n",
       "0  0.250  \n",
       "1  0.375  \n",
       "2  1.000  \n",
       "3  0.125  \n",
       "4  1.000  "
      ]
     },
     "execution_count": 922,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stack_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "base_model = LogisticRegression()\n",
    "Stacking(base_model,Stack_Train,Stack_Test,y,'ffinal_stack11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "base_model = SVC(class_weight = 'balanced', probability = True)\n",
    "Stacking(base_model,Stack_Train,Stack_Test,y,'ffinal_stack13.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "bbc = BalancedBaggingClassifier(base_estimator= gbm_model, sampling_strategy='auto',replacement = False, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_model = bbc.fit(X_train,y_train)\n",
    "pred = b_model.predict(X_test)\n",
    "print(f1_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = b_model.predict(test_df.drop(['target'],axis =1))\n",
    "sub= ttest[[\"ID\"]]\n",
    "sub['target'] = preds\n",
    "sub.to_csv('catd.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
